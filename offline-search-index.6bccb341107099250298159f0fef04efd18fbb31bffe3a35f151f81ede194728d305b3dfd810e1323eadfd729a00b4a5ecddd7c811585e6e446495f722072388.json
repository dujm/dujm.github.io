[{"body":"\nPolicy-Based Methods  With value-based methods, the agent uses its experience with the environment to maintain an estimate of the optimal action-value function. The optimal policy is then obtained from the optimal action-value function estimate. Policy-based methods directly learn the optimal policy, without having to maintain a separate value function estimate.  Why There are three reasons why we consider policy-based methods:\n Simplicity  Policy-based methods directly get to the problem at hand (estimating the optimal policy), without having to store a bunch of additional data (i.e., the action values) that may not be useful.   Stochastic policies  Unlike value-based methods, policy-based methods can learn true stochastic policies.   Continuous action spaces  Policy-based methods are well-suited for continuous action spaces.    Policy Function Approximation A stochastic policy  The agent passes the current environment state as input to the network, which returns action probabilities. Then, the agent samples from those probabilities to select an action.  A Deterministic Policy  The agent passes the current environment state as input to the network, which returns action probabilities. Then, the agent selects the greedy action  NN that encodes action probabilities (Source)\nDiscrete vs Continuous  Discrete action spaces  Cart Pole  output layer: the probabilities for each action: 3 nodes output activation function: softmax     Continuous action spaces  Bipedal Walker  output layer: 4 nodes output activation function: tanh   Bontinuous Mountain Car  output layer: 1 node output activation function: tanh                    Gradient Ascent  Gradient descent steps in the direction opposite the gradient, since it wants to minimize a function.  $\\theta \\leftarrow \\theta - \\alpha \\nabla_\\theta U(\\theta) $ $\\alpha$: step size   Gradient ascent is otherwise identical, except we step in the direction of the gradient, to reach the maximum.  $\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta U(\\theta) $ $\\alpha$: step size    Local Minima  A minimum within some neighborhood It may not be a global minimum.  Hill Climbing  A mathematical optimization technique which belongs to the family of local search. An iterative algorithm that starts with an arbitrary solution to a problem, then attempts to find a better solution by making an incremental change to the solution. If the change produces a better solution, another incremental change is made to the new solution, and so on until no further improvements can be found.  Mathematical Definition\n Hill climbing is an iterative algorithm that can be used to find the weights $\\theta$ for an optimal policy. At each iteration,  we slightly perturb the values of the current best estimate for the weights $\\theta_{best}$, to yield a new set of weights. These new weights are then used to collect an episode. If the new weights $\\theta_{new}$ resulted in higher return than the old weights, then we set $\\theta_{best} \\leftarrow \\theta_{new}$ .    Beyond Hill Climbing  Steepest ascent hill climbing  a variation of hill climbing that chooses a small number of neighboring policies at each iteration and chooses the best among them.   Simulated annealing  uses a pre-defined schedule to control how the policy space is explored, and gradually reduces the search radius as we get closer to the optimal solution.   Adaptive noise scaling  decreases the search radius with each iteration when a new best policy is found, and otherwise increases the search radius.    More Black-Box Optimization  The cross-entropy method  iteratively suggests a small number of neighboring policies, and uses a small percentage of the best performing policies to calculate a new estimate.   The evolution strategies technique considers the return corresponding to each candidate policy.  The policy estimate at the next iteration is a weighted sum of all of the candidate policies, where policies that got higher return are given higher weight.     Ref  Evolution Strategies as a Scalable Alternative to Reinforcement Learning - OpenAI Open AI classic control environments An overview of gradient descent optimization algorithms  SGD optimization on loss surface contours\nSGD optimization on saddle point\n","excerpt":"Policy-Based Methods  With value-based methods, the agent uses its experience with the environment …","ref":"/docs/machinelearning/courses/reinforcement-learning/c3-policy/p01-intro/","title":"Introduction"},{"body":"\nDeep Q-Learning algorithm   Represents the optimal action-value function $q_*$ as a neural network (instead of a table)\n  Reinforcement learning is unstable when neural networks are used to represent the action values.\n  In this lesson, you\u0026rsquo;ll learn all about the Deep Q-Learning algorithm, which addressed these instabilities by using two key features:\n Experience Replay Fixed Q-Targets    Atari DQN For each Atari game, the DQN was trained from scratch on that game.\n Input: images of game  Images: spatial information Stacked images: capture temporal information   NN:  CNN Fully Connected Layers   Output:  The predicted action values for each possible game action    Experience Replay  Based on the idea that we can learn better, if we do multiple passes over the sample experience To Generate uncorrelated experience data for online training  Fixed Q-Targets  In Q-Learning, we update a guess with a guess, which can potentially lead to harmful correlations To avoid this, we can update the parameters $w$ in the network $\\hat{q}$ to better approximate the action value corresponding to state $S$ and action A with the following update rule  $\\Delta{w} = \\alpha \\Bigl(\\color{#fc8d59} {R + \\gamma max \\hat{q} (S',a, w^-)} - \\color{#4575b4} {\\hat{q}(S,A,w)} \\color{black} {\\Bigr)\\nabla_w \\hat{q}(S,A,w)}$\n TD target:  $\\color{#fc8d59} {R + \\gamma max \\hat{q} (S',a, w^-)}$ $w^-$:  fixed are the weights of a separate target network that are not changed during the learning step,     Current value: $\\color{#4575b4} {\\hat{q}(S,A,w)}$ TD error: $\\Bigl(\\color{#fc8d59} {R + \\gamma max \\hat{q} (S',a, w^-)} - \\color{#4575b4} {\\hat{q}(S,A,w)} \\color{black} {\\Bigr)}$  Why?  Decoupling the target\u0026rsquo;s position from the agent\u0026rsquo;s actions (parameters) Giving the agent a more stable learning environment Making the learning algorithm more stable and less likely to diverge or fall into oscillations.  [Non-fixed target, image from Udacity nd839]\n[Fixed target, image from Udacity nd839]\nDeep Q-Learning  Uses two separate networks with identical architectures The target Q-Network\u0026rsquo;s weights are updated less often (or more slowly) than the primary Q-Network Without fixed Q-targets, we could encounter a harmful form of correlation, whereby we shift the parameters of the network based on a constantly moving target  Illustration of DQN Architecture (Source)\nImprovements  Double DQN   Deep Q-Learning tends to overestimate action values. Double Q-Learning has been shown to work well in practice to help with this.   Prioritized Experience Replay   Deep Q-Learning samples experience transitions uniformly from a replay memory. Prioritized experienced replay is based on the idea that the agent can learn more effectively from some transitions than from others, and the more important transitions should be sampled with higher probability.   Dueling DQN   Currently, in order to determine which states are (or are not) valuable, we have to estimate the corresponding action values for each action. However, by replacing the traditional Deep Q-Network (DQN) architecture with a dueling architecture, we can assess the value of each state, without having to learn the effect of each action.    Learning from multi-step bootstrap targets\n  Distributional DQN\n  Noisy DQN\n  Rainbow\n An agent that incorporated all above six DQN extensions It outperforms each of the individual modifications and achieves state-of-the-art performance on Atari 2600 games!    (Source)\nIn practice  Try different env in openAI and evaluate the performance of Q-Learning Assess trained RL agents to generalize to new tasks   In mid-2018, OpenAI held a contest, where participants were tasked to create an algorithm that could learn to play the Sonic the Hedgehog game. The participants were tasked to train their RL algorithms on provided game levels; then, the trained agents were ranked according to their performance on previously unseen levels.\n  One of the provided baseline algorithms was Rainbow DQN. If you\u0026rsquo;d like to play with this dataset and run the baseline algorithms, you\u0026rsquo;re encouraged to follow the setup instructions.\n    Reading Papers Questions  What kind of tasks are the authors using deep reinforcement learning (RL) to solve? What are the states, actions, and rewards? What neural network architecture is used to approximate the action-value function? How are experience replay and fixed Q-targets used to stabilize the learning algorithm? What are the results?  Papers   Riedmiller, Martin. \u0026ldquo;Neural fitted Q iteration–first experiences with a data efficient neural reinforcement learning method.\u0026quot; European Conference on Machine Learning. Springer, Berlin, Heidelberg, 2005.\n  Mnih, Volodymyr, et al. \u0026ldquo;Human-level control through deep reinforcement learning\u0026rdquo; Nature518.7540 (2015): 529.\n  van Hasselt, Guez, Silver \u0026ldquo;Deep Reinforcement Learning with Double Q-learning\u0026rdquo; arXiv (2015)\n  Thrun, Schwartz. \u0026ldquo;Issues in Using Function Approximation for Reinforcement Learning\u0026rdquo; (1993)\n  Schaul, Quan, Antonoglou, Silver. \u0026ldquo;Prioritized Experience Replay\u0026rdquo; arXiv (2016)\n  Wang, Schaul, et. al. \u0026ldquo;Dueling Network Architectures for Deep Reinforcement Learning\u0026rdquo; arXiv (2015)\n  Hessel, Modayil, et. al. \u0026ldquo;Rainbow: Combining Improvements in Deep Reinforcement Learning\u0026rdquo; arXiv (2017)\n  ","excerpt":"Deep Q-Learning algorithm   Represents the optimal action-value function $q_*$ as a neural network …","ref":"/docs/machinelearning/courses/reinforcement-learning/c2-value/dqn/","title":"DQN"},{"body":"\nApplication   Game\n Backgammon game  10 - 20 game state TD-Gammon: the 1st NN that advanced the theroy of Backgammon by discovering strategies previously unkown   Atari breakout Dota2  OpenAI   AlphaGo    Robotics\n Walk  Producing flexible behaviours in simulated environments   Driving    Other:\n Biology Telecommunications  Low Power Wireless Communication via Reinforcement Learning    Finance  Introduction to Learning to Trade with Reinforcement Learning   Inventory management  Inventory management in supply chains: a reinforcement learning approach      Exploration-Exploitation Dilemma Managing the Exploration-Exploitation Dilemma, image from 52Aces\n","excerpt":"Application   Game\n Backgammon game  10 - 20 game state TD-Gammon: the 1st NN that advanced the …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f01-intro/","title":"Introduction"},{"body":"\nUdacity LICENSE As a condition of accessing or using any of the Services and/or Online Courses, you are, prohibited from undertaking, and agree not to: (a) violate any applicable laws, regulations, or rules; (b) set up multiple User Accounts, (c) reproduce, duplicate, copy, sell, resell, display, publish, transfer, distribute, create derivative works of, or exploit for any commercial purposes any portion of the Services, the Online Courses, any Content (as defined below), or any other aspect of our operations, other than as expressly allowed under this Terms of Use; (d) reverse-engineer, decompile, disassemble or otherwise access the source code for any software that may be used to operate the Services; (e) use Udacity’s name, trademarks, service marks, or other materials in connection with, or to transmit, any unsolicited communications or emails; (f) use any high volume, automated, electronic, or third party means to access the Services including without limitation robots, crawlers, browser plug-ins, browser extensions, spiders, or scripts (“Add-ons”)); (g) frame the Services, place pop-up windows over its pages, or otherwise affect the display of its pages; (h) falsely state, impersonate, or otherwise misrepresent your identity, including but not limited to the use of a pseudonym or misrepresenting your affiliations with a person or entity, past or present; (i) force headers or otherwise manipulate identifiers in order to disguise the origin of any communication transmitted through the Services; (j) directly, or through any Add-ons, scrape any part of the Websites and/or Services; and/or (k) interfere with or disrupt the Services or servers or networks connected to the Services, or disobey any requirements, procedures, policies or regulations of networks connected to the Services.\nIn addition, you may not post, upload, or transmit to or otherwise make available through the Services any content, communications, or other information (collectively, \u0026ldquo;Unauthorized Content\u0026rdquo;):\nthat is obscene, fraudulent, indecent, or libelous or that defames, abuses, harasses, discriminates against or threatens others; that contains any viruses, Trojan horses, worms, time bombs, cancelbots, or other disabling devices or other harmful components intended to or that may damage, detrimentally interfere with, surreptitiously intercept, or expropriate any system, data, or personal information that you do not have the right to disclose or make available under any law or under contractual or fiduciary relationships (such as insider information, or proprietary and confidential information learned or disclosed as part of employment relationships or under nondisclosure agreements); that infringes the copyright, patent, trademark, trade secret, right of publicity, or other intellectual property or proprietary right of any third party; that violates the rights of other Users of the Services; or that violates any applicable local, state, national or international law or otherwise advocates or encourages any illegal activity.\n","excerpt":"Udacity LICENSE As a condition of accessing or using any of the Services and/or Online Courses, you …","ref":"/docs/machinelearning/courses/reinforcement-learning/license-udacitycourse/","title":"LICENSE"},{"body":"\nunit test import unittest class TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual(\u0026#39;foo\u0026#39;.upper(), \u0026#39;FOO\u0026#39;) def test_isupper(self): self.assertTrue(\u0026#39;FOO\u0026#39;.isupper()) self.assertFalse(\u0026#39;Foo\u0026#39;.isupper()) def test_split(self): s = \u0026#39;hello world\u0026#39; self.assertEqual(s.split(), [\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;]) # s.split should throw when the separator is not a string with self.assertRaises(TypeError): s.split(2) unittest.main(exit=False) pytest import pytest def test_upper(): assert \u0026#39;foo\u0026#39;.upper() == \u0026#39;FOO\u0026#39; def test_isupper(): assert \u0026#39;FOO\u0026#39;.isupper() assert not \u0026#39;Foo\u0026#39;.isupper() def test_split(): s = \u0026#39;hello world\u0026#39; assert s.split() == [\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;] # s.split should throw when the separator is not a string with pytest.raises(TypeError): s.split(2) pytest.main() Mock mock is also available if you need to stub out some behavior.\nfrom mock import Mock mock = Mock() mock.method(1, 2, 3) mock.method.assert_called_with(\u0026#39;this should break\u0026#39;) Hypothesis hypothesis is available for property-based testing in Python.\nfrom hypothesis import given from hypothesis.strategies import text def encode(string): # return encoded string def decode(string): # return decoded string @given(text()) def test_decode_inverts_encode(s): assert decode(encode(s)) == s test_decode_inverts_encode() ","excerpt":"unit test import unittest class TestStringMethods(unittest.TestCase): def test_upper(self): …","ref":"/docs/coding/functional-coding/python/testing/","title":"Testing"},{"body":"\nRead  Best RESTful API Practices and Tools   ","excerpt":"\nRead  Best RESTful API Practices and Tools   ","ref":"/docs/cloud/devops/api/","title":"API"},{"body":"\nFlax  A neural network ecosystem for JAX designed for flexibility\n  What makes Flax a rising star in Machine learning? 🤩  It\u0026rsquo;s a fast, lightweight and highly customizable ML framework   Doc GitHub Google’s Approach To Flexibility In Machine Learning Shakespeare Meets Google’s Flax  Overview   Neural network API (flax.linen): Dense, Conv, {Batch|Layer|Group} Norm, Attention, Pooling, {LSTM|GRU} Cell, Dropout\n  Optimizers (flax.optim): SGD, Momentum, Adam, LARS, Adagrad, LAMB, RMSprop\n  Utilities and patterns: replicated training, serialization and checkpointing, metrics, prefetching on device\n  Educational examples that work out of the box: MNIST, LSTM seq2seq, Graph Neural Networks, Sequence Tagging\n  Fast, tuned large-scale end-to-end examples: CIFAR10, ResNet on ImageNet, Transformer LM1b\n  What does Flax look like? We provide here two examples using the Flax API: a simple multi-layer perceptron and a CNN. To learn more about the Module abstraction, please check our docs.\nclass SimpleMLP(nn.Module): \u0026#34;\u0026#34;\u0026#34; A MLP model \u0026#34;\u0026#34;\u0026#34; features: Sequence[int] @nn.compact def __call__(self, x): for i, feat in enumerate(self.features): x = nn.Dense(feat)(x) if i != len(self.features) - 1: x = nn.relu(x) return x class CNN(nn.Module): \u0026#34;\u0026#34;\u0026#34;A simple CNN model.\u0026#34;\u0026#34;\u0026#34; @nn.compact def __call__(self, x): x = nn.Conv(features=32, kernel_size=(3, 3))(x) x = nn.relu(x) x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) x = nn.Conv(features=64, kernel_size=(3, 3))(x) x = nn.relu(x) x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) x = x.reshape((x.shape[0], -1)) # flatten x = nn.Dense(features=256)(x) x = nn.relu(x) x = nn.Dense(features=10)(x) x = nn.log_softmax(x) return x Ref  Flax GitHub  ","excerpt":"Flax  A neural network ecosystem for JAX designed for flexibility\n  What makes Flax a rising star in …","ref":"/docs/machinelearning/frameworks/flax/flax/","title":"Flax"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/frameworks/flax/","title":"JAX"},{"body":"\nMLOps (Machine Learning Operations) Fundamentals  Offered by Coursera and Google Cloud  ","excerpt":"\nMLOps (Machine Learning Operations) Fundamentals  Offered by Coursera and Google Cloud  ","ref":"/docs/cloud/devops/course/","title":"Courses"},{"body":"\nCS Courses  Computer Science 101   Six weeks The nature of computers and code, what they can and cannot do\n How computer hardware works: chips, cpu, memory, disk Necessary jargon: bits, bytes, megabytes, gigabytes How software works: what is a program, what is \u0026ldquo;running\u0026rdquo; How digital images work Computer code: loops and logic Big ideas: abstraction, logic, bugs How structured data works How the internet works: ip address, routing, ethernet, wi-fi Computer security: viruses, trojans, and passwords, oh my! Analog vs. digital Digital media, images, sounds, video, compression    CS50\u0026rsquo;s Web Programming with Python and JavaScript    This course picks up where Harvard University\u0026rsquo;s CS50 leaves off, diving more deeply into the design and implementation of web apps with Python, JavaScript, and SQL using frameworks like Flask, Django, and Bootstrap. Topics include database design, scalability, security, and user experience. Through hands-on projects, students learn to write and use APIs, create interactive UIs, and leverage cloud services like GitHub and Heroku. By course\u0026rsquo;s end, students emerge with knowledge and experience in principles, languages, and tools that empower them to design and deploy applications on the Internet.    CS50\u0026rsquo;s Introduction to Computer Science   11 weeks\n A broad and robust understanding of computer science and programming How to think algorithmically and solve programming problems efficiently Concepts like abstraction, algorithms, data structures, encapsulation, resource management, security, software engineering, and web development Familiarity in a number of languages, including C, Python, SQL, and JavaScript plus CSS and HTML How to engage with a vibrant community of like-minded learners from all levels of experience How to develop and present a final programming project to your peers     Teach Yourself Computer Science\n  Microsoft Web Dev For Beginners\n  Ref  How to Hack Together Your Own CS Degree Online  ","excerpt":"CS Courses  Computer Science 101   Six weeks The nature of computers and code, what they can and …","ref":"/docs/computer_science/cs/","title":"Courses"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/models/feature/","title":"Feature Selection"},{"body":"\nHow to Choose a Feature Selection Method For Machine Learning?  Tutorial Overview of Feature Selection Techniques Image from Jason Brownlee    How to choose a feature selection method?\n[Image from Jason Brownlee](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/\n  ","excerpt":"\nHow to Choose a Feature Selection Method For Machine Learning?  Tutorial Overview of Feature …","ref":"/docs/machinelearning/models/feature/feature-selection/","title":"Feature Selection"},{"body":"\nImage is copied from Next we have a maturity model that has never been shown publicly before to my knowledge; it appears to have sprung fully formed from the forehead of some god. pic.twitter.com/7PrKVKhTBG\n\u0026mdash; Corey Quinn (@QuinnyPig) November 13, 2020  ","excerpt":"\nImage is copied from Next we have a maturity model that has never been shown publicly before to my …","ref":"/docs/cloud/devops/model/","title":"Model"},{"body":"\nData Frame EDA Packages  pandas profiling sweetviz pandasgui  ","excerpt":"\nData Frame EDA Packages  pandas profiling sweetviz pandasgui  ","ref":"/docs/data/visual-art/eda/","title":"EDA"},{"body":"\nAlgebra  Linear algebra is the study of vectors and certain rules to manipulate vectors. Vectors: are special objects that can be added together and multiplied by scalars to produce another object of the same kind.  Examples  Geometric vectors Polynomials Audio signals Elements of $\\Bbb{R}^n $(tuples of $n$ real numebers)     Geometric Interpretation of Systems of Linear Equatiion  In a system of linear equations  with two variables x1, x2, each linear equation defines a line on the x1x2-plane. with three variables, x1, x2, x3, each linear equation defines a plane in three-dimensional space.  When we intersect these planes, i.e., satisfy all linear equations at the same time, we can obtain a solution set that is a plane, a line, a point or empty (when the planes have no common intersection).        Matrices  A central role in linear algebra  used to compactly represent systems of linear equations represent linear functions (linear mappints)   Matrix Matrix addtion Matrix multiplication Hadamard product: element-wise product. It is a binary operation that takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices. Matrix product Identity matrix: $n × n$-matrix containing $1$ on the diagonal and $0$ everywhere else Matrix properties  Associativity Distributivity Multiplication with the identity matrix    Image from jconlineimagem\n","excerpt":"Algebra  Linear algebra is the study of vectors and certain rules to manipulate vectors. Vectors: …","ref":"/docs/math/machinelearning/02linear_algebra/","title":"Linear Algebra"},{"body":"Read  Paul\u0026rsquo;s notes at Lamar University A Gentle Introduction To Graph Theory Comprehensive \u0026amp; Practical Inferential Statistics Guide for data science Probability and statistics, MIT Mathematics for Computer Science, MIT  ","excerpt":"Read  Paul\u0026rsquo;s notes at Lamar University A Gentle Introduction To Graph Theory Comprehensive …","ref":"/docs/math/intro/","title":"Introduction"},{"body":"\nProbability and Life  Genetics Finance History  Mosteller \u0026amp; Wallace Apply Computing in Disputed Authorship Investigation of The Federalist Papers   Games  Fermat and Pascal Letters  The problem of points, also called the problem of division of the stakes, is a classical problem in probability theory. One of the famous problems that motivated the beginnings of modern probability theory in the 17th century, it led Blaise Pascal to the first explicit reasoning about what today is known as an expected value.     Game theory  The study of mathematical models of strategic interaction among rational decision-makers.    What is a sample space S? The set of all possible outcomes of a (random) experiment.\nWhat is an event? A subset of the sample space.\nWhat is probability?  The very naive definition of $P_{(A)}$  Number of favorable outcomes $A$ divided by all possible outcomes Assumptions:  all outcomes are equally likely the sample space is finite     The non-naive definition $P_{(A)}$ or Probability Axioms  A function which takes an input, event $A$, a subset of sample space $S$, returns $P_{(A)} \\in [0,1]$ as an output, such that  the probability of the empty set $P_{\\varnothing} = 0$  An event that is impossible to happy   the probability of the full set $P_{S} = 1$  Certainty: a guaranteed event that always happens   the probability of a countable infinite union equals to the sum of the probabilities of $A_1$,$A_2$,\u0026hellip;, $A_n$ if they are disjoined (non-overlapping)  $P_{(\\bigcup_{i=1}^{\\infty} A_{n})} = \\sum_{n=1}^{\\infty}P_{A_n}$        What are some basic principles of counting?   Multiplication rules:\n Independent events assuming  $P_{(A and B)}=P_{(A)}⋅P_{(B)}$   The general rule  $P_{(A and B)}=P_{(A)}⋅P_{(B|A)}$ If the events are independent, one happening doesn\u0026rsquo;t impact the probability of the other, and in that case $P_{(B|A)}=P_{(B)}$      Binomial coefficient\t$\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ = $\\frac{n(n-1)(n-2)(n-k+1)}{k!}$\n Example, what is the probability of having a full house card? (A full house has three cards of one kind and two of another) First you choose a type of card (13 choices), then you choose three out of four of those cards, then you choose a second type of card, and finally you choose two of those four cards. $P = \\frac{\\binom{13}{1} \\cdot \\binom{4}{3} \\cdot \\binom{12}{1 }\\binom{4}{2}} {\\binom{52}{5}} \\approx 0.00144 $    How to choose $k$ objects out of $n$?  Sampling table      Order matters Order doesn\u0026rsquo;t matter     Without replacement S1: $n(n-1)\u0026hellip;(n-k+1)$ S3: $\\binom{n}{k}$   With replacement S2: $n^k$ S4:$\\binom{n+k-1}{k}$     S1: The number of choices reduces every time S2: $n$ choices each time S3: $n$ choose $k$: think about how you choose the ice cream flavor and cones S4:  Simple trivial cases  $k = 0$:  $P = \\binom{n-1}{0} = 1$ not choosing is also a choice   $k = 1$:  $P = \\binom{n}{1} = n$ you only choose once, there\u0026rsquo;s no difference whether there\u0026rsquo;s order or replacement     Simple non-trivial cases  $n = 2$:  $P = \\binom{k+1}{k} = \\binom{k+1}{1} = k + 1$ put $k$ particles in two boxes     General cases  how many ways are there to put $k$ indistinguishable particles in $n$ distinguishable boxes? convert the question to a \u0026ldquo;dot and separator\u0026rdquo; code $\\binom{n+k-1}{k}$: $n+k-1$ positions, choose $k$ positions to put the dots the same as $\\binom{n+k-1}{n-1}$: $n+k-1$ positions, choose $n-1$ positions to put the seperators e.g.  $n= 4$, $k=6$ $\\cdot\\cdot|\\cdot|\\cdot|\\cdot\\cdot$ 6 dots and 3 separators = 9 positions choose 6 positions to put the dots the same as choose 3 positions to put the seperators        Image Source\n Ref  Lecture 1: Probability and Counting | Statistics 110  GitHub notes The book provided by authors edx course   Financial Theory (ECON 251) An Introduction to Quantitative Finance by Stephen Blyth   Terms  Bose-Einstein condensate (BEC)   In condensed matter physics, a Bose–Einstein condensate (BEC) is a state of matter (also called the fifth state of matter) which is typically formed when a gas of bosons at low densities is cooled to temperatures very close to absolute zero (-273.15 °C, -459.67 °F). Under such conditions, a large fraction of bosons occupy the lowest quantum state, at which point microscopic quantum mechanical phenomena, particularly wavefunction interference, become apparent macroscopically. A BEC is formed by cooling a gas of extremely low density (about one-hundred-thousandth (1/100,000) the density of normal air) to ultra-low temperatures. This state was first predicted, generally, in 1924–1925 by Albert Einstein following and crediting a pioneering paper by Satyendra Nath Bose on the new field now known as quantum statistics.\n  Quantum statistics   In quantum statistics, Bose–Einstein (B–E) statistics describe one of two possible ways in which a collection of non-interacting, indistinguishable particles may occupy a set of available discrete energy states at thermodynamic equilibrium.\n ","excerpt":"Probability and Life  Genetics Finance History  Mosteller \u0026amp; Wallace Apply Computing in Disputed …","ref":"/docs/math/intro/probability/s110_l01_probability_and_counting/","title":"Probability and Counting"},{"body":"\nAdaBelief Optimizer  Trains fast as Adam, generalizes well as SGD, and is stable to train GANs.\n  GitHub  pip install adabelief-tf==0.0.1 from adabelief_tf impoty AdaBeliefOptimizer optimizer = AdaBeliefOptimizer(learning_rate, epsilon=1e-12) \nWatch  Optimization  ","excerpt":"\nAdaBelief Optimizer  Trains fast as Adam, generalizes well as SGD, and is stable to train GANs. …","ref":"/docs/machinelearning/frameworks/tensorflow/optimizer/","title":"Optimizer"},{"body":"\n Course Link\n Data can be stored and accessed in many different ways, both in JavaScript and other languages. This section will teach you how to\n manipulate arrays and access and copy the information within them ⚒ manipulate and access the data within JavaScript objects, using  dot bracket notation    When you\u0026rsquo;re done with this section, you should understand the basic properties and differences between arrays and objects, as well as how to choose which to use for a given purpose.\n","excerpt":"Course Link\n Data can be stored and accessed in many different ways, both in JavaScript and other …","ref":"/docs/coding/functional-coding/javascript/course/data-structure/intro/","title":"Introduction"},{"body":"\n Course Link\n Debugging is a valuable and (unfortunately) necessary tool for programmers. It follows the testing phase of checking if your code works as intended, and discovering it does not. Debugging is the process of finding exactly what isn\u0026rsquo;t working and fixing it. After spending time creating a brilliant block of code, it is tough realizing it may have errors. These issues generally come in three forms:\n syntax errors that prevent a program from running runtime errors when code fails to execute or has unexpected behavior semantic (or logical) errors when code doesn\u0026rsquo;t do what it\u0026rsquo;s meant to  Modern code editors (and experience) can help identify syntax errors. Semantic and runtime errors are harder to find. They may cause your program to crash, make it run forever, or give incorrect output. Think of debugging as trying to understand why your code is behaving the way it is.\n Example of a syntax error - often detected by the code editor  funtcion willNotWork( console.log(\u0026#34;Yuck\u0026#34;); } // \u0026#34;function\u0026#34; keyword is misspelled and there\u0026#39;s a missing parenthesis  Example of a runtime error - often detected while the program executes:  function loopy() { while(true) { console.log(\u0026#34;Hello, world!\u0026#34;); } } // Calling loopy starts an infinite loop, which may crash your browser  Example of a semantic error - often detected after testing code output:  function calcAreaOfRect(w, h) { return w + h; // This should be w * h } let myRectArea = calcAreaOfRect(2, 3); ","excerpt":"Course Link\n Debugging is a valuable and (unfortunately) necessary tool for programmers. It follows …","ref":"/docs/coding/functional-coding/javascript/course/debugging/intro/","title":"Introduction"},{"body":"\n Course Link\n 1. Using the Test Method to Check Literal Strings  The .test() method takes the regex, applies it to a string (which is placed inside the parentheses), and returns true or false if your pattern finds something or not. Notice that quote marks are not required within the regular expression Case sensitive  let testRegex = /Code/; let testStr = \u0026#34;freeCodeCamp\u0026#34;; testRegex.test(testStr); // Returns true \n2. Match a Literal String with Different Possibilities  Search for multiple patterns using the alternation or OR operator: |, for instance, /yes|no|maybe  let petString = \u0026#34;James has a pet cat.\u0026#34;; let petRegex = /dog|cat|bird|fish/; let result = petRegex.test(petString); \n3. Use flag i to match both upper and lower cases let myString = \u0026#34;Sunflower\u0026#34;; let fccRegex = /sunfower/i; let result = fccRegex.test(myString); result;//true \n4. Extract Matches  Use .match() method and apply the method on a string and pass in the regex inside the parentheses The .match syntax is the \u0026ldquo;opposite\u0026rdquo; of the .test method you have been using thus far  \u0026#39;string\u0026#39;.match(/regex/); /regex/.test(\u0026#39;string\u0026#39;);  Example 1  \u0026#34;Hello, World!\u0026#34;.match(/Hello/); // Returns [\u0026#34;Hello\u0026#34;] let ourStr = \u0026#34;Regular expressions\u0026#34;; let ourRegex = /expressions/; ourStr.match(ourRegex); // Returns [\u0026#34;expressions\u0026#34;]  Example 2  let extractStr = \u0026#34;Extract the word \u0026#39;coding\u0026#39; from this string.\u0026#34;; let codingRegex = /coding/; // Change this line let result = extractStr.match(codingRegex); // Change this line \n5. Use g Flag to Find More Than the First Match  Example  let twinkleStar = \u0026#34;Twinkle, twinkle, little star\u0026#34;; let starRegex = /Twinkle/gi; let result = twinkleStar.match(starRegex); \n6. Match Anything with Wildcard Period  Sometimes you won\u0026rsquo;t (or don\u0026rsquo;t need to) know the exact characters in your patterns. Thinking of all words that match, say, a misspelling would take a long time. Luckily, you can save time using the wildcard character: . The wildcard character . will match any one character. The wildcard is also called dot and period. You can use the wildcard character just like any other character in the regex. For example, if you wanted to match \u0026ldquo;hug\u0026rdquo;, \u0026ldquo;huh\u0026rdquo;, \u0026ldquo;hut\u0026rdquo;, and \u0026ldquo;hum\u0026rdquo;, you can use the regex /hu./ to match all four words Example 1  let humStr = \u0026#34;I\u0026#39;ll hum a song\u0026#34;; let hugStr = \u0026#34;Bear hug\u0026#34;; let huRegex = /hu./; huRegex.test(humStr); // Returns true huRegex.test(hugStr); // Returns true  Example 2  let exampleStr = \u0026#34;Let\u0026#39;s have fun with regular expressions!\u0026#34;; let unRegex = /.un/; // Change this line let result = unRegex.test(exampleStr); \n7. Use Character Sets to Match Single Character with Multiple Possibilities  Search for a literal pattern with some flexibility with character classes, which allow you to define a group of characters you wish to match by placing them inside square brackets [] Example 1  let bigStr = \u0026#34;big\u0026#34;; let bagStr = \u0026#34;bag\u0026#34;; let bugStr = \u0026#34;bug\u0026#34;; let bogStr = \u0026#34;bog\u0026#34;; let bgRegex = /b[aiu]g/; bigStr.match(bgRegex); // Returns [\u0026#34;big\u0026#34;] bagStr.match(bgRegex); // Returns [\u0026#34;bag\u0026#34;] bugStr.match(bgRegex); // Returns [\u0026#34;bug\u0026#34;] bogStr.match(bgRegex); // Returns null  Example 2  let quoteSample = \u0026#34;Beware of bugs in the above code; I have only proved it correct, not tried it.\u0026#34;; let vowelRegex = /[aeiou]/gi; // Change this line let result = quoteSample.match(vowelRegex); // Change this line \n8. Match Letters of the Alphabet  Inside a character set, you can define a range of characters to match using [] and - Example 1  let catStr = \u0026#34;cat\u0026#34;; let batStr = \u0026#34;bat\u0026#34;; let matStr = \u0026#34;mat\u0026#34;; let bgRegex = /[a-e]at/; catStr.match(bgRegex); // Returns [\u0026#34;cat\u0026#34;] batStr.match(bgRegex); // Returns [\u0026#34;bat\u0026#34;] matStr.match(bgRegex); // Returns null  Example 2  let quoteSample = \u0026#34;The quick brown fox jumps over the lazy dog.\u0026#34;; let alphabetRegex = /[a-z]/ig; let result = quoteSample.match(alphabetRegex); \n9. Match Numbers and Letters of the Alphabet  /[0-5]/matches any number between 0 and 5, including the 0 and 5 Combine a range of letters and numbers in a single character set Example 1  let jennyStr = \u0026#34;Jenny8675309\u0026#34;; let myRegex = /[a-z0-9]/ig; // matches all letters and numbers in jennyStr jennyStr.match(myRegex);  Example 2  // Create a single regex that matches a range of letters between h and s, and a range of numbers between 2 and 6. Remember to include the appropriate flags in the regex. let quoteSample = \u0026#34;Blueberry 3.141592653s are delicious.\u0026#34;; let myRegex = /[h-s2-6]/gi; let result = quoteSample.match(myRegex); \n10. Match Single Characters Not Specified  Create a set of characters that you do not want to match. These types of character sets are called negated character sets. Create a negated character set, you place a caret character ^ after the opening bracket and before the characters you do not want to match. /[^aeiou]/gi matches all characters that are not a vowel Note that characters like ., !, [, @, / and white space are matched - the negated vowel character set only excludes the vowel characters Example  let quoteSample = \u0026#34;3 blind mice.\u0026#34;; let myRegex = /[^aeiou0-9]/gi; // Change this line let result = quoteSample.match(myRegex); // Change this line \n11. Match Characters that Occur One or More Times   You can use the + character to check if that is the case. Remember, the character or pattern has to be present consecutively. That is, the character has to repeat one after the other.\n  Example 1\n  /a+/g would find one match in \u0026quot;abc\u0026quot; and return [\u0026quot;a\u0026quot;]. Because of the +, it would also find a single match in \u0026quot;aabc\u0026quot; and return [\u0026quot;aa\u0026quot;].\n  If it were instead checking the string \u0026quot;abab\u0026quot;, it would find two matches and return [\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;] because the a characters are not in a row - there is a b between them.\n    // You want to find matches when the letter s occurs one or more times in \u0026#34;Mississippi\u0026#34;. Write a regex that uses the + sign. let difficultSpelling = \u0026#34;Mississippi\u0026#34;; let myRegex = /s+/g; // Change this line let result = difficultSpelling.match(myRegex); \n12. Match Characters that Occur Zero or More Times using *  Example 1  let soccerWord = \u0026#34;gooooooooal!\u0026#34;; let gPhrase = \u0026#34;gut feeling\u0026#34;; let oPhrase = \u0026#34;over the moon\u0026#34;; let goRegex = /go*/; soccerWord.match(goRegex); // Returns [\u0026#34;goooooooo\u0026#34;] gPhrase.match(goRegex); // Returns [\u0026#34;g\u0026#34;] oPhrase.match(goRegex); // Returns null  Example 2  // Create a regex chewieRegex that uses the * character to match an uppercase \u0026#34;A\u0026#34; character immediately followed by zero or more lowercase \u0026#34;a\u0026#34; characters in chewieQuote. Your regex does not need flags or character classes, and it should not match any of the other quotes. let chewieRegex = /A0*a+/; // Change this line  let result = chewieQuote.match(chewieRegex); \n","excerpt":"Course Link\n 1. Using the Test Method to Check Literal Strings  The .test() method takes the regex, …","ref":"/docs/coding/functional-coding/javascript/course/regular-expression/part1/","title":"Part 1"},{"body":"\nVariables  1.Always declare an variable with the var keyword explicitly   Variable name can be\n letters: case sensitive numbers symbols $ and _    Use camelCase for mutable variables: multi-word variable names have the first word in lowercase and the first letter of each subsequent word is capitalized\nvar anOrdinaryMan     Use const keywor to name variables you don\u0026rsquo;t want to reassign   Use all uppercase letters for immutable variables, with words separated by an underscore.    ","excerpt":"Variables  1.Always declare an variable with the var keyword explicitly   Variable name can be …","ref":"/docs/coding/functional-coding/javascript/practices/best-practices/","title":"Best practices"},{"body":"\n Course Link\n What is ES? ECMAScript is a standardized version of JavaScript with the goal of unifying the language\u0026rsquo;s specifications and features. As all major browsers and JavaScript-runtimes follow this specification, the term ECMAScript is interchangeable with the term JavaScript.\nThe most recent standardized version is called ECMAScript 6 (ES6), released in 2015. This new version of the language adds some powerful features including:\n Arrow functions Classes Modules Promises Generators let and const  1. Explore Differences Between the var and let Keywords  Why was let added as a keyword?  A variable with the same name can only be declared once using let    // var var camper = \u0026#39;James\u0026#39;; var camper = \u0026#39;David\u0026#39;; console.log(camper); // logs \u0026#39;David\u0026#39;  //let let camper = \u0026#39;James\u0026#39;; let camper = \u0026#39;David\u0026#39;; // throws an error   Compare Scopes of the var and let Keywords\n  When you declare a variable with the var keyword, it is declared globally, or locally if declared inside a function.\n  The let keyword behaves similarly, but with some extra features. When you declare a variable with the let keyword inside a block, statement, or expression, its scope is limited to that block, statement, or expression.\n    var numArray = []; for (var i = 0; i \u0026lt; 3; i++) { numArray.push(i); } console.log(numArray); // returns [0, 1, 2] console.log(i); // returns 3 is similar to\nvar numArray = []; var i; for (i = 0; i \u0026lt; 3; i++) { numArray.push(i); } console.log(numArray); // returns [0, 1, 2] console.log(i); // returns 3 however, this can cause issues\nvar printNumTwo; for (var i = 0; i \u0026lt; 3; i++) { if (i === 2) { printNumTwo = function() { return i; }; } } console.log(printNumTwo()); // returns 3 let can fix it!\n\u0026#39;use strict\u0026#39;; let printNumTwo; for (let i = 0; i \u0026lt; 3; i++) { if (i === 2) { printNumTwo = function() { return i; }; } } console.log(printNumTwo()); // returns 2 console.log(i); // returns \u0026#34;i is not defined\u0026#34; \n2. What is use strict? The \u0026ldquo;use strict\u0026rdquo; enables Strict Mode, which catches common coding mistakes and \u0026ldquo;unsafe\u0026rdquo; actions.\n Example 1  \u0026#34;use strict\u0026#34;; x = 3.14; // throws an error because x is not declared  Example 2  let catName; let quote; function catTalk() { \u0026#34;use strict\u0026#34;; catName = \u0026#34;Oliver\u0026#34;; quote = catName + \u0026#34; says Meow!\u0026#34;; } catTalk(); \n3. Declare a Read-Only Variable with the const Keyword  const has all the awesome features that let has, with the added bonus that variables declared using const are read-only. They are a constant value, which means that once a variable is assigned with const, it cannot be reassigned You should always name variables you don\u0026rsquo;t want to reassign using the const keyword  function printManyTimes(str) { \u0026#34;use strict\u0026#34;; // Only change code below this line  const END_WORDS = \u0026#34; is cool!\u0026#34;; const SENTENCE = str + END_WORDS; for (let i = 0; i \u0026lt; str.length; i+=2) { console.log(SENTENCE); } // Only change code above this line } printManyTimes(\u0026#34;freeCodeCamp\u0026#34;); \n4. Mutate an Array Declared with const  Objects (including arrays and functions) assigned to a variable using const are still mutable. Using the const declaration only prevents reassignment of the variable identifier.  \u0026#34;use strict\u0026#34;; const s = [5, 6, 7]; s = [1, 2, 3]; // throws error, trying to assign a const s[2] = 45; // works just as it would with an array declared with var or let console.log(s); // returns [5, 6, 45] \n5. Prevent Object Mutation  To ensure your data doesn\u0026rsquo;t change, JavaScript provides a function Object.freeze to prevent data mutation ❄️ Once the object is frozen, you can no longer add, update, or delete properties from it. Any attempt at changing the object will be rejected without an error.  function freezeObj() { \u0026#39;use strict\u0026#39;; const MATH_CONSTANTS = { PI: 3.14 }; // Only change code below this line  Object.freeze(MATH_CONSTANTS); // Only change code above this line  try { MATH_CONSTANTS.PI = 99; } catch(ex) { console.log(ex); } return MATH_CONSTANTS.PI; } const PI = freezeObj(); \n5. Use Arrow Functions to Write Concise Anonymous Functions ➡️   In JavaScript, we often don\u0026rsquo;t need to name our functions, especially when passing a function as an argument to another function.\n  Instead, we create inline functions. We don\u0026rsquo;t need to name these functions because we do not reuse them anywhere else.\n  Example 1\n  const myFunc = function() { const myVar = \u0026#34;value\u0026#34;; return myVar; } // ES6 provides us with the syntactic sugar to not have to write anonymous functions this way. Instead, you can use arrow function syntax: const myFunc = () =\u0026gt; \u0026#34;value\u0026#34;;  Example 2  const magic = () =\u0026gt; { \u0026#34;use strict\u0026#34;; return new Date(); }; \n6. Write Arrow Functions with Parameters ➡️  Just like a regular function, you can pass arguments into an arrow function If an arrow function has a single argument, the parentheses enclosing the argument may be omitted  // doubles input value and returns it const doubler = (item) =\u0026gt; item * 2; // or // the same function, without the argument parentheses const doubler = item =\u0026gt; item * 2;  It is possible to pass more than one argument into an arrow function  // multiplies the first input value by the second and returns it const multiplier = (item, multi) =\u0026gt; item * multi;  Example: write the myConcat function which appends contents of arr2 to arr1 so that the function uses arrow function syntax  const myConcat = (arr1, arr2) =\u0026gt; { \u0026#34;use strict\u0026#34;; arr1.concat(arr2) } console.log(myConcat([1, 2], [3, 4, 5])); \n7. Set Default Parameters for Your Functions  In order to help us create more flexible functions, ES6 introduces default parameters for functions  const greeting = (name = \u0026#34;Anonymous\u0026#34;) =\u0026gt; \u0026#34;Hello \u0026#34; + name; console.log(greeting(\u0026#34;John\u0026#34;)); // Hello John console.log(greeting()); // Hello Anonymous // Create an increment function by adding default parameters so that it will add 1 to number if value is not specified const increment = (number, value=1) =\u0026gt; number + value; \n8. Use the Rest Parameter ...args with Function Parameters  In order to help us create more flexible functions, ES6 introduces the rest parameter for function parameters. With the rest parameter, you can create functions that take a variable number of arguments. These arguments are stored in an array that can be accessed later from inside the function. The rest parameter eliminates the need to check the args array and allows us to apply map(), filter() and reduce() on the parameters array Example  const sum = (x, y, z) =\u0026gt; { const args = [x, y, z]; return args.reduce((a, b) =\u0026gt; a + b, 0); } // can be rewritten as const sum(...args){ return args.reduce((a,b) =\u0026gt; a+b,0) } \n9. Use the Spread Operator to Evaluate Arrays In-Place  The spread operator allows us to expand arrays and other expressions in places where multiple parameters or elements are expected  // ES5: We had to use Math.max.apply(null, arr) because Math.max(arr) returns NaN. Math.max() expects comma-separated arguments, but not an array. var arr = [6, 89, 3, 45]; var maximus = Math.max.apply(null, arr); // returns 89  // ES6: ...arr returns an unpacked array. In other words, it spreads the array. const arr = [6, 89, 3, 45]; const maximus = Math.max(...arr); // returns 89  The spread operator only works in-place, like in an argument to a function or in an array literal. The following code will not work:  const spreaded = ...arr; // will throw a syntax error  Example  const arr1 = [\u0026#39;JAN\u0026#39;, \u0026#39;FEB\u0026#39;, \u0026#39;MAR\u0026#39;, \u0026#39;APR\u0026#39;, \u0026#39;MAY\u0026#39;]; let arr2; arr2 = []; // Change this line  console.log(arr2); // rewritten as (function() { \u0026#34;use strict\u0026#34;; arr2 = [...arr1]; // change this line })(); \n10. Use Destructuring Assignment to Extract Values from Objects  Destructuring assignment is special syntax introduced in ES6, for neatly assigning values taken directly from an object You can extract as many or few values from the object as you want Example 1  //ES5 const user = { name: \u0026#39;John Doe\u0026#39;, age: 34 }; const name = user.name; // name = \u0026#39;John Doe\u0026#39; const age = user.age; // age = 34  //ES6 const { name, age } = user; // name = \u0026#39;John Doe\u0026#39;, age = 34 // Here, the name and age variables will be created and assigned the values of their respective values from the user object. You can see how much cleaner this is.  Example 2  const HIGH_TEMPERATURES = { yesterday: 75, today: 77, tomorrow: 80 }; // Only change code below this line const {today, tomorrow} = HIGH_TEMPERATURES; // Only change code above this line \n11. Use Destructuring Assignment to Assign Variables from Objects  Destructuring allows you to assign a new variable name when extracting values. You can do this by putting the new name after a colon when assigning the value. Example 1  const user = { name: \u0026#39;John Doe\u0026#39;, age: 34 }; //ES6 const { name: userName, age: userAge } = user; // userName = \u0026#39;John Doe\u0026#39;, userAge = 34 \n12. Use Destructuring Assignment to Assign Variables from Nested Objects const user = { johnDoe: { age: 34, email: \u0026#39;johnDoe@freeCodeCamp.com\u0026#39; } }; // ES6 // extract the values of object properties and assign them to variables with the same name const { johnDoe: { age, email }} = user; // assign an object properties\u0026#39; values to variables with different names const { johnDoe: { age: userAge, email: userEmail }} = user;  Example 2  const LOCAL_FORECAST = { yesterday: { low: 61, high: 75 }, today: { low: 64, high: 77 }, tomorrow: { low: 68, high: 80 } }; const {today:{low:lowToday, high:highToday}} = LOCAL_FORECAST \n13. Use Destructuring Assignment to Assign Variables from Arrays  One key difference between the spread operator and array destructuring is that:  the spread operator unpacks all contents of an array into a comma-separated list. Consequently, you cannot pick or choose which elements you want to assign to variables.    // Destructuring an array lets us do exactly that: const [a, b] = [1, 2, 3, 4, 5, 6]; console.log(a, b); // 1, 2  // We can also access the value at any index in an array with destructuring by using commas to reach the desired index const [a, b,,, c] = [1, 2, 3, 4, 5, 6]; console.log(a, b, c); // 1, 2, 5  Exmple 2  let a = 8, b = 6; // Use destructuring assignment to swap the values of a and b so that a receives the value stored in b, and b receives the value stored in a. // Only change code below this line [a,b ]=[b,a]; // Do not try to re-declare a or b while destructuring as they are already declared in the first let statement. \n14. Use Destructuring Assignment with the Rest Parameter to Reassign Array Elements  In some situations involving array destructuring, we might want to collect the rest of the elements into a separate array The result is similar to Array.prototype.slice(), as shown below The rest element only works correctly as the last variable in the list. As in, you cannot use the rest parameter to catch a subarray that leaves out the last element of the original array. Example 1  const [a, b, ...arr] = [1, 2, 3, 4, 5, 7]; console.log(a, b); // 1, 2 console.log(arr); // [3, 4, 5, 7]  Example 2  const source = [1,2,3,4,5,6,7,8,9,10]; function removeFirstTwo(list) { \u0026#34;use strict\u0026#34;; // Only change code below this line  const [a, b,...arr] = list; // Only change code above this line  return arr; } const arr = removeFirstTwo(source); \n15. Use Destructuring Assignment to Pass an Object as a Function\u0026rsquo;s Parameters  In some cases, you can destructure the object in a function argument itself This removes some extra lines and makes our code look neat This has the added benefit of not having to manipulate an entire object in a function — only the fields that are needed are copied inside the function Example 1  const profileUpdate = (profileData) =\u0026gt; { const { name, age, nationality, location } = profileData; // do something with these variables } //ES6 const profileUpdate = ({ name, age, nationality, location }) =\u0026gt; { /* do something with these fields */ } //  Example 2  const stats = { max: 56.78, standard_deviation: 4.34, median: 34.54, mode: 23.87, min: -0.75, average: 35.85 }; // Only change code below this line const half = (stats) =\u0026gt; (stats.max + stats.min) / 2.0; // Only change code above this line  //ES6 const stats = { max: 56.78, standard_deviation: 4.34, median: 34.54, mode: 23.87, min: -0.75, average: 35.85 }; // Only change code below this line const half = ({ max, min }) =\u0026gt; (max + min) / 2.0; // Only change code above this line ","excerpt":"Course Link\n What is ES? ECMAScript is a standardized version of JavaScript with the goal of …","ref":"/docs/coding/functional-coding/javascript/course/es6/part1/","title":"Part 1"},{"body":"\nJavaScript Algorithm and Data Structures Certification by FreeCodeCamp\n","excerpt":"JavaScript Algorithm and Data Structures Certification by FreeCodeCamp","ref":"/docs/coding/functional-coding/javascript/course/","title":"Course"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/course/basics/","title":"Basics"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/practices/","title":"Practices"},{"body":"\n Course Link\n 1. Basic JavaScript   How to comment?\n//exactitude  /* hi, how is the novel?*/   2. Seven Data types  undefined: declared variables without values null symbol boolean string: immutable number object  3. Numeric variable   Store a value in a variable\nvar q = 1.1   Value Operator\n  Increment and decrement\ni = 19 i++ // is the equivalent of i = i + 1  i-- // is the equivalent of i = i - 1   Remainder operator %\n17 % 2 = 1 // 17 is odd 18 % 2 = 0 // 18 is even   Compound assignment With augmented addition, substraction, multiplication and devision\nvar a = 90; a += 9; // this is equal to a = a + 9; a -= 9; // this is equal to a = a -9; a *= 9; // this is eqaul to a = a * 9; a /= 9; // this is equal to a = a / 9;     4. String variable var p = \u0026#34;Mauriat\u0026#34;; # Escaping Literal Quotes in Strings var p = \u0026#34;Mauriat said, \\\u0026#34;I worked as an arranger for other artists \\\u0026#34;.\u0026#34;; # Quoting Strings with Single Quotes var myStr = \u0026#39;\u0026lt;a href=\u0026#34;http://www.example.com\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Link\u0026lt;/a\u0026gt;\u0026#39;; # Escape Sequences in Strings var myStr = \u0026#39;FirstLine\\n\\t\\\\SecondLine\\nThirdLine\u0026#39;; // Change this line  Escaping characters     Code Output     -' single quote   -\u0026quot; double quote   -\\ backslash   -\\n newline   -\\r carriage return   -\\t tab   -\\b word boundary   -\\f form feed     Concatenating Strings with plus operator, plus equals operator  var myWords = \u0026#34;I hear \u0026#34; + \u0026#34;you say: \u0026#34;; var myWords += \u0026#34;It\u0026#39;s gonna be OK\u0026#34;;  Find the lenth of a String  var myWordseLength = myWords.length;  Use bracket notation to find the first/last character in a string  var firstLetter = myWords[0]; var lastLetter = myWords[myWords.length-1]; var thirdToLastLetter = myWords[myWords.length - 3]; \n5. Array variable  Store multiple values in one variable using JavaScript arrays  var myArray = [\u0026#34;a\u0026#34;,1]  Multidimensional array: nest one array within another array  var myArray = [[\u0026#34;a\u0026#34;,1],[\u0026#34;b\u0026#34;,2]]  Access array data with indexes  var myData = myArray[0] # Access array of arrays var arr = [ [1,2,3], [4,5,6], [7,8,9], [[10,11,12], 13, 14] ]; arr[3]; // equals [[10,11,12], 13, 14]  arr[3][0]; // equals [10,11,12]  arr[3][0][1]; // equals 11  Modify array data with indexes  var ourArray = [50,40,30]; ourArray[0] = 15; // equals [15,40,30]  Manipulate arrays with push()  var arr1 = [1,2,3]; arr1.push(4); // arr1 is now [1,2,3,4]  var arr2 = [\u0026#34;Stimpson\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;cat\u0026#34;]; arr2.push([\u0026#34;happy\u0026#34;, \u0026#34;joy\u0026#34;]); // arr2 now equals [\u0026#34;Stimpson\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;cat\u0026#34;, [\u0026#34;happy\u0026#34;, \u0026#34;joy\u0026#34;]]  Remove the first element from an array  var ourArray = [\u0026#34;Stimpson\u0026#34;, \u0026#34;J\u0026#34;, [\u0026#34;cat\u0026#34;]]; var removedFromOurArray = ourArray.shift(); // removedFromOurArray now equals \u0026#34;Stimpson\u0026#34; and ourArray now equals [\u0026#34;J\u0026#34;, [\u0026#34;cat\u0026#34;]]  Remove the last element from an array  var threeArr = [1, 4, 6]; var oneDown = threeArr.pop(); console.log(oneDown); // Returns 6 console.log(threeArr); // Returns [1, 4]  Add an element to the beginning of an array  var ourArray = [\u0026#34;Stimpson\u0026#34;, \u0026#34;dog\u0026#34;]; ourArray.shift(); // ourArray now equals [\u0026#34;dog\u0026#34;] ourArray.unshift(\u0026#34;Happy\u0026#34;); // ourArray now equals [\u0026#34;Happy\u0026#34;, \u0026#34;dog\u0026#34;] \n6. Boolean Boolean values are never written with quotes.\n The strings \u0026ldquo;true\u0026rdquo; and \u0026ldquo;false\u0026rdquo; are not Boolean and have no special meaning in JavaScript.\n ","excerpt":"Course Link\n 1. Basic JavaScript   How to comment?\n//exactitude  /* hi, how is the novel?*/   2. …","ref":"/docs/coding/functional-coding/javascript/course/basics/variables/","title":"Variables"},{"body":"\nLicense To the extent possible under law, rasbt has waived all copyright and related or neighboring rights to this work.\nA collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\nTraditional Machine Learning  Perceptron\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Logistic Regression\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Softmax Regression (Multinomial Logistic Regression)\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Softmax Regression with MLxtend\u0026rsquo;s plot_decision_regions on Iris\n[PyTorch: GitHub | Nbviewer]  Multilayer Perceptrons  Multilayer Perceptron\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Multilayer Perceptron with Dropout\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Multilayer Perceptron with Batch Normalization\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Multilayer Perceptron with Backpropagation from Scratch\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer]  Convolutional Neural Networks Basic  Convolutional Neural Network\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Convolutional Neural Network with He Initialization [PyTorch: GitHub | Nbviewer]  Concepts  Replacing Fully-Connnected by Equivalent Convolutional Layers\n[PyTorch: GitHub | Nbviewer]  Fully Convolutional  Fully Convolutional Neural Network\n[PyTorch: GitHub | Nbviewer]  LeNet  LeNet-5 on MNIST\n[PyTorch: GitHub | Nbviewer] LeNet-5 on CIFAR-10\n[PyTorch: GitHub | Nbviewer] LeNet-5 on QuickDraw\n[PyTorch: GitHub | Nbviewer]  AlexNet  AlexNet on CIFAR-10\n[PyTorch: GitHub | Nbviewer]  VGG  Convolutional Neural Network VGG-16\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] VGG-16 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer] VGG-16 Dogs vs Cats Classifier\n[PyTorch: GitHub | Nbviewer] Convolutional Neural Network VGG-19\n[PyTorch: GitHub | Nbviewer]  DenseNet  DenseNet-121 Digit Classifier Trained on MNIST\n[PyTorch: GitHub | Nbviewer] DenseNet-121 Image Classifier Trained on CIFAR-10\n[PyTorch: GitHub | Nbviewer]  ResNet  ResNet and Residual Blocks\n[PyTorch: GitHub | Nbviewer] ResNet-18 Digit Classifier Trained on MNIST\n[PyTorch: GitHub | Nbviewer] ResNet-18 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer] ResNet-34 Digit Classifier Trained on MNIST\n[PyTorch: GitHub | Nbviewer] ResNet-34 Object Classifier Trained on QuickDraw\n[PyTorch: GitHub | Nbviewer] ResNet-34 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer] ResNet-50 Digit Classifier Trained on MNIST\n[PyTorch: GitHub | Nbviewer] ResNet-50 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer] ResNet-101 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer] ResNet-101 Trained on CIFAR-10\n[PyTorch: GitHub | Nbviewer] ResNet-152 Gender Classifier Trained on CelebA\n[PyTorch: GitHub | Nbviewer]  Network in Network  Network in Network CIFAR-10 Classifier\n[PyTorch: GitHub | Nbviewer]  Normalization Layers  BatchNorm before and after Activation for Network-in-Network CIFAR-10 Classifier [PyTorch: GitHub | Nbviewer] Filter Response Normalization for Network-in-Network CIFAR-10 Classifier\n[PyTorch: GitHub | Nbviewer]  Metric Learning  Siamese Network with Multilayer Perceptrons\n[TensorFlow 1: GitHub | Nbviewer]  Autoencoders Fully-connected Autoencoders  Autoencoder (MNIST)\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Autoencoder (MNIST) + Scikit-Learn Random Forest Classifier\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer]  Convolutional Autoencoders  Convolutional Autoencoder with Deconvolutions / Transposed Convolutions\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Convolutional Autoencoder with Deconvolutions and Continuous Jaccard Distance\n[PyTorch: GitHub | Nbviewer] Convolutional Autoencoder with Deconvolutions (without pooling operations)\n[PyTorch: GitHub | Nbviewer] Convolutional Autoencoder with Nearest-neighbor Interpolation\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Convolutional Autoencoder with Nearest-neighbor Interpolation \u0026ndash; Trained on CelebA\n[PyTorch: GitHub | Nbviewer] Convolutional Autoencoder with Nearest-neighbor Interpolation \u0026ndash; Trained on Quickdraw\n[PyTorch: GitHub | Nbviewer]  Variational Autoencoders  Variational Autoencoder\n[PyTorch: GitHub | Nbviewer] Convolutional Variational Autoencoder\n[PyTorch: GitHub | Nbviewer]  Conditional Variational Autoencoders  Conditional Variational Autoencoder (with labels in reconstruction loss)\n[PyTorch: GitHub | Nbviewer] Conditional Variational Autoencoder (without labels in reconstruction loss)\n[PyTorch: GitHub | Nbviewer] Convolutional Conditional Variational Autoencoder (with labels in reconstruction loss)\n[PyTorch: GitHub | Nbviewer] Convolutional Conditional Variational Autoencoder (without labels in reconstruction loss)\n[PyTorch: GitHub | Nbviewer]  Generative Adversarial Networks (GANs)  Fully Connected GAN on MNIST\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Fully Connected Wasserstein GAN on MNIST\n[PyTorch: GitHub | Nbviewer] Convolutional GAN on MNIST\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Convolutional GAN on MNIST with Label Smoothing\n[TensorFlow 1: GitHub | Nbviewer]\n[PyTorch: GitHub | Nbviewer] Convolutional Wasserstein GAN on MNIST\n[PyTorch: GitHub | Nbviewer] \u0026ldquo;Deep Convolutional GAN\u0026rdquo; (DCGAN) on Cats and Dogs Images\n[PyTorch: GitHub | Nbviewer] \u0026ldquo;Deep Convolutional GAN\u0026rdquo; (DCGAN) on CelebA Face Images\n[PyTorch: GitHub | Nbviewer]  Graph Neural Networks (GNNs)  Most Basic Graph Neural Network with Gaussian Filter on MNIST [PyTorch: GitHub | Nbviewer] Basic Graph Neural Network with Edge Prediction on MNIST [PyTorch: GitHub | Nbviewer] Basic Graph Neural Network with Spectral Graph Convolution on MNIST\n[PyTorch: GitHub | Nbviewer]  Recurrent Neural Networks (RNNs) Many-to-one: Sentiment Analysis / Classification  A simple single-layer RNN (IMDB)\n[PyTorch: GitHub | Nbviewer] A simple single-layer RNN with packed sequences to ignore padding characters (IMDB)\n[PyTorch: GitHub | Nbviewer] RNN with LSTM cells (IMDB)\n[PyTorch: GitHub | Nbviewer] RNN with LSTM cells (IMDB) and pre-trained GloVe word vectors\n[PyTorch: GitHub | Nbviewer] RNN with LSTM cells and Own Dataset in CSV Format (IMDB)\n[PyTorch: GitHub | Nbviewer] RNN with GRU cells (IMDB)\n[PyTorch: GitHub | Nbviewer] Multilayer bi-directional RNN (IMDB)\n[PyTorch: GitHub | Nbviewer] Bidirectional Multi-layer RNN with LSTM with Own Dataset in CSV Format (AG News) [PyTorch: GitHub | Nbviewer]  Many-to-Many / Sequence-to-Sequence  A simple character RNN to generate new text (Charles Dickens)\n[PyTorch: GitHub | Nbviewer]  Ordinal Regression  Ordinal Regression CNN \u0026ndash; CORAL w. ResNet34 on AFAD-Lite\n[PyTorch: GitHub | Nbviewer] Ordinal Regression CNN \u0026ndash; Niu et al. 2016 w. ResNet34 on AFAD-Lite\n[PyTorch: GitHub | Nbviewer] Ordinal Regression CNN \u0026ndash; Beckham and Pal 2016 w. ResNet34 on AFAD-Lite\n[PyTorch: GitHub | Nbviewer]  Tips and Tricks  Cyclical Learning Rate\n[PyTorch: GitHub | Nbviewer] Annealing with Increasing the Batch Size (w. CIFAR-10 \u0026amp; AlexNet)\n[PyTorch: GitHub | Nbviewer] Gradient Clipping (w. MLP on MNIST)\n[PyTorch: GitHub | Nbviewer]  Transfer Learning  Transfer Learning Example (VGG16 pre-trained on ImageNet for Cifar-10)\n[PyTorch: GitHub | Nbviewer]  Visualization and Interpretation  Vanilla Loss Gradient (wrt Inputs) Visualization (Based on a VGG16 Convolutional Neural Network for Kaggle\u0026rsquo;s Cats and Dogs Images)\n[PyTorch: GitHub | Nbviewer] Guided Backpropagation (Based on a VGG16 Convolutional Neural Network for Kaggle\u0026rsquo;s Cats and Dogs Images)\n[PyTorch: GitHub | Nbviewer]  PyTorch Workflows and Mechanics Custom Datasets  Custom Data Loader Example for PNG Files\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; CSV files converted to HDF5\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Face Images from CelebA\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Drawings from Quickdraw\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Drawings from the Street View House Number (SVHN) Dataset\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Asian Face Dataset (AFAD)\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Dating Historical Color Images\n[PyTorch: GitHub | Nbviewer] Using PyTorch Dataset Loading Utilities for Custom Datasets \u0026ndash; Fashion MNIST\n[PyTorch: GitHub | Nbviewer]  Training and Preprocessing  Generating Validation Set Splits\n[PyTorch: GitHub | Nbviewer] Dataloading with Pinned Memory\n[PyTorch: GitHub | Nbviewer] Standardizing Images\n[PyTorch: GitHub | Nbviewer] Image Transformation Examples\n[PyTorch: GitHub | Nbviewer] Char-RNN with Own Text File\n[PyTorch: GitHub | Nbviewer] Sentiment Classification RNN with Own CSV File\n[PyTorch: GitHub | Nbviewer]  Parallel Computing  Using Multiple GPUs with DataParallel \u0026ndash; VGG-16 Gender Classifier on CelebA\n[PyTorch: GitHub | Nbviewer]  Other  Sequential API and hooks [PyTorch: GitHub | Nbviewer] Weight Sharing Within a Layer [PyTorch: GitHub | Nbviewer] Plotting Live Training Performance in Jupyter Notebooks with just Matplotlib [PyTorch: GitHub | Nbviewer]  Autograd  Getting Gradients of an Intermediate Variable in PyTorch [PyTorch: GitHub | Nbviewer]  TensorFlow Workflows and Mechanics Custom Datasets  Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives\n[TensorFlow 1: GitHub | Nbviewer] Storing an Image Dataset for Minibatch Training using HDF5\n[TensorFlow 1: GitHub | Nbviewer] Using Input Pipelines to Read Data from TFRecords Files\n[TensorFlow 1: GitHub | Nbviewer] Using Queue Runners to Feed Images Directly from Disk\n[TensorFlow 1: GitHub | Nbviewer] Using TensorFlow\u0026rsquo;s Dataset API\n[TensorFlow 1: GitHub | Nbviewer]  Training and Preprocessing  Saving and Loading Trained Models \u0026ndash; from TensorFlow Checkpoint Files and NumPy NPZ Archives\n[TensorFlow 1: GitHub | Nbviewer]  ","excerpt":"License To the extent possible under law, rasbt has waived all copyright and related or neighboring …","ref":"/docs/machinelearning/models/deep-learning/model-list/","title":"Models"},{"body":"\nInstall PyTorch Documentation\nconda install pytorch torchvision -c pytorch \nTensor What is a Tensor?  Tensor: representated as N-dimensional array of data with certain transformation properties. Tensor factorization: high-order generalization of matrix SVD or PCA Matrix: a linear transformation  Tensor\nMethods of data reduction for a data tensor\nHow to initialize a Tensor?  From a list From a numpy array From another tensor. The shape and datatype are reained, unless explicitly overridden.  What are the attributes of a tensor?  Shape: a tuple (row, col) to dtermine the dimensionality of a tensor dtype device a tensor is running on  cpu gpu    Tensor Operation API  Over 100 Operations In-place operations: operations that have a _ suffix are in place  tensor.add_(5)  x.copy_(y)   Transposing Indexing Sliding Mathmatical  Multiply  use * tensor.mul(tensor)     Linear Algebra  Matrix Multiplication  tensor @ tensor.T tensor.matmul(tensor.T)     Random Sampling Tensor and Numpy  Tensor to Numpy tensor.numpy() Numpy to Tensor torch.from_numpy()    Autograd Notebook Tutorial  An automatic differentiation engine that powers NN training Training a NN happens in two steps:  Forward Propagation: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess. Backward Propagation: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop    Computational Graph Autograd keeps a record ot data(tensors) and all executed operations (along with resulting new tensors) in a directed acyclic graph (DAG) consisting of Function objects.\n Tensors  Leaves: input tensors Roots: output tensors From leaves to roots: run the requested operations From roots to leaves: compute the gradients using chain rules   Operations  Forward pass  run the requested operation to compute a resulting tensor maintain the operation\u0026rsquo;s gradient function in the DAG   Backward pass  computes the gradients from each .grad_fn accumulates them in the respective tensor\u0026rsquo;s .grad attributes use the chain rule, propagates all the way to leaf tensors      DAGs  What are DAGs?  DAGs are dynamic in PyTorch An important thing to note is that the graph is recreated from scratch; after each .backward() call, autograd starts populating a new graph. This is exactly what allows you to use control flow statements in your model; you can change the shape, size and operations at every iteration if needed.    Inclusion and Exclusion from the DAG  torch.autograd tracks operations on all tensors which have their requires_grad flag set to True. For tensors that don’t require gradients, setting this attribute to False excludes it from the gradient computation DAG  x = torch.rand(5, 5) y = torch.rand(5, 5) z = torch.rand((5, 5), requires_grad=True) a = x + y print(f\u0026#34;Does `a` require gradients? : {a.requires_grad}\u0026#34;) # False b = x + z print(f\u0026#34;Does `b` require gradients?: {b.requires_grad}\u0026#34;) # True Why exclusion is needed?  Frozen Parameters   Parameters that don\u0026rsquo;t compute gradients Useful to freeze part of your model to offer some performance benefits by reducing autograd computations   Finetune a pretrained network   In finetuning, we freeze most of the model Modify the classifier layers to make predictions on new labels  How to use exlusionary functionality?  Use a context manager in torch.no_grad() Set requires_grad=False in a tensor  from torch import nn, optim model = torchvision.models.resnet18(pretrained=True) # Freeze all the parameters in the network!!! for param in model.parameters(): param.requires_grad = False # Finetune the model on a new dataset with 10 labels.  # In resnet, the classifier is the last linear layer model.fc.  # We can simply replace it with a new linear layer (unfrozen by default) that acts as our classifier model.fc = nn.Linear(512, 10) # Now all parameters in the model, except the parameters of model.fc, are frozen. The only parameters that compute gradients are the weights and bias of model.fc # Optimize only the classifier optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9) \nNeural Networks  Tutorial Colab  How to construct a NN?  Use torch.nn package Define the network You just have to define the forward function The backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function. The learnable parameters of a model are returned by net.parameters()  convnet\nimport torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 3x3 square convolution # kernel self.conv1 = nn.Conv2d(1, 6, 3) self.conv2 = nn.Conv2d(6, 16, 3) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6*6 from image dimension  self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) # params params = list(net.parameters()) print(len(params)) print(params[0].size())  Reference  pytorch 60 min  tensor autograd_tutorial.ipynb   pytorch pytorch kaggle udacity  ","excerpt":"Install PyTorch Documentation\nconda install pytorch torchvision -c pytorch \nTensor What is a Tensor? …","ref":"/docs/machinelearning/frameworks/pytorch/pytorch-tutorial/","title":"PyTorch Tutorial"},{"body":"\nList folder size and corresponding file sizes du -chd 1 | sort -h du -aBM 2\u0026gt;/dev/null | sort -nr | head -n 50 | more # use du\u0026#39;s -x flag to keep things limited to one filesystem  # 2\u0026gt;/dev/null redirects any error messages into oblivion. If they don\u0026#39;t bother you, it\u0026#39;s not obligatory. sudo du -sx /* 2\u0026gt;/dev/null | sort -n # List all files larger than 1000MiB find / -size +1000M -ls \nClean Ubuntu # To delete downloaded packages (.deb) already installed (and no longer needed) sudo apt-get clean # To remove all stored archives in your cache for packages that can not be downloaded anymore (thus packages that are no longer in the repository or that have a newer version in the repository). sudo apt-get autoclean # To remove unnecessary packages (After uninstalling an app there could be packages you don\u0026#39;t need anymore) sudo apt-get autoremove # Install bleachbit  sudo apt-get install bleachbit # Open bleachbit and select files to clean  # To delete old kernel versions sudo apt-get remove --purge linux-image-X.X.XX-XX-generic # If you don\u0026#39;t know which kernel version to remove dpkg --get-selections | grep linux-image \nClean conda Anaconda accumulate lots of garbage package caches and tarballs.\n conda clean\n # To delete caches, tarballs and lock files which are not used (except tmp) conda clean -iptf # To delete all conda clean -a ","excerpt":"List folder size and corresponding file sizes du -chd 1 | sort -h du -aBM 2\u0026gt;/dev/null | sort -nr …","ref":"/docs/coding/functional-coding/bash/free/","title":"Free up disk space"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/ai/","title":"AI"},{"body":"\n1. TensorFlow Datasets # Install: pip install tensorflow-datasets import tensorflow_datasets as tfds mnist_data = tfds.load(\u0026#34;mnist\u0026#34;) mnist_train, mnist_test = mnist_data[\u0026#34;train\u0026#34;], mnist_data[\u0026#34;test\u0026#34;] assert isinstance(mnist_train, tf.data.Dataset) \n2. Data For Everyone  Link  3. Autonomous Driving Dataset  Audi A2D2   A2D2 is around 2.3 TB in total. It is split by annotation type (i.e. semantic segmentation, 3D bounding box), to break up the download into smaller packages. Each split is packaged into a single tar file, while the remaining unlabelled sequence data is split into multiple tar files.\n 4. Sound  DESED   Domestic environment sound event detection (DESED). \u0026gt; Mix of recorded and synthetic data.\n 5. NLP dataset  Huggingface datasets  pip install datasets     Read More  Introducing TensorFlow Datasets What datasets are available in Datasetsv1.0.2? Try TensorFlow Datasets in Colab How to Add a Dataset tensor2tensor  ","excerpt":"1. TensorFlow Datasets # Install: pip install tensorflow-datasets import tensorflow_datasets as tfds …","ref":"/docs/data/dataset/find-data/","title":"Find Data"},{"body":"","excerpt":"","ref":"/docs/machinelearning/ai/papers/","title":"Papers"},{"body":"\nWhich type of visualization plot to choose?  data-to-viz guide  Which tools are good for data visualization?  HoloViews  conda install -c pyviz holoviews bokeh # If you are working with a JupyterLab version \u0026lt;2.0 you will also need the PyViz JupyterLab extension jupyter labextension install @pyviz/jupyterlab_pyviz ","excerpt":"\nWhich type of visualization plot to choose?  data-to-viz guide  Which tools are good for data …","ref":"/docs/data/visual-art/data-viz/","title":"Data to Viz"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/graph-nn/applications/","title":"Applications"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/deep-learning/","title":"Deep Learning"},{"body":"","excerpt":"","ref":"/docs/machinelearning/cv/papers/","title":"Papers"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/graph-nn/papers/","title":"Papers"},{"body":"","excerpt":"","ref":"/docs/machinelearning/nlp/nlp-papers/","title":"Papers"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/frameworks/pytorch/","title":"PyTorch"},{"body":"\nEC2  -bash: cd: directory/: Permission denied  Reason: The ec2-user doesn\u0026rsquo;t have permission on that directory. Solution:  sudo su - to become root. Then you\u0026rsquo;ll be able to go into the directory and do as you see fit. sudo chmod 755 /home/ec2-user which will make that user directory world readable. If the ec2-user is a real user (i.e. has an entry in /etc/passwd) then you can sudo su - ec2-user to become that operating system user. The relative merits of the answers depend on the security that you want in your system. If you just need to look then the first or third answer are likely the best as they are not a persistent change. But if you really want to use that directory by the ec2-user then you may want to use the second answer.      Which Spark kernel to use on AWS SageMaker?  Use python3 and import pysaprk If you want to use spark magic   You should also start Livy which is API service used by magicspark to talk to your Spark cluster. How?  Download Livy from Apache Livy and unzip it Check SPARK_HOME environment is set, if not, set to your Spark Run Livy server by \u0026lt;livy_home\u0026gt;/bin/livy-server in the command line      ","excerpt":"EC2  -bash: cd: directory/: Permission denied  Reason: The ec2-user doesn\u0026rsquo;t have permission on …","ref":"/docs/coding/practices/error_collection/aws/","title":"AWS"},{"body":"\nHow to create and change emojis using JavaScript? You can create and change emojis using JavaScript\nRead more at this fantastic article by @mathias https://t.co/lSACG8rufx pic.twitter.com/wdG1yYCkwh\n\u0026mdash; Minko Gechev (@mgechev) April 16, 2020  How to use emojis in Markdown?  Complete list of github markdown emoji markup \n  ","excerpt":"\nHow to create and change emojis using JavaScript? You can create and change emojis using JavaScript …","ref":"/docs/coding/expressitive-coding/emojis/","title":"Emojis"},{"body":"Python f-string formatting  All examples below were executed in Python interactive shell\n  precision  \u0026gt;\u0026gt;\u0026gt; import math \u0026gt;\u0026gt;\u0026gt; math.pi 3.141592653589793 \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{math.pi:.2f}\u0026#39; \u0026#39;3.14\u0026#39;  grouping_option  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{1000000:,.2f}\u0026#39; \u0026#39;1,000,000.00\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{1000000:_.2f}\u0026#39; \u0026#39;1_000_000.00\u0026#39;  with numbers  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{12345:0\u0026gt;10}\u0026#39; \u0026#39;0000012345\u0026#39;  negative numbers  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{-12345:0=10}\u0026#39; \u0026#39;-000012345\u0026#39;  shortcut (no align)  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{12345:010}\u0026#39; \u0026#39;0000012345\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{-12345:010}\u0026#39; \u0026#39;-000012345\u0026#39;  sign (+/-)  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{12345:+}\u0026#39; \u0026#39;+12345\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{-12345:+}\u0026#39; \u0026#39;-12345\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{-12345:+10}\u0026#39; \u0026#39; -12345\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{-12345:+010}\u0026#39; \u0026#39;-000012345\u0026#39;  binary  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{10:b}\u0026#39; \u0026#39;1010\u0026#39;  octal  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{10:o}\u0026#39; \u0026#39;12\u0026#39;  hexadecimal  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{200:x}\u0026#39; \u0026#39;c8\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{200:X}\u0026#39; \u0026#39;C8\u0026#39;  scientific notation  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{345600000000:e}\u0026#39; \u0026#39;3.456000e+11\u0026#39;  character type  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{65:c}\u0026#39; \u0026#39;A\u0026#39;  with notation (base)  \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{10:#b}\u0026#39; \u0026#39;0b1010\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{10:#o}\u0026#39; \u0026#39;0o12\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{10:#x}\u0026#39; \u0026#39;0xa\u0026#39; - percentage (multiply by 100)\n\u0026gt;\u0026gt;\u0026gt; f\u0026#39;{0.25:0%}\u0026#39; \u0026#39;25.000000%\u0026#39; \u0026gt;\u0026gt;\u0026gt; f\u0026#39;{0.25:.0%}\u0026#39; \u0026#39;25%\u0026#39; \nLicense To the extent possible under law, myshell-src has waived all copyright and related or neighboring rights to this file.\n","excerpt":"Python f-string formatting  All examples below were executed in Python interactive shell\n  precision …","ref":"/docs/coding/functional-coding/python/f-string/","title":"f-string"},{"body":"\nTable of Contents  Vector Determinant Dot products Cross products Cramer\u0026rsquo;s rule Linear transformations Matrix vector multiplication Matrix multiplication Change of basis Eigenvectors and eigenvalues Abstract vector spaces Questions Glossary References  Vector  Imagine we have a two dimensional space composed of x and y axis, and their intersection called origin (0). $\\begin{bmatrix}1 \\\\2 \\end{bmatrix}$ : The coordinate of a vector is a pair of numbers which gives instructions to tell the vector how to get from the origin of the vector to the tip of the vector. The first number tells you how far to walk on the x-axis After that, the second number tells you how far to walk parallel to the y-axis To differentiate vectors from points, the convention is to write these two numbers vertically in a square bracket. Every pair of numbers is associated with one and only one vector, vice versa Vectors, what even are they? 3'- 4'  Determinant 2-D  $A = \\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix}$ Determinant of $A$: $det(A)$ Numerically  a scalar value that can be computed from the elements of a square matrix and measures the scaling of linear transformation described by the matrix $det(A)= ad-bc$   Geometrically  $det(A)$:the area scaling factor of the linear transformation $\\lvert det(A) \\rvert \u0026gt; 1$, increase the area by a factor of 5 0\u0026lt; $\\lvert det(A) \\rvert \u0026lt; 1$: squish down area Zero determinant: when $det(A) =0$, the transformation squishes down the area to a line or a point $det(A) \u0026lt; 0$: the orientation of space is inverted (space is inverted. The basis vector $\\vec{i}$ is now on the left side of $\\vec{j}$)    3-D  $B = \\begin{bmatrix}u_1\u0026amp;v_1\u0026amp;w_1 \\\\u_2\u0026amp;v_2\u0026amp;w_2 \\\\u_3\u0026amp;v_3\u0026amp;w_3 \\end{bmatrix}$ Numerically:  $det(B)$: the volume scaling factor of the linear transformation described by the matrix $det(B) = u_1(v2w3-w2v3)-v_1(u_2w_3-w_2u_3)+w_1(u_2v_3-v_2u_3)$   Geometrically  $det(B) \u0026lt; 0$: Right finger rule no longer fits  index finger: points to the direction of $\\vec{i}$ middle finger: points to the direction of $\\vec{j}$ thumb: points to the direction of $\\vec{k}$      Dot products   Two vectors of the same dimension\n  $\\vec{v}$ = $\\begin{bmatrix}1 \\\\2 \\end{bmatrix}$\n  $\\vec{w}$ = $\\begin{bmatrix}3 \\\\4 \\end{bmatrix}$\n    Order: doesn\u0026rsquo;t matter\n  Numerically\n Pair the coordinates of multiply them together and add the result $\\begin{bmatrix}1 \\\\2 \\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix}3 \\\\4 \\end{bmatrix}$ = 1 $\\cdot$ 3+ 2 $\\cdot$ 4 = 11    Geometrically\n Project $\\vec{w}$ onto the line passing through the origin on the tip of $\\vec{v}$ $\\vec{v}$ $\\cdot$ $\\vec{w}$ = (length of projected $\\vec{w}$) $\\cdot$ (length of projected $\\vec{v}$) Dot product vs Directions  $\\vec{v}$ $\\cdot$ $\\vec{w}$\u0026gt; 0: vectors are pointing to similar directions $\\vec{v}$ $\\cdot$ $\\vec{w}$\u0026lt; 0: vectors are pointing to opposing direction $\\vec{v}$ $\\cdot$ $\\vec{w}$ = 0: vectors are perpendicular      Duality: natural-but-surprising correspondence\n Matrix vector product:\n[$u_x$ $u_y$] $\\begin{bmatrix}x \\\\y \\end{bmatrix}$ = $u_x$ $\\cdot$ $x$ + $u_y$ $\\cdot$ $y$ Dot product:\n$\\begin{bmatrix}u_x \\\\u_y \\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix}x \\\\y \\end{bmatrix}$ = $u_x$ $\\cdot$ $x$ + $u_y$ $\\cdot$ $y$    Screenshot at 2:19 in video Cross products   The standard basis vectors $\\vec{i}$, $\\vec{j}$, and $\\vec{k}$\n  Two vectors of the same dimension\n  $\\vec{v}$ = $\\begin{bmatrix}v_1 \\\\v_2\\\\v_3 \\end{bmatrix}$\n  $\\vec{w}$ = $\\begin{bmatrix}w_1 \\\\w_2 \\\\w_3\\end{bmatrix}$\n    Order: matters\n  Cross products\n $\\vec{p}$ = $\\vec{v}$ $\\times$ $\\vec{w}$ $\\vec{p}$ is a vector that is perpendicular to both $\\vec{v}$ and $\\vec{w}$ and thus normal to the plane containing them    $\\vec{p}$ directions\n $\\vec{p}$ \u0026gt; 0: when $\\vec{v}$ is on the right side of $\\vec{w}$ $\\vec{p}$ \u0026lt; 0: when $\\vec{v}$ is on the left side of $\\vec{w}$    Numerically\n $\\begin{bmatrix}v_1 \\\\v_2\\\\v_3 \\end{bmatrix}$ $\\times$ $\\begin{bmatrix}w_1 \\\\w_2 \\\\w_3\\end{bmatrix}$ = ($v_2w_3 -w_2v_3)\\vec{i}$ + ($v_3w_1$ - $v_1w_3)\\vec{j}$ + ($v_1w_2$ - $v_3w_1)\\vec{k}$    Geometrically\n The positive area of the parallelogram having $\\vec{v}$ and $\\vec{w}$ as sides The length of $\\vec{p}$ = the area of parallelogram defined by $\\vec{v}$ and $\\vec{w}$ The direction of $\\vec{p}$ is defined using the Right Hand Rule  index finger: points to the direction of $\\vec{v}$ middle finger: points to the direction of $\\vec{w}$ thumb: points to the direction of $\\vec{p}$      Screenshot at 6:03 in video\nCramer\u0026rsquo;s rule  Cramer\u0026rsquo;s rule expresses the solution in terms of the determinants of the (square) coefficient matrix and of matrices obtained from it by replacing one column by the column vector of right-hand-sides of the equations. It is named after Gabriel Cramer Consider a system of linear equation    $ax + by =e$\n$cx+dy=f$\n  $\\frac{e-ax}{b}=\\frac{f-cx}{a}$; $x = \\frac{ed-bf}{ad-bc}$\n  $\\frac {e-by} {a} = \\frac{f-dy}{c}$; $y = \\frac{af-ec} {ad=bc}$\n   Matrix Equation    $\\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix} \\begin{bmatrix}x \\\\y \\end{bmatrix} = \\begin{bmatrix}e \\\\f \\end{bmatrix}$\n  $x = \\frac { \\begin{array}{| cc |} e\u0026amp;b\\\\ f\u0026amp;d\\end{array} } { {\\begin{array}{|cc|} a\u0026amp;b\\\\c\u0026amp;d\\end{array} } }$\n  $y = \\frac { \\begin{array}{|cc|} a\u0026amp;e\\\\c\u0026amp;f\\end{array} } { {\\begin{array}{|cc|} a\u0026amp;b\\\\c\u0026amp;d\\end{array} } }$\n  Linear transformations What is linear transformation?  A function that takes an input vector and generates an output vector The word \u0026lsquo;transformation\u0026rsquo; suggests that we think using movement The word \u0026lsquo;Linear\u0026rsquo; suggests all spatial grid lines (for visualizing the coordinate system) must remain parallel and evenly spaced (not curvy), and the origin remains fixed (not moving).   What is a shear matrix?\nA shear matrix is an elementary matrix that represents the addition of a multiple of one row or column to another.\n $\\begin{bmatrix}1\u0026amp;s \\\\0\u0026amp;1 \\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;0 \\\\s\u0026amp;1 \\end{bmatrix}$    How is matrix useful?\n Computer graphics Robotics: e.g. rotation Solve system equations: Linear system   Matrix vector multiplication  Numerically:  $\\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix} \\begin{bmatrix}x \\\\y \\end{bmatrix} = x\\begin{bmatrix}a \\\\c \\end{bmatrix} + y\\begin{bmatrix}b \\\\d \\end{bmatrix} = \\begin{bmatrix}{ax+by} \\\\ {cx+dy} \\end{bmatrix}$   Geometrically: apply a transformation to a vector  Think of the columns of a matrix as transformed basis vectors $\\begin{bmatrix}a \\\\c \\end{bmatrix}$ and $\\begin{bmatrix}b \\\\d \\end{bmatrix}$ The linear trans result is the linear combination of the transformed basis vectors   Matrix Vector multiplication 8:00    Matrix multiplication  Numerically: Right to left  $\\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix}\\begin{bmatrix}e\u0026amp;f \\\\g\u0026amp;h \\end{bmatrix} =\\begin{bmatrix}{ae+bg}\u0026amp;{af+bh} \\\\ {ce+dg}\u0026amp;{cf+dh}\\end{bmatrix}$ Step1: $\\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix}\\begin{bmatrix}e \\\\g \\end{bmatrix} = e\\begin{bmatrix}a \\\\c \\end{bmatrix} + g\\begin{bmatrix}b \\\\d \\end{bmatrix} = \\begin{bmatrix}{ae+bg} \\\\ {ce+dg} \\end{bmatrix}$ Step 2: $\\begin{bmatrix}a\u0026amp;b \\\\c\u0026amp;d \\end{bmatrix}\\begin{bmatrix}f \\\\h \\end{bmatrix} = f\\begin{bmatrix}a \\\\c \\end{bmatrix} + h\\begin{bmatrix}b \\\\d \\end{bmatrix} = \\begin{bmatrix}{af+bh} \\\\ {cf+dh} \\end{bmatrix}$   Geometrically:  $f(g(x))$ Composition: apply one transformation $f$ after another $g$   Order: matters $M_1M_2 \\ne M_2M_1$ Associativity: $(AB)C=A(BC)$, meaning applying transformation C, B, and A  Change of basis  Translate between two coordinate systems An inverse transformation $A^{-1}$ means: reverse the transformation $A^{-1}MA$  $M$: a transformation in coordinate system P $A^{-1}$ and $A$: mathematical sort of empathy $A^{-1}MA$: mathematical product in coordinate system Q    Eigenvectors and eigenvalues   Eigenvector: a vector that stays on its own span (the line passing through the origin and the tip of the vector) during a matrix transformation, unlike other vectors that are knocked off their spans during transformation\n  Eigenvalue: The factor by which the eigengectors is stretched or squished\n  e.g. Matrix $A = \\begin{bmatrix}3\u0026amp;1 \\\\0\u0026amp;2 \\end{bmatrix}$ Eigenvector $\\vec{v}$ = $\\begin{bmatrix}-1 \\\\1 \\end{bmatrix}$, eigenvalue of $\\vec{v}$ is 2\n  Eigenvector 3:39\n  The axis of a 3-D rotation: the span of an eigenvector, with eigenvalue equal to 1 (no stretching or squishing during rotation)\n  Eigenbasis: a set of basis vectors which are also eigenvectors\n useful for matrix operations, e.g. To calculate $\\begin{bmatrix}3\u0026amp;1 \\\\0\u0026amp;2 \\end{bmatrix}^{100}$, change the basis vector to eigenbasis system $\\begin{bmatrix}1\u0026amp;-1 \\\\0\u0026amp;1 \\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;-1 \\\\0\u0026amp;1 \\end{bmatrix}^{-1}$ $\\begin{bmatrix}3\u0026amp;1 \\\\0\u0026amp;2 \\end{bmatrix}$ $\\begin{bmatrix}1\u0026amp;-1 \\\\0\u0026amp;1 \\end{bmatrix}$ = $\\begin{bmatrix}3\u0026amp;0 \\\\0\u0026amp;2 \\end{bmatrix}$    How to calculate the eigenvalue of a matrix?\n Matrix-vector multiplication $A\\vec{v} = \\lambda\\vec{v}$ Scalar multiplication Change the scalar multiplication to matrix multiplication ($I\\vec{v}$) scaled by a factor $\\lambda$ $A\\vec{v} = \\lambda I \\vec{v}$; matrix-vector multiplication on both sides $I = \\begin{bmatrix}1 \u0026amp;0 \\\\0\u0026amp;1 \\end{bmatrix}$, the identity matrix with ones in the diagonal $(A-\\lambda I)\\vec{v} = 0$ For non-zero $\\vec{v}$, the transformation associated with the matrix has to be squished down to a lower dimension (squishification), which corresponds to a zero determinant of the matrix $det(A-\\lambda I) = 0$ e.g.   For matrix $A = \\begin{bmatrix}3\u0026amp;1 \\\\0\u0026amp;2 \\end{bmatrix}$\n  $\\biggl(\\begin{bmatrix}3\u0026amp;1 \\\\0\u0026amp;2 \\end{bmatrix} - \\lambda\\begin{bmatrix}1 \u0026amp;0 \\\\0\u0026amp;1 \\end{bmatrix}\\biggr)\\vec{v}=0$\n  $det \\biggl(\\begin{bmatrix}{3-\\lambda}\u0026amp;1 \\\\0\u0026amp;{2-\\lambda } \\end{bmatrix}\\biggr) = 0$\n  $(3-\\lambda)(2-\\lambda)=0$\n  $\\lambda$ can only be an eigenvalue, therefore, $\\lambda=2$ or $\\lambda=3$, which are the eigenvectors of matrix $A$\n      Abstract vector spaces  Function: a type of vectors  Questions   What does a determinant of 0 mean for a matrix transformation?\n $det(A)=0$ The matrix is squished down to a lower dimension    What kind of matrices have no eigenvalues?\n Non-square matrix A skew-symmetric matrix (or anti-symmetric matrix) where $A^T=-A$    What properties do linear transformations have?\n Linear transformations preserve addition and scalar multiplication Preserving additivity: The result of adding two vectors and applying transformation to the sum is the same as adding the transformed vectors.\n$L(\\vec{v}+\\vec{w})=L(\\vec{v})+L(\\vec{w})$ Preserving scaling: when you scale a vector by a scaler and then apply the transformation is the same as scaling the transformed vector. These properties make it possible to represent any vector and do matrix multiplications. $L(c\\vec{v})=cL(\\vec{v})$    Glossary  Column space: all the linear combinations of the column vectors Video by Sal Khan Identity transformation: the transformation that does nothing Gaussian elimination Inverse matrices: the inverse transformation in geometry (clockwise-counterclockwise, rightward shear \u0026ndash; leftward shear) $A^{-1}*A^1=\\begin{bmatrix}0\u0026amp;1 \\\\1\u0026amp;0 \\end{bmatrix}$ Rank: the number of dimensions in the output of a transformation (e.g. Rank 2: All vectors after a transformation land on a 2-D plane) Null space (kernel): the space of all vectors becoming null Row echelon form Span: the set of all linear combinations of two vectors. Symmetric matrix: $A^T=A$ Skew-symmetric matrix $A^T=-A$   Read More  Essence of linear algebra Cross product introduction Essence of linear algebra MIT Eigen Eigenvalues and Eigenvectors KSmith-EigenValues Shears and one directional scaling Mary L Boas, John Wiley and Sons, 3rd Ed, 2006. Linear Algebra - Chapter 3. Introduction to Linear Algebra by Gilbert Strang, Wellesley-Cambridge Press, 5th Ed, 2016. Introduction to Applied Linear Algebra – Vectors, Matrices, and Least Squares, by Stephen Boyd and Lieven Vandenberghe  ","excerpt":"Table of Contents  Vector Determinant Dot products Cross products Cramer\u0026rsquo;s rule Linear …","ref":"/docs/math/intro/linear_algebra/","title":"Linear Algebra"},{"body":"\nI: Recurrent Neural Networks 1.What are some examples of sequence data?   DNA/RNA/Protein Sequence\n  Smart home\n  Stock change\n  Supply chain\n  Music generation\n  Speech recognition\n  Sentiment classification\n  Video activity recognition\n  Name entity recognition (one example here)\n Representing Words  Words Index xT, yT   Dictionary :  Big company use 1 million words Commercial: 30k This lecture example: 10k One-Hot encoders      2. Why don\u0026rsquo;t we use a standard network for sequence data analysis? Problems:\n Input and outputs can be different lengths in different sentences You may pad or zero-pad each inputs up to that maximum length Don\u0026rsquo;t share features learned across different positions of text Huge matrix: each vector xT * max No. of words  3. How does a (uni-directional) recurrent neural network different from a standard network?  To kick off, add a made-up activation at time 0  Usually the vectors of zeros as the fake times zero activation) Or initialize a0 randomly   Reads the 1st word in a sentence, predict whether the word is a part of the name y1 for X1 Reads the 2nd word in a sentence, predict y2 for X2 Passes the activation information from time step 1 to time step 2  4. What are the disadvantages of a RNN?   Exploding gradients:\n Parameters get large Gradient Clipping: when you derivatives explode or you see NaNs, then rescale numerical vectors. This is a very robust way.    Vanishing gradients:\n Harder to solve GRU    5. What are forward propagation and backward propagation?  Forward Propagation Backward propagation through time The Unreasonable Effectiveness of Recurrent Neural Networks  6. Bidrectional Neural Networks (BRNNs) Activation Functions: Hidden Layers:   Relu\n If a lot of neurons die  Leaky Relu MaxOut      Don\u0026rsquo;t use:\n Sigmoid  Gradient vanishing problems Loss of control because it\u0026rsquo;s not 0-centered (all +)   Tanh (Hyperbolic Tangent Function)  Gradient vanishing problems      Output layers   Softmax: For classification\n  Linear function: For regression\n  Note:  For a real type speech recognition applications: complex modules. NLP processing applications: use standard BRNN when you can get the entire sentence all the same time  7.Deep BRNNs  You don\u0026rsquo;t see a lot of deep-connected layers because of the large temporal dimensions 3 layers is already deep  8. Language modelling and sequence generation   A training set comprising a large corpus of text\n  Tokenization\n End of Sentence (EOS) Unkown words (UNK)    Vocabulary-level language model\n  Character-level language model\n Punctuations and space are also vectors Don\u0026rsquo;t need to worry about UNK, assign non-zero vectors Not good at capturing long-range word dependencies An example of character level language model Dinosaurus land notebook    Sequence generation\n  9. Gated Recurrent Unit (GRU)   What is GRU? GRU is a modification of the RNN hidden layer\n  Why GRU? GRU is much better capturing long range connections and helps a lot with the vanishing gradient problems.\n  What is a common GRU composed of?   Memory Cell Value (c): a new variable in GRU\n  Provide a bit of memory to remember\n  E.g. The dog, which already ate a sausage, was full.\n  The c will remember whether the subject of the sentence, \u0026ldquo;dog\u0026rdquo;, was singular or plural, so that when it gets much further into the sentence it can\n  For GRU, ct = at (output activation)\n    The optic gate\n  Notion: capital Greek alphabet gamma Γu\n  The job of the Gate, gamma u: to decide when do you update the value ct\n  [0 -1] For intuition, think of gamma as either 0 or 1\n    The relevance gate\n Notion: Γr    10. Long Short-Term Memory (LSTM) network What is a LSTM unit and network? Long short-term memory (LSTM) units are units of a RNN. An RNN composed of LSTM units is often called an LSTM network.\nWhat is a common LSTM composed of?  a cell an input gate an output gate a forget gate  How does LSTM work?  Forget gate: LSTM should remove that piece of information (e.g. the singular subject) in the corresponding component. If one of the values is 1, then it will keep the information. Update gate: Once we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Updating the cell: To update the new subject we need to create a new vector of numbers that we can add to our previous cell state. Output gate: To decide which outputs we will use   Read more?   Text and Image source: \u0026ldquo;Sequence Models\u0026rdquo;, Coursera\n  Understanding LSTM Networks, GitHub\n  The Illustrated BERT, ELMo\n  BERT Explained: State of the art language model for NLP, Medium\n  ","excerpt":"I: Recurrent Neural Networks 1.What are some examples of sequence data?   DNA/RNA/Protein Sequence …","ref":"/docs/machinelearning/models/deep-learning/sequence-models/sequence-models/","title":"Sequence Models"},{"body":"\nLicense \nTo the extent possible under law, Daniel Stefanovic has waived all copyright and related or neighboring rights to this work.\nTable of contents  3D Renderer Augmented Reality BitTorrent Client Blockchain / Cryptocurrency Bot Command-Line Tool Database Docker Emulator / Virtual Machine Front-end Framework / Library Game Git Network Stack Neural Network Operating System Physics Engine Programming Language Regex Engine Search Engine Shell Template Engine Text Editor Visual Recognition System Voxel Engine Web Search Engine Web Server Uncategorized  Tutorials Build your own 3D Renderer  C++: Introduction to Ray Tracing: a Simple Method for Creating 3D Images C++: How OpenGL works: software rendering in 500 lines of code C++: Raycasting engine of Wolfenstein 3D C++: Physically Based Rendering:From Theory To Implementation C++: Rasterization: a Practical Implementation C# / TypeScript / JavaScript: Learning how to write a 3D soft engine from scratch in C#, TypeScript or JavaScript Java / JavaScript: Build your own 3D renderer Java: How to create your own simple 3D render engine in pure Java JavaScript / Pseudocode: Computer Graphics from scratch Python: A 3D Modeller  Build your own Augmented Reality  C#: How To: Augmented Reality App Tutorial for Beginners with Vuforia and Unity 3D [video] C#: How To Unity ARCore [video] C#: AR Portal Tutorial with Unity [video] C#: How to create a Dragon in Augmented Reality in Unity ARCore [video] C#: How to Augmented Reality AR Tutorial: ARKit Portal to the Upside Down [video] Python: Augmented Reality with Python and OpenCV  Build your own BitTorrent Client  C#: Building a BitTorrent client from scratch in C# Nim: Writing a Bencode Parser Node.js: Write your own bittorrent client Python: A BitTorrent client in Python 3.5  Build your own Blockchain / Cryptocurrency  ATS: Functional Blockchain C#: Programming The Blockchain in C# Crystal: Write your own blockchain and PoW algorithm using Crystal Go: Building Blockchain in Go Go: Code your own blockchain in less than 200 lines of Go Go: Building A Simple Blockchain with Go Java: Creating Your First Blockchain with Java JavaScript: A cryptocurrency implementation in less than 1500 lines of code JavaScript: Build your own Blockchain in JavaScript JavaScript: Learn \u0026amp; Build a JavaScript Blockchain JavaScript: Creating a blockchain with JavaScript JavaScript: How To Launch Your Own Production-Ready Cryptocurrency JavaScript: Writing a Blockchain in Node.js Kotlin: Let’s implement a cryptocurrency in Kotlin Python: Learn Blockchains by Building One Python: Build your own blockchain: a Python tutorial Python: A Practical Introduction to Blockchain with Python Python: Let’s Build the Tiniest Blockchain Ruby: Programming Blockchains Step-by-Step (Manuscripts Book Edition) Scala: How to build a simple actor-based blockchain TypeScript: Naivecoin: a tutorial for building a cryptocurrency TypeScript: NaivecoinStake: a tutorial for building a cryptocurrency with the Proof of Stake consensus  Build your own Bot  Haskell: Roll your own IRC bot Java: How To Make a Scary Russian Twitter Bot With Java Node.js: Creating a Simple Facebook Messenger AI Bot with API.ai in Node.js Node.js: How to make a responsive telegram bot Node.js: Create a Discord bot Node.js: gifbot - Building a GitHub App Node.js: Building A Simple AI Chatbot With Web Speech API And Node.js Python: Chatbot Fundamentals: An interactive guide to writing bots in Python Python: How to Build Your First Slack Bot with Python Python: How to build a Slack Bot with Python using Slack Events API \u0026amp; Django under 20 minute Python: Build a Reddit Bot Python: How To Make A Reddit Bot [video] Python: How To Create a Telegram Bot Using Python Python: Create a Twitter Bot in Python Using Tweepy Python: Creating Reddit Bot with Python \u0026amp; PRAW [video] R: Build A Cryptocurrency Trading Bot with R Rust: A bot for Starcraft in Rust, C or any other language  Build your own Command-Line Tool  C: Rewriting the cat command from scratch [video] Go: Visualize your local git contributions with Go Go: Build a command line app with Go: lolcat Go: Building a cli command with Go: cowsay Go: Go CLI tutorial: fortune clone Nim: Writing a stow alternative to manage dotfiles  Build your own Database  C: Let\u0026rsquo;s Build a Simple Database C++: Implementing a Key-Value Store C#: Build Your Own Database Clojure: An Archaeology-Inspired Database Crystal: Why you should build your own NoSQL Database JavaScript: Dagoba: an in-memory graph database Python: DBDB: Dog Bed Database Python: Write your own miniature Redis with Python  Build your own Docker  C: Linux containers in 500 lines of code Go: Build Your Own Container Using Less than 100 Lines of Go Go: Building a container from scratch in Go [video] Python: A workshop on Linux containers: Rebuild Docker from Scratch Python: A proof-of-concept imitation of Docker, written in 100% Python Shell: Docker implemented in around 100 lines of bash  Build your own Emulator / Virtual Machine  C: Virtual machine in C C: Write your Own Virtual Machine C: Writing a Game Boy emulator, Cinoop C++: How to write an emulator (CHIP-8 interpreter) C++: Emulation tutorial (CHIP-8 interpreter) C++: Emulation tutorial (GameBoy emulator) C++: Emulation tutorial (Master System emulator) Common Lisp: CHIP-8 in Common Lisp JavaScript: GameBoy Emulation in JavaScript Python: Emulation Basics: Write your own Chip 8 Emulator/Interpreter  Build your own Front-end Framework / Library  JavaScript: WTF is JSX (Let\u0026rsquo;s Build a JSX Renderer) JavaScript: A DIY guide to build your own React JavaScript: Reverse Engineering React [video] JavaScript: Building React From Scratch [video] JavaScript: Building Your Own React Clone in Five Easy Steps JavaScript: Gooact: React in 160 lines of JavaScript JavaScript: React Internals JavaScript: Learn how React Reconciler package works by building your own lightweight React DOM JavaScript: Build Yourself a Redux JavaScript: Let’s Write Redux! JavaScript: Redux: Implementing Store from Scratch [video] JavaScript: Build Your own Simplified AngularJS in 200 Lines of JavaScript JavaScript: Make Your Own AngularJS JavaScript: How to write your own Virtual DOM JavaScript: Building a frontend framework, from scratch, with components (templating, state, VDOM)  Build your own Game  C: Handmade Hero C: How to Program an NES game in C C: Chess Engine In C [video] C: Let\u0026rsquo;s Make: Dangerous Dave [video] C: Learn Video Game Programming in C [video] C: Coding A Sudoku Solver in C [video] C: Coding a Rogue/Nethack RPG in C [video] C: On Tetris and Reimplementation C++: Breakout C++: Beginning Game Programming v2.0 C++: Tetris tutorial in C++ platform independent focused in game logic for beginners C++: Remaking Cavestory in C++ [video] C++: Reconstructing Cave Story [video] C++: Space Invaders from Scratch C#: Learn C# by Building a Simple RPG C#: Creating a Roguelike Game in C# C#: Build a C#/WPF RPG Go: Games With Go [video] Java: 3D Game Development with LWJGL 3 JavaScript: 2D breakout game using Phaser JavaScript: How to Make Flappy Bird in HTML5 With Phaser JavaScript: Developing Games with React, Redux, and SVG JavaScript: Build your own 8-Ball Pool game from scratch [video] JavaScript: How to Make Your First Roguelike JavaScript: Think like a programmer: How to build Snake using only JavaScript, HTML \u0026amp; CSS Lua: BYTEPATH Python: Developing Games With PyGame Python: Making Games with Python \u0026amp; Pygame [pdf] Python: The Complete Roguelike Tutorial [video] Python: Roguelike Tutorial Revised Ruby: Developing Games With Ruby Ruby: Ruby Snake Rust: Adventures in Rust: A Basic 2D Game Rust: Roguelike Tutorial in Rust + tcod  Build your own Git  Haskell: Reimplementing “git clone” in Haskell from the bottom up JavaScript: Gitlet JavaScript: Build GIT - Learn GIT Python: Just enough of a Git client to create a repo, commit, and push itself to GitHub Python: Write yourself a Git! Ruby: Rebuilding Git in Ruby  Build your own Network Stack  C: Beej\u0026rsquo;s Guide to Network Programming C: Let\u0026rsquo;s code a TCP/IP stack Ruby: How to build a network stack in Ruby  Build your own Neural Network  C#: Neural Network OCR F#: Building Neural Networks in F# Go: Build a multilayer perceptron with Golang Go: How to build a simple artificial neural network with Go Go: Building a Neural Net from Scratch in Go JavaScript / Java: Neural Networks - The Nature of Code [video] JavaScript: Neural Network implementation in JavaScript, by an example JavaScript: Neural networks from scratch for JavaScript linguists (Part1 — The Perceptron) Python: A Neural Network in 11 lines of Python Python: Implement a Neural Network from Scratch Python: Optical Character Recognition (OCR) Python: Traffic signs classification with a convolutional network Python: Generate Music using LSTM Neural Network in Keras  Build your own Operating System  Assembly: Writing a Tiny x86 Bootloader Assembly: Baking Pi – Operating Systems Development C: Building a software and hardware stack for a simple computer from scratch [video] C: Operating Systems: From 0 to 1 C: The little book about OS development C: Roll your own toy UNIX-clone OS C: Kernel 101 – Let’s write a Kernel C: Kernel 201 – Let’s write a Kernel with keyboard and screen support C: Build a minimal multi-tasking kernel for ARM from scratch C: How to create an OS from scratch C: Malloc tutorial C: Hack the virtual memory C: Learning operating system development using Linux kernel and Raspberry Pi C: Operating systems development for Dummies C++: Write your own Operating System [video] C++: Writing a Bootloader Rust: Writing an OS in Rust  Build your own Physics Engine  C: Video Game Physics Tutorial C++: Game physics series by Allen Chou C++: How to Create a Custom Physics Engine C++: 3D Physics Engine Tutorial [video] C#: TowerFall Physics JavaScript: Build your own basic physics engine in JavaScript JavaScript: How Physics Engines Work JavaScript: Broad Phase Collision Detection Using Spatial Partitioning JavaScript: Build a simple 2D physics engine for JavaScript games  Build your own Programming Language  (any): mal - Make a Lisp Assembly: Jonesforth C: Baby\u0026rsquo;s First Garbage Collector C: Build Your Own Lisp: Learn C and build your own programming language in 1000 lines of code C: Writing a Simple Garbage Collector in C C: C interpreter that interprets itself. C: A C \u0026amp; x86 version of the \u0026ldquo;Let\u0026rsquo;s Build a Compiler\u0026rdquo; by Jack Crenshaw C++: Writing Your Own Toy Compiler Using Flex C++: How to Create a Compiler [video] C++: Kaleidoscope: Implementing a Language with LLVM F#: Understanding Parser Combinators Elixir: Demystifying compilers by writing your own [video] Go: The Super Tiny Compiler Go: Lexical Scanning in Go [video] Haskell: Let\u0026rsquo;s Build a Compiler Haskell: Write You a Haskell Haskell: Write Yourself a Scheme in 48 Hours Haskell: Write You A Scheme Java: Crafting interpreters: A handbook for making programming languages Java: Creating JVM Language JavaScript: The Super Tiny Compiler JavaScript: The Super Tiny Interpreter JavaScript: Little Lisp interpreter JavaScript: How to implement a programming language in JavaScript OCaml: Writing a C Compiler OCaml: Writing a Lisp, the series Pascal: Let\u0026rsquo;s Build a Compiler Python: A Python Interpreter Written in Python Python: lisp.py: Make your own Lisp interpreter Python: Simple Iterator-based Parsing Python: Simple Top-Down Parsing in Python Python: How to Write a Lisp Interpreter in Python Python: Let’s Build A Simple Interpreter Python: Make Your Own Simple Interpreted Programming Language [video] Racket: Beautiful Racket: How to make your own programming languages with Racket Ruby: A Compiler From Scratch Ruby: Markdown compiler from scratch in Ruby Rust: So You Want to Build a Language VM Rust: Learning Parser Combinators With Rust Swift: Building a LISP from scratch with Swift TypeScript: Build your own WebAssembly Compiler  Build your own Regex Engine  C: A Regular Expression Matcher C: Regular Expression Matching Can Be Simple And Fast JavaScript: Build a Regex Engine in Less than 40 Lines of Code JavaScript: How to implement regular expressions in functional javascript using derivatives Perl: How Regexes Work Scala: No Magic: Regular Expressions  Build your own Search Engine  CSS: A search engine in CSS Python: Building a search engine using Redis and redis-py Python: Building a Vector Space Indexing Engine in Python Python: Building A Python-Based Search Engine [video] Python: Making text search learn from feedback Python: Finding Important Words in Text Using TF-IDF  Build your own Shell  C: Tutorial - Write a Shell in C C: Let\u0026rsquo;s build a shell! C: Writing a UNIX Shell C: Build Your Own Shell Go: Writing a simple shell in Go Ruby: A Unix Shell in Ruby Rust: Build Your Own Shell using Rust  Build your own Template Engine  JavaScript: JavaScript template engine in just 20 lines JavaScript: Understanding JavaScript Micro-Templating Python: Approach: Building a toy template engine in Python Python: A Template Engine Ruby: How to write a template engine in less than 30 lines of code  Build your own Text Editor  C: Build Your Own Text Editor C++: Designing a Simple Text Editor Python: Python Tutorial: Make Your Own Text Editor [video] Python: Create a Simple Python Text Editor! Ruby: Build a Collaborative Text Editor Using Rails  Build your own Visual Recognition System  Python: Developing a License Plate Recognition System with Machine Learning in Python Python: Building a Facial Recognition Pipeline with Deep Learning in Tensorflow  Build your own Voxel Engine  C++: Let\u0026rsquo;s Make a Voxel Engine Java: Let\u0026rsquo;s make a voxel engine [video] Java: Java Voxel Engine Tutorial [video]  Build your own Web Search Engine  PHP: Code a Search Engine in PHP Ruby: Write an Internet search engine with 200 lines of Ruby code  Build your own Web Server  C#: Writing a Web Server from Scratch Node.js: Let\u0026rsquo;s code a web server from scratch with NodeJS Streams Node.js: lets-build-express PHP: Writing a webserver in pure PHP Python: A Simple Web Server Python: Let’s Build A Web Server. Python: Web application from scratch Python: Building a basic HTTP Server from scratch in Python Python: Implementing a RESTful Web API with Python \u0026amp; Flask Ruby: Building a simple websockets server from scratch in Ruby  Uncategorized  (any): From NAND to Tetris: Building a Modern Computer From First Principles Alloy: The Same-Origin Policy C: How to Write a Video Player in Less Than 1000 Lines C: Learn how to write a hash table in C C: The very basics of a terminal emulator C: Write a System Call C: Sol - An MQTT broker from scratch C++: Build your own VR headset for $100 C++: How X Window Managers work and how to write one C++: Writing a Linux Debugger C++: How a 64k intro is made C#: C# Networking: Create a TCP chater server, TCP games, UDP Pong and more C#: Loading and rendering 3D skeletal animations from scratch in C# and GLSL Clojure: Building a spell-checker Java: How to Build an Android Reddit App [video] JavaScript: Build Your Own Module Bundler - Minipack JavaScript: Learn JavaScript Promises by Building a Promise from Scratch JavaScript: Implementing promises from scratch (TDD way) JavaScript: Implement your own — call(), apply() and bind() method in JavaScript JavaScript: JavaScript Algorithms and Data Structures JavaScript: How to Make an Evolutionary Tetris AI [video] JavaScript: Build a ride hailing app with React Native Kotlin: Build Your Own Cache Nim: Writing a Redis Protocol Parser Nim: Writing a Build system Nim: Writing a MiniTest Framework Nim: Writing a DMIDecode Parser Nim: Writing a INI Parser Nim: Writing a Link Checker Nim: Writing a URL Shortening Service Node.js: Build a static site generator in 40 lines with Node.js Node.js: Building A Simple Single Sign On(SSO) Server And Solution From Scratch In Node.js. Node.js: How to create a real-world Node CLI app with Node PHP: Write your own MVC from scratch in PHP  PHP: Make your own blog PHP: Modern PHP Without a Framework Python: Build a Deep Learning Library [video] Python: How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes Python: Continuous Integration System Python: Recommender Systems in Python: Beginner Tutorial Python: Write SMS-spam detector with Scikit-learn Python: A Simple Content-Based Recommendation Engine in Python Python: Stock Market Predictions with LSTM in Python Python: Build your own error-correction fountain code with Luby Transform Codes Python: Building a simple Generative Adversial Network (GAN) using Tensorflow Python: Learn ML Algorithms by coding: Decision Trees Python: JSON Decoding Algorithm Ruby: A Pedometer in the Real World Ruby: Creating a Linux Desktop application with Ruby Rust: Let\u0026rsquo;s build a browser engine Rust: Building a DNS server in Rust Rust: Writing Scalable Chat Service from Scratch TypeScript: Tiny Package Manager: Learns how npm or Yarn works  ","excerpt":"License \nTo the extent possible under law, Daniel Stefanovic has waived all copyright and related or …","ref":"/docs/swiss-knives/build-your-own/","title":"Build Your Own"},{"body":"","excerpt":"","ref":"/docs/cloud/","title":"Cloud"},{"body":"","excerpt":"","ref":"/docs/data/dataset/","title":"Data Set"},{"body":"","excerpt":"","ref":"/docs/coding/functional-coding/","title":"Functional Coding"},{"body":"\n Smart Job Searching App for Myself X-Ray Imaging Diagnostics PubMed Literature Search Variant Ranker  ","excerpt":"\n Smart Job Searching App for Myself X-Ray Imaging Diagnostics PubMed Literature Search Variant …","ref":"/docs/web/my-app/","title":"My Apps"},{"body":"\nData Privacy The basic requirement is that the owners of the data should\n know  what is collected what it will be used for   be able to  view it ask for any part of it to be corrected or deleted completely.    Companies that use use the data\n are responsible for its safekeeping should not share it without the authorization of the original owner  Data Sanitizer Personal data should be sanitized by hiding all the personal details.\n Anonymization is not enough  e.g. Fileds such as birth date and zip code are informative    Data Diversity  Machine learning programs are trained on data collected in the past, when there may have been lack of diversity  e.g. a bank may have had more men than women as customers in the past    Explainable Artifical Intelligence (XAI)  We want models to be written down in a form understandable by human. The experts in that area can access and analyze the model.  ","excerpt":"Data Privacy The basic requirement is that the owners of the data should\n know  what is collected …","ref":"/docs/data/privacy/","title":"Privacy and Security"},{"body":"Features should be treated as first-class entities Ref  The Feature Store - Jim Dowling  ","excerpt":"Features should be treated as first-class entities Ref  The Feature Store - Jim Dowling  ","ref":"/docs/machinelearning/models/feature/feature-stores/","title":"Feature Stores"},{"body":"\nPolicy Gradient Methods RL vs. Supervised Methods Connections between supervised learning and reinforcement learning (Source)\nThe Big Picture The policy gradient method will iteratively amend the policy network weights to:\n make (state, action) pairs that resulted in positive return more likely, 👍 make (state, action) pairs that resulted in negative return less likely. ⬇️  Reinforce REINFORCE increases the probability of \u0026ldquo;good\u0026rdquo; actions and decreases the probability of \u0026ldquo;bad\u0026rdquo; actions. (Source)\nAlgorithm   Our goal is to find the values of the weights $\\theta$ in the neural network that maximize the expected return $U$.\n $U(\\theta) = \\sum_\\tau P(\\tau; \\theta)R(\\tau)$, where $\\tau$ is an arbitrary trajectory (a sequence of states and actions) One way to determine the value of $\\theta$ that maximizes this function is through gradient ascent. Once we know how to calculate or estimate this gradient, we can repeatedly apply this update step, in the hopes that $\\theta$ converges to the value that maximizes $U(\\theta)$.    $\\theta \\leftarrow \\theta + \\alpha \\color{#af8dc3} {\\nabla_\\theta U(\\theta)} $\n $\\alpha$ is the step size that is generally allowed to decay over time.    Estimate the gradient for one trajectory\n   Collect an episode and trajectory $\\tau =$ a full episode    Change the weights of the policy network  $ \\color{#af8dc3} {\\nabla_\\theta U(\\theta)} \\color{black} \\approx \\color{#af8dc3} {\\hat{g}} \\color{black} := \\color{#1b7837} {\\sum_{t=0} ^H} \\color{black}\\nabla_\\theta log\\color{blue}{\\pi_\\theta} \\color{black} {(}\\color{#1b7837} {a_t|s_t}\\color{black}) R(\\color{#1b7837} {\\tau} \\color{black})$  $ \\color{black}\\nabla_\\theta log\\color{blue}{\\pi_\\theta} \\color{black} {(}\\color{#1b7837} {a_t|s_t}\\color{black}{)} $: direction of steepest increase of the $log$ probability of selecting action $a_t$ from state $s_t$   $R(\\color{#1b7837} {\\tau} \\color{black})$: cumulative reward  If $\\color{green}{Won}$: $R = +1$,  by taking a small step into the gradient we can increase the probability of each $\\color{#1b7837} {(S, a)}$ combination 👍   If $\\color{red}{Lost}$: $R=-1$:  by taking a small step from the gradient we can decrease the probability of each $\\color{#1b7837} {(S, a)}$ combination ⬇️            Using $\\color{blue}{m}$ trajectories to estimate the gradient $ \\color{#af8dc3} {\\nabla_\\theta U(\\theta)}$\n   Use the policy $\\color{blue}{\\pi_\\theta}$ to collect $m$ trajectories ${\\tau^{(1)}, \\tau^{(2)}, \u0026hellip; \\tau^{(m)}}$ with horizon $H$ (the last time step)  therefore, the $i$-th trajectory is $ \\color{#1b7837} {\\tau^{(i)}} \\color{black} = (\\color{#1b7837} {{s_0}^{(i)}, {a_0}^{(i)}, \u0026hellip;, {s_H}^{(i)}, {a_H}^{(i)}, {s_{H+1}}^{(i)} }) $      Estimate the gradient  trajectory $\\tau \\le$ a full episode $ \\color{#af8dc3} {\\nabla_\\theta U(\\theta)} \\color{black} \\approx \\color{#af8dc3} {\\hat{g}} \\color{black} := \\color{blue} {\\frac{1}{m} \\sum_{i=1} ^m} \\color{#1b7837} {\\sum_{t=0} ^H} \\color{black}\\nabla_\\theta log\\color{blue}{\\pi_\\theta} \\color{black} {(}\\color{#1b7837} {a_t^{(i)}|s_t^{(i)}}\\color{black}) R(\\color{#1b7837} {\\tau^{(i)}} \\color{black})$      Update the weights of the policy:  $\\theta \\leftarrow \\theta + \\alpha \\color{#af8dc3} {\\hat{g}} $      Loop over steps 1-3.      Continuous Action Spaces   For an environment with a continuous action space, the corresponding policy network could have an output layer that parametrizes a continuous probability distribution.\n  For instance, assume the output layer returns the mean \\muμ and variance $\\sigma^2$ of a normal distribution\n  Then in order to select an action, the agent needs only to pass the most recent state $s_t$ as input to the network, and then use the output mean $\\mu$ and variance $\\sigma^2$ to sample from the distribution $a_t\\sim\\mathcal{N}(\\mu, \\sigma^2)$\n  This should work in theory, but it\u0026rsquo;s unlikely to perform well in practice! To improve performance with continuous action spaces, we\u0026rsquo;ll have to make some small modifications to the REINFORCE algorithm\n  Probability density function corresponding to normal distribution (Source: Wikipedia)\n(Optional) Derivation Read  Deep Reinforcement Learning: Pong from Pixels \u0026ndash; Andrej Karpathy  ","excerpt":"Policy Gradient Methods RL vs. Supervised Methods Connections between supervised learning and …","ref":"/docs/machinelearning/courses/reinforcement-learning/c3-policy/p02-gradient/","title":"Policy Gradient"},{"body":"\nHuman-level control through deep reinforcement learning  This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.\n Deep Q-network (DQN)  Combine reinforcement learning with deep neural networks. Deep convolutional network  which uses hierarchical layers of tiled convolutional filters to mimic the effects of receptive fields—inspired by Hubel and Wiesel’s seminal work on feedforward processing in early visual cortex thereby exploiting the local spatial correlations present in images and building in robustness to natural transformations such as changes of viewpoint or scale.    Ref  Mnih, Volodymyr, et al. \u0026ldquo;Human-level control through deep reinforcement learning\u0026rdquo; Nature518.7540 (2015): 529.  ","excerpt":"Human-level control through deep reinforcement learning  This work bridges the divide between …","ref":"/docs/machinelearning/courses/reinforcement-learning/c2-value/paper-dqn/","title":"DQN Paper"},{"body":"\nThe Settings  Agent\u0026rsquo;s Actions: Goal is to maximize expected cumulative reward Env Rewards  The agent-environment interaction in rl (Source: Sutton and Barto, 2017)\n The reinforcement learning (RL) framework is characterized by an agent learning to interact with its environment. At each time step, the agent receives the environment\u0026rsquo;s state (the environment presents a situation to the agent), and the agent must choose an appropriate action in response. One time step later, the agent receives a reward (the environment indicates whether the agent has responded appropriately to the state) and a new state. All agents have the goal to maximize expected cumulative reward, or the expected sum of rewards attained over all time steps.   Episodic vs. Continuing Tasks A task is an instance of the reinforcement learning (RL) problem.\n Episodic task: tasks with a well-defined starting and ending point.  In this case, we refer to a complete sequence of interaction, from start to finish, as an episode Episodic tasks come to an end whenever the agent reaches a terminal state About past life regression and reincarnation 😳 Game   Continuing Tasks: interaction continues for ever, without limit 😬  Stocks    The Reward Hypothesis All goals can be framed as the maximization of (expected) cumulative reward.\n Problem of sparse rewards: when the reward signal is largely uninformative Cumulative reward  The goal of the agent at time step T: maximize accumulative reward The robot learns to move a bit slowly to sacrifice a little bit of reward but it will payoff because it will avoid falling for longer and collect higher accumulative reward   Discounted return: we give a discount rate $\\gamma \\in (0,1)$ to Reward at each step to avoid having to look too far into the limitless future  For larger values of $\\gamma$, the agent cares more about the distant future. Smaller values of $\\gamma$ result in more extreme discounting $\\gamma = 0$: agent only cares about most immediate reward, not caring about the future $\\gamma = 1$: the return is not discounted. This becomes a pretty difficult task if the future is limitless Most relevant for selection of actions in continuing tasks Note: with or without the discount rate, the goal of agent is always the same    Markov Decision Process A (finite) Markov Decision Process (MDP) is defined by:\n   a (finite) set of Action $A$: space of all possible actions available to the agent    a (finite) set of States $S$: all nonterminal states    at a dicount rate $\\gamma \\in (0,1)$   $G_t = R_{t+1} + \\gamma R_{t+2} + {\\gamma}^2 R_{t+3} +\u0026hellip;$ A common choice: $\\gamma = 0.9$    a (finite) set of Rewards $\\gamma $    the one-step dynamics of the environment: $p(s',\\gamma |s,a) = \\Bbb{P}(S_{t+1} = s', R_{t+1} =\\gamma | S_t =s, A_t = a)$    The agent knows 1-3 and does not know 4 and 5. Therefore, the agent needs to learn from interaction to accomplish its goal.\nA MDP Problem For a can-picking recycling robot:\n  He\\gamma e is a method that the environment could use to decide the state and reward, at any time step.\n $A$:  Search cans Wait Recharge   $S$:  High battery Low battery      Say at an arbitrary time step t, the state of the robot\u0026rsquo;s battery is high ($S_t = \\text{high}$). Then, in response, the agent decides to search ($A_t = \\text{search}$). You learned in the previous concept that in this case, the environment responds to the agent by flipping a theoretical coin with 70% probability of landing heads.\n If the coin lands heads, the environment decides that the next state is high ($S_{t+1} = \\text{high}$), and the reward is $(R_{t+1} = 4$). If the coin lands tails, the environment decides that the next state is low ($S_{t+1} = \\text{low}$), and the reward is $(R_{t+1} = 4)$. At an arbitrary time step $t$, the agent-environment interaction has evolved as a sequence of states, actions, and rewards. When the environment responds to the agent at time step $t+1$,  it considers only the state and action at the previous time step ($S_t, A_t$) it does not consider any of ${ R_0, \\ldots, R_t }$      For the case that $S_t = \\text{high}$, and $A_t = \\text{search}$, when the environment responds to the agent at the next time step, - with 70% probability, the next state is high and the reward is 4. In other words, $p(high,4|high,search) = \\Bbb{P}(S_{t+1} = high, R_{t+1} = 4 | S_t = high, A_t = search) = 0.7$\n  Consider the following probabilities,\n which of the above probabilities is equal to 0? (1,3,5) Which of the above probabilities is equal to 1? (2,4)  (1) $p(\\text{low}, 1|\\text{low},\\text{search})$ (2) $p(\\text{high}, 0|\\text{low},\\text{recharge})$ (3) $p(\\text{high}, 1|\\text{low},\\text{wait})$ (4) $p(\\text{high}, 1|\\text{high},\\text{wait})$ (5) $p(\\text{high}, 1|\\text{high},\\text{search})$      Image from Udacity nd893\nOpenAI Gym  Table of environments  Quiz  Consider an agent who would like to learn to escape a maze. Which reward signals will encourage the agent to escape the maze as quickly as possible?   Who is Markov? Andrey Markov (1856–1922) was a Russian mathematician best known for his work on stochastic processes. A primary subject of his research later became known as Markov chains and Markov processes. Andrey Markov, image from Wikipedia\n","excerpt":"The Settings  Agent\u0026rsquo;s Actions: Goal is to maximize expected cumulative reward Env Rewards  The …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f02-rl-problem/","title":"RL Problem"},{"body":"\nUdacity Deep Reinforcement Learning Trainers  Arthur Juliani, Deep Learning Researcher at Unity Avilay Parekh, Principal Machine Learning Engineer at Unity Melody Guan, Machine Learning Ph.D. at Stanford University Peter Welinder, Research Scientist at OpenAI Vincent Gao, Software Engineer (Machine Learning) at Unity  Estimated Time  4 months: at 10-15 hrs/week Total: 160-240 hrs  Contents 1. Foundations of Reinforcement Learning  how to define real-world problems as Markov Decision Processes (MDPs), so that they can be solved with reinforcement learning. implement classical methods such as SARSA and Q-learning to solve several environments in OpenAI Gym  2. Value-Based Methods  how to leverage neural networks when solving complex problems using the Deep Q-Networks (DQN) algorithm double Q-learning prioritized experience replay dueling networks create an artificially intelligent game-playing agent that can navigate a spaceship use a Gazebo simulation to train a rover to navigate an environment without running into walls  3. Policy-Based Methods  Proximal Policy Optimization (PPO) Advantage Actor-Critic (A2C) Deep Deterministic Policy Gradients (DDPG) optimization techniques such as evolution strategies and hill climbing how to apply deep reinforcement learning techniques to finance and explore an algorithm for optimal execution of portfolio transactions  4. Multi-Agent Reinforcement Learning  Most of reinforcement learning is concerned with a single agent that seeks to demonstrate proficiency at a single task. In this agent\u0026rsquo;s environment, there are no other agents. However, if we\u0026rsquo;d like our agents to become truly intelligent, they must be able to communicate with and learn from other agents. In the final part of this nanodegree, we will extend the traditional framework to include multiple agents. Monte Carlo Tree Search (MCTS), the skills behind DeepMind\u0026rsquo;s AlphaZero  Projects   Project 1: Navigation In the first project, you’ll leverage neural networks to train an agent to navigate a virtual world and collect as many yellow bananas as possible while avoiding blue banana\n  Project 2: Continuous Control In the second project, you’ll write an algorithm to train a robotic arm to reach moving target positions.\n  Project 3: Collaboration and Competition In the final project of the Nanodegree program, you’ll design your own algorithm to train a pair of agents to play tennis.\n  Tools   All of the projects in this Nanodegree program use the rich simulation environments from the Unity Machine Learning Agents (ML-Agents) software development kit (SDK). It is a flexible and intuitive framework which enables:\n Academic and industry researchers to study complex behaviors from visual content and realistic physics Industrial and enterprise researchers to implement large-scale parallel training regimes for robotics, autonomous vehicles, and other industrial applications Game developers to tackle challenges, such as using agents to dynamically adjust the game-difficulty level    Tanks\n  Installation of tools  ml-agents  Installation   Gazebo OpenAI Gym  GitHub    Reach out  knowledge chat Udacity Services  Resource Center Coaching Events    Ref  Udacity Course Page Udacity GitHub: deep-reinforcement-learning Deep Reinforcement Learning Nanodegree Program: What You’ll Learn cheatsheet Student curated links The Complete Reinforcement Learning Dictionary  Books to read  Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G.. This book is a classic text with an excellent introduction to reinforcement learning fundamentals. Grokking Deep Reinforcement Learning by Miguel Morales  Good to know  Learn by doing Data from nearly 100,000 Udacity graduates show that commitment and persistence are the highest predictors of whether or not a student will graduate.  ","excerpt":"Udacity Deep Reinforcement Learning Trainers  Arthur Juliani, Deep Learning Researcher at Unity …","ref":"/docs/machinelearning/courses/reinforcement-learning/syllabus/","title":"Syllabus"},{"body":"\nJAX  Autograd and XLA\n  GitHub Doc: Autodiff Cookbook Try JAX on Cloud TPUs in Colab Talk by Skye Wanderman-Milne  Slides: Accelerated machine-learning researchvia composable function transformationsin Python    What is JAX?  Numpy on GPU  Leverages XLA compiler  XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.     Autodifferentiation capability  How to get gradients of some loss function your code computes with respect to you input parameters    What is Elegy? A higher level of JAX.\n Elegy  Read more  Plugging Into JAX  DL Frameworks\n From PyTorch to JAX: towards neural net frameworks that purify stateful code  Jax vs PyTorch\n","excerpt":"JAX  Autograd and XLA\n  GitHub Doc: Autodiff Cookbook Try JAX on Cloud TPUs in Colab Talk by Skye …","ref":"/docs/machinelearning/frameworks/flax/jax/","title":"JAX"},{"body":"","excerpt":"","ref":"/docs/math/machinelearning/activation/","title":"Activation"},{"body":"\n","excerpt":"","ref":"/docs/cloud/aws/","title":"AWS"},{"body":"\nHow to detect and remove outliers?  Remove outliers by interquartile range (IQR)  def remove_outliers_by_iqr(df,colname,iqr_threshold): df_drop_na = df[df[colname].notnull()] threshold = float(iqr_threshold) Q3 = df_drop_na[colname].quantile(0.75) Q1 = df_drop_na[colname].quantile(0.25) IQR = Q3 - Q1 df_drop_na_qt = df_drop_na[~((df_drop_na[colname] \u0026lt; (Q1 - threshold * IQR)) |(df_drop_na[colname] \u0026gt; (Q3 + threshold * IQR)))] number_nas = len(df.index) - df_drop_na[colname].count() number_outliers = df_drop_na[colname].count() -df_drop_na_qt[colname].count() print(\u0026#39;Dataframe shape before removing outliers: \u0026#39;, df.shape) print(number_nas, \u0026#39;rows where column\u0026#39; ,colname,\u0026#39;are NULL are removed\u0026#39;) print(\u0026#39;Dataframe shape after removing NAs in the column\u0026#39;, colname,\u0026#39;:\u0026#39;, df_drop_na.shape) print(number_outliers, \u0026#39;outliers are removed\u0026#39;) print(\u0026#39;Dataframe shape after removing NAs and ourliers in the column\u0026#39;, colname, \u0026#39;by\u0026#39;,iqr_threshold,\u0026#39;* IQR:\u0026#39;, df_drop_na_qt.shape) return df_drop_na_qt df2= remove_outliers_by_iqr(df,\u0026#39;area\u0026#39;,1.5)  Remove outliers by Z score  def remove_outliers_by_z(df,colname,z_score_threshold): df_drop_na = df[df[colname].notnull()] from scipy import stats import numpy as np z = np.abs(stats.zscore(df_drop_na[colname])) df_drop_na_zoutlier =df_drop_na[(z \u0026lt; float(z_score_threshold))] number_nas = len(df.index) - df_drop_na[colname].count() number_outliers = df_drop_na[colname].count() -df_drop_na_zoutlier[colname].count() print(\u0026#39;Dataframe shape before removing outliers: \u0026#39;, df.shape) print(number_nas, \u0026#39;rows where column\u0026#39; ,colname,\u0026#39;are NULL are removed\u0026#39;) print(\u0026#39;Dataframe shape after removing NAs in the column\u0026#39;, colname, \u0026#39;:\u0026#39;, df_drop_na.shape) print(number_outliers, \u0026#39;outliers are removed\u0026#39;) print(\u0026#39;Dataframe shape after removing NAs and ourliers in the column\u0026#39;, colname, \u0026#39;by Z score threshold\u0026#39;,z_score_threshold,\u0026#39;:\u0026#39;, df_drop_na_zoutlier.shape) return df_drop_na_zoutlier df3= remove_outliers_by_z(df,\u0026#39;area\u0026#39;,3)  What kind of outliers should be removed?  Wrong calculation, these can be identified as Outliers should be dropped but at the same time you might want to correct them too, as they change the level of data and cause issues when you model your data.  Decomposition Based Detection  sckit-lego  Image from sckit-lego\nDensity Based Detection Gaussian Mixture\nWhat kind of outliers should not be removed? Read more   Outlier removal clustering\n  1\n  2\n  3\n  ","excerpt":"How to detect and remove outliers?  Remove outliers by interquartile range (IQR)  def …","ref":"/docs/coding/functional-coding/python/outliers/","title":"Outliers"},{"body":"\n Adversarial Latent Autoencoders  ","excerpt":"\n Adversarial Latent Autoencoders  ","ref":"/docs/machinelearning/models/deep-learning/gans/","title":"GANs"},{"body":"","excerpt":"","ref":"/docs/math/machinelearning/","title":"Machine Learning"},{"body":"\nStory Proof  Proof by interpretation  Count the same thing in two ways:  $\\binom{n}{k} = \\binom{n}{n-k}$ $ k\\binom{n}{k} = n\\binom{n-1}{k-1}$  Story proof:  Picking $k$ Cabinet members out of $n$ people, with one selected as the Prime Minister the same as picking one person from $n$ people as the Prime Minister, the rest as $k-1$ the Cabinet members     Vandermonde\u0026rsquo;s identity $\\binom{m+n}{k} = \\sum_{j=0}^{k}\\binom{m}{j}\\binom{n}{k-j}$  Story proof:  Picking $k$ people from $m+n$ places = the same as picking $j$ people from place $m$, $k-j$ people from place $n$           Ref  Alexandre-Théophile Vandermonde  Thoughts  Labeling people is dangerous, but labeling events in a probability problem is important Think about the subtle differences between probabilities of  choosing one people in a team from four people  $P = \\binom{4}{1}$   choosing three people in a team from four people  $P = \\binom{4}{3}$   choosing one people in a team, three people in another team from a total of four people  $P = \\binom{4}{1} = \\binom{4}{3}$   choosing two people in a team, two people in another team from a total of four people  $P = \\frac{\\binom{4}{2}}{2}$      ","excerpt":"\nStory Proof  Proof by interpretation  Count the same thing in two ways:  $\\binom{n}{k} = …","ref":"/docs/math/intro/probability/s110_l02_story_proofs_axioms_probability/","title":"Story Proofs, Axioms of Probability"},{"body":"\n","excerpt":"","ref":"/docs/computer_science/software-engineering/","title":"Software Engineering"},{"body":"\nCallbacks   tf.keras.callbacks.ReduceLROnPlateau\n Reduce learning rate when a metric has stopped improving. Example  reduce_lr = ReduceLROnPlateau(monitor=\u0026#39;val_loss\u0026#39;, factor=0.2,patience=5, min_lr=0.001) model.fit(X_train, Y_train, callbacks=[reduce_lr])   ","excerpt":"\nCallbacks   tf.keras.callbacks.ReduceLROnPlateau\n Reduce learning rate when a metric has stopped …","ref":"/docs/machinelearning/frameworks/tensorflow/callbacks/","title":"Callbacks"},{"body":"\nTutorial  TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras  ","excerpt":"\nTutorial  TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras  ","ref":"/docs/machinelearning/frameworks/tensorflow/","title":"Tensorflow"},{"body":"\nTensorPipe A high Performance Tensorflow Data Pipeline with State of Art Augmentations and low level optimizations.\n GitHub How to write Efficient DataPipeline in Keras/Tensorflow with TensorPipe   Developing DataPipeline which is flexible and high performing is a painful task in TensorFlow.\nState of Art Augmentations are written in a very clumsy way and it is not necessary you will find a version of it in Tensorflow.\nTensorPipe fills this “Gap” with high performance, flexible and loaded with all SOTA augmentations available in the computer vision domain in one package written in core TensorFlow.\n ","excerpt":"TensorPipe A high Performance Tensorflow Data Pipeline with State of Art Augmentations and low level …","ref":"/docs/machinelearning/frameworks/tensorflow/tensorpipe/","title":"TensorPipe"},{"body":"\n Course Link\n 1. Use an Array to Store a Collection of Data  One-dimensional array  let simpleArray =[1, \u0026#34;plains hymn\u0026#34;, true,null,undefined]; // Change this line  // Access the length property console.log(simpleArray.length); // logs 5  multi-dimensional array arrays are also capable of storing complex objects.  let complexArray = [ [ { one: 1, two: 2 }, { three: 3, four: 4 } ], [ { a: \u0026#34;a\u0026#34;, b: \u0026#34;b\u0026#34; }, { c: \u0026#34;c\u0026#34;, d: \u0026#34;d\u0026#34; } ] ]; \n2. Access an Array\u0026rsquo;s Contents Using Bracket Notation The fundamental feature of any data structure is, of course, the ability to not only store data, but to be able to retrieve that data on command.\nlet myArray = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;]; // Only change code below this line myArray[1] =\u0026#34;bd\u0026#34; // Only change code above this line console.log(myArray); \n3. Add Items to an Array with push() and unshift() Both methods take one or more elements as parameters and add those elements to the array the method is being called on.\n push() method adds elements to the end of an array unshift() adds elements to the beginning  let twentyThree = \u0026#39;XXIII\u0026#39;; let romanNumerals = [\u0026#39;XXI\u0026#39;, \u0026#39;XXII\u0026#39;]; romanNumerals.unshift(\u0026#39;XIX\u0026#39;, \u0026#39;XX\u0026#39;); // now equals [\u0026#39;XIX\u0026#39;, \u0026#39;XX\u0026#39;, \u0026#39;XXI\u0026#39;, \u0026#39;XXII\u0026#39;]  romanNumerals.push(twentyThree); // now equals [\u0026#39;XIX\u0026#39;, \u0026#39;XX\u0026#39;, \u0026#39;XXI\u0026#39;, \u0026#39;XXII\u0026#39;, \u0026#39;XXIII\u0026#39;]Notice that we can also pass variables, which allows us even greater flexibility in dynamically modifying our array\u0026#39;s data. \n4. Remove Items from an Array with pop() and shift() Both push() and unshift() have corresponding methods that are nearly functional opposites: pop() and shift()\nlet greetings = [\u0026#39;whats up?\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;see ya!\u0026#39;]; greetings.pop(); // now equals [\u0026#39;whats up?\u0026#39;, \u0026#39;hello\u0026#39;]  greetings.shift(); // now equals [\u0026#39;hello\u0026#39;]  // return the value of the removed element let popped = greetings.pop(); // returns \u0026#39;hello\u0026#39; // greetings now equals [] \n5. Remove Items Using splice()   splice() allows us to do just that: remove any number of consecutive elements from anywhere in an array.\n  splice() can take up to 3 parameters, but for now, we\u0026rsquo;ll focus on just the first 2.\n first parameter represents the index on the array from which to begin removing elements, while the second parameter indicates the number of elements to delete. For example:    let array = [\u0026#39;today\u0026#39;, \u0026#39;was\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;so\u0026#39;, \u0026#39;great\u0026#39;]; array.splice(2, 2); // remove 2 elements beginning with the 3rd element // array now equals [\u0026#39;today\u0026#39;, \u0026#39;was\u0026#39;, \u0026#39;great\u0026#39;] let array = [\u0026#39;I\u0026#39;, \u0026#39;am\u0026#39;, \u0026#39;feeling\u0026#39;, \u0026#39;really\u0026#39;, \u0026#39;sleepy\u0026#39;]; let newArray = array.splice(3, 2); // newArray equals [\u0026#39;really\u0026#39;, \u0026#39;sleepy\u0026#39;] // array equals [ \u0026#39;I\u0026#39;, \u0026#39;am\u0026#39;, \u0026#39;feeling\u0026#39; ] // Use splice() to remove elements from arr, so that it only contains elements that sum to the value of 10 const arr = [2, 4, 5, 1, 7, 5, 2, 1]; // Only change code below this line arr.splice(1,4) // Only change code above this line console.log(arr); \n6. Add Items Using splice() const numbers = [10, 11, 12, 12, 15]; const startIndex = 3; const amountToDelete = 1; numbers.splice(startIndex, amountToDelete, 13, 14); // the second entry of 12 is removed, and we add 13 and 14 at the same index console.log(numbers); // returns [ 10, 11, 12, 13, 14, 15 ] \n7. Add Items Using splice() You can use the third parameter, comprised of one or more element(s), to add to the array. This can be incredibly useful for quickly switching out an element, or a set of elements, for another.\nconst numbers = [10, 11, 12, 12, 15]; const startIndex = 3; const amountToDelete = 1; numbers.splice(startIndex, amountToDelete, 13, 14); // the second entry of 12 is removed, and we add 13 and 14 at the same index console.log(numbers); // returns [ 10, 11, 12, 13, 14, 15 ] \n8. Copy Array Items Using slice()  slice(), rather than modifying an array, copies, or extracts, a given number of elements to a new array, leaving the array it is called upon untouched. slice() takes only 2 parameters  the first is the index at which to begin extraction the second is the index at which to stop extraction (extraction will occur up to, but not including the element at this index).   Example 1  let weatherConditions = [\u0026#39;rain\u0026#39;, \u0026#39;snow\u0026#39;, \u0026#39;sleet\u0026#39;, \u0026#39;hail\u0026#39;, \u0026#39;clear\u0026#39;]; let todaysWeather = weatherConditions.slice(1, 3); // todaysWeather equals [\u0026#39;snow\u0026#39;, \u0026#39;sleet\u0026#39;]; // weatherConditions still equals [\u0026#39;rain\u0026#39;, \u0026#39;snow\u0026#39;, \u0026#39;sleet\u0026#39;, \u0026#39;hail\u0026#39;, \u0026#39;clear\u0026#39;]  Example 2  function forecast(arr) { // Only change code below this line  arr = arr.slice(2,4) return arr; } // Only change code above this line console.log(forecast([\u0026#39;cold\u0026#39;, \u0026#39;rainy\u0026#39;, \u0026#39;warm\u0026#39;, \u0026#39;sunny\u0026#39;, \u0026#39;cool\u0026#39;, \u0026#39;thunderstorms\u0026#39;])); \n9. Copy an Array with the Spread Operator ...  Example 1  let thisArray = [true, true, undefined, false, null]; let thatArray = [...thisArray]; // thatArray equals [true, true, undefined, false, null] // thisArray remains unchanged, and is identical to thatArray  Example 2  function copyMachine(arr, num) { let newArr = []; while (num \u0026gt;= 1) { // Only change code below this line  newArr.push([...arr]); // Only change code above this line  num--; } return newArr; } console.log(copyMachine([true, false, true], 2)); \n10. Combine Arrays with the Spread Operator ","excerpt":"Course Link\n 1. Use an Array to Store a Collection of Data  One-dimensional array  let simpleArray …","ref":"/docs/coding/functional-coding/javascript/course/data-structure/array/","title":"Recap Array"},{"body":"\n Course Link\n 1. Use the JavaScript Console to Check the Value of a Variable   Both Chrome (Ctrl Shift K)and Firefox (Command Option K)have excellent JavaScript consoles, also known as DevTools, for debugging your JavaScript.\n  The console.log() method, which \u0026ldquo;prints\u0026rdquo; the output of what\u0026rsquo;s within its parentheses to the console, will likely be the most helpful debugging tool.\n Placing it at strategic points in your code can show you the intermediate values of variables. It\u0026rsquo;s good practice to have an idea of what the output should be before looking at what it is. Having check points to see the status of your calculations throughout your code will help narrow down where the problem is.    Example 1\n  let a = 5; let b = 1; a++; // Only change code below this line console.log(a) let sumAB = a + b; console.log(sumAB);  Example 2  // Open your browser console. let output = \u0026#34;Get this to log once in the freeCodeCamp console and twice in the browser console\u0026#34;; // Use console.log() to print the output variable. console.log(output) // Run the tests to see the difference between the two consoles.  // Now, add console.clear() before your console.log() to clear the browser console, and pass the tests. console.clear() \n2. Use typeof to Check the Type of a Variable  You can use typeof to check the data structure, or type, of a variable. This is useful in debugging when working with multiple data types. If you think you\u0026rsquo;re adding two numbers, but one is actually a string, the results can be unexpected. Type errors can lurk in calculations or function calls. Be careful especially when you\u0026rsquo;re accessing and working with external data in the form of a JavaScript Object Notation (JSON) object. JavaScript recognizes B2N2SOU   Six primitive (immutable) data types:\n Boolean Number Null String Symbol (new with ES6) Undefined    One type for mutable items\n Object  arrays are technically a type of object.        console.log(typeof \u0026#34;\u0026#34;); // outputs \u0026#34;string\u0026#34; console.log(typeof 0); // outputs \u0026#34;number\u0026#34; console.log(typeof []); // outputs \u0026#34;object\u0026#34; console.log(typeof {}); // outputs \u0026#34;object\u0026#34; \n3. Catch Misspelled Variable and Function Names 🕵   The console.log() and typeof methods are the two primary ways to check intermediate values and types of program output.\n  Now it\u0026rsquo;s time to get into the common forms that bugs take. One syntax-level issue that fast typers can commiserate with is the humble spelling error.\n Transposed, missing, or mis-capitalized characters in a variable or function name will have the browser looking for an object that doesn\u0026rsquo;t exist - and complain in the form of a reference error. (JavaScript variable and function names are case-sensitive)    4. Catch Unclosed Parentheses, Brackets, Braces and Quotes 🔒  Another syntax error to be aware of is that all opening parentheses, brackets, curly braces, and quotes have a closing pair 🖇 Forgetting a piece tends to happen when you\u0026rsquo;re  editing existing code inserting items with one of the pair types   Also, take care when nesting code blocks into others, such as  adding a callback function as an argument to a method    One way to avoid this mistake is as soon as the opening character is typed\n immediately include the closing match then move the cursor back between them continue coding  Fortunately, most modern code editors generate the second half of the pair automatically 🍀\n5. Catch Mixed Usage of Single and Double Quotes JavaScript allows the use of both single (') and double (\u0026quot;) quotes to declare a string. Deciding which one to use generally comes down to personal preference, with some exceptions\n Having two choices is great when a string has contractions or another piece of text that\u0026rsquo;s in quotes. Just be careful that you don\u0026rsquo;t close the string too early, which causes a syntax error.  Here are some examples of mixing quotes:\n// These are correct: const grouchoContraction = \u0026#34;I\u0026#39;ve had a perfectly wonderful evening, but this wasn\u0026#39;t it.\u0026#34;; const quoteInString = \u0026#34;Groucho Marx once said \u0026#39;Quote me as saying I was mis-quoted.\u0026#39;\u0026#34;; // This is incorrect: const uhOhGroucho = \u0026#39;I\u0026#39;ve had a perfectly wonderful evening, but this wasn\u0026#39;t it.\u0026#39;;  Of course, it is okay to use only one style of quotes. You can escape the quotes inside the string by using the backslash \\ escape character:  // Correct use of same quotes: const allSameQuotes = \u0026#39;I\\\u0026#39;ve had a perfectly wonderful evening, but this wasn\\\u0026#39;t it.\u0026#39;; let innerHtml = \u0026#34;\u0026lt;p\u0026gt;Click here to \u0026lt;a href=\\\u0026#34;#Home\\\u0026#34;\u0026gt;return home\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026#34;; \n6. Catch Use of Assignment Operator Instead of Equality Operator  Branching programs, i.e. ones that do different things if certain conditions are met, rely on if, else if, and else statements in JavaScript. The condition sometimes takes the form of testing whether a result is equal to a value. This logic is spoken (in English, at least) as \u0026quot;if x equals y, then ...\u0026quot; which can literally translate into code using the =, or assignment operator. This leads to unexpected control flow in your program. As covered in previous challenges, the assignment operator = in JavaScript assigns a value to a variable name. And the == and === operators check for equality (the triple === tests for strict equality, meaning both value and type are the same). Example  The code below assigns x to be 2, which evaluates as true. Almost every value on its own in JavaScript evaluates to true, except what are known as the \u0026ldquo;falsy\u0026rdquo; values: false, 0, \u0026quot;\u0026quot; (an empty string), NaN, undefined, and null.\n   let x = 7; let y = 9; let result = \u0026#34;to come\u0026#34;; if(x === y) { result = \u0026#34;Equal!\u0026#34;; } else { result = \u0026#34;Not equal!\u0026#34;; } console.log(result); // \n7. Catch Missing Open and Closing Parenthesis After a Function Call  When a function or method doesn\u0026rsquo;t take any arguments, you may forget to include the (empty) opening and closing parentheses when calling it. Often times the result of a function call is saved in a variable for other use in your code. This error can be detected by logging variable values (or their types) to the console and seeing that one is set to a function reference, instead of the expected value the function returns.  The variables in the following example are different:\nfunction myFunction() { return \u0026#34;You rock!\u0026#34;; } let varOne = myFunction; // set to equal a function let varTwo = myFunction(); // set to equal the string \u0026#34;You rock!\u0026#34; \n8. Catch Arguments Passed in the Wrong Order When Calling a Function  Continuing the discussion on calling functions, the next bug to watch out for is when a function\u0026rsquo;s arguments are supplied in the incorrect order.  If the arguments are different types, such as a function expecting an array and an integer, this will likely throw a runtime error. If the arguments are the same type (all integers, for example), then the logic of the code won\u0026rsquo;t make sense.   Make sure to supply all required arguments, in the proper order to avoid these issues.  9. Catch Off By One Errors When Using Indexing   Off by one errors (sometimes called OBOE) crop up when you\u0026rsquo;re trying to target a specific index of a string or array (to slice or access a segment), or when looping over the indices of them.\n  JavaScript indexing starts at zero, not one, which means the last index is always one less than the length of the item. If you try to access an index equal to the length, the program may throw an \u0026quot;index out of range\u0026quot; reference error or print undefined.\n  When you use string or array methods that take index ranges as arguments, it helps to read the documentation and understand if they are inclusive (the item at the given index is part of what\u0026rsquo;s returned) or not.\n  Here are some examples of off by one errors:\n  let alphabet = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; let len = alphabet.length; for (let i = 0; i \u0026lt;= len; i++) { // loops one too many times at the end  console.log(alphabet[i]); } for (let j = 1; j \u0026lt; len; j++) { // loops one too few times and misses the first character at index 0  console.log(alphabet[j]); } for (let k = 0; k \u0026lt; len; k++) { // Goldilocks approves - this is just right  console.log(alphabet[k]); } \nToo many bugs? Take a break and listen to a song.        10. Use Caution When Reinitializing Variables Inside a Loop 🔖  Sometimes it\u0026rsquo;s necessary to save information, increment counters, or re-set variables within a loop. A potential issue is when variables either should be reinitialized, and aren\u0026rsquo;t, or vice versa. This is particularly dangerous if you accidentally reset the variable being used for the terminal condition, causing an infinite loop. Printing variable values with each cycle of your loop by using console.log() can uncover buggy behavior related to resetting, or failing to reset a variable. Example 1   The following function is supposed to create a two-dimensional array with m rows and n columns of zeroes. Unfortunately, it\u0026rsquo;s not producing the expected output because the row variable isn\u0026rsquo;t being reinitialized (set back to an empty array) in the outer loop. Fix the code so it returns a correct 3x2 array of zeroes, which looks like [[0, 0], [0, 0], [0, 0]].\n function zeroArray(m, n) { // Creates a 2-D array with m rows and n columns of zeroes  let newArray = []; for (let i = 0; i \u0026lt; m; i++) { let row = []; //a new row will be initialised during each iteration of the outer loop allowing for the desired matrix.  // Adds the m-th row into newArray  for (let j = 0; j \u0026lt; n; j++) { // Pushes n zeroes into the current row to create the columns  row.push(0); } // Pushes the current row, which now has n zeroes in it, to the array  newArray.push(row); } return newArray; } let matrix = zeroArray(3, 2); console.log(matrix); \n11. Prevent Infinite Loops with a Valid Terminal Condition   Loops are great tools when you need your program to run a code block a certain number of times or until a condition is met, but they need a terminal condition that ends the looping. Infinite loops are likely to freeze or crash the browser, and cause general program execution mayhem, which no one wants.\n  There was an example of an infinite loop in the introduction to this section - it had no terminal condition to break out of the while loop inside loopy(). Do NOT call this function!\n  function loopy() { while(true) { console.log(\u0026#34;Hello, world!\u0026#34;); } }  It\u0026rsquo;s the programmer\u0026rsquo;s job to ensure that the terminal condition, which tells the program when to break out of the loop code, is eventually reached.   One error is incrementing or decrementing a counter variable in the wrong direction from the terminal condition. Another one is accidentally resetting a counter or index variable within the loop code, instead of incrementing or decrementing it.   Example  The myFunc() function contains an infinite loop because the terminal condition i != 4 will never evaluate to false (and break the looping) - i will increment by 2 each pass, and jump right over 4 since i is odd to start. Fix the comparison operator in the terminal condition so the loop only runs for i less than or equal to 4.\n   function myFunc() { for (let i = 1; i != 4; i += 2) { console.log(\u0026#34;Still going!\u0026#34;); } } // Fix function myFunc() { for (let i = 1; i \u0026lt;\u0026gt;= 4; i += 2) { console.log(\u0026#34;Still going!\u0026#34;); } } \nImage from imgflip\n","excerpt":"Course Link\n 1. Use the JavaScript Console to Check the Value of a Variable   Both Chrome (Ctrl …","ref":"/docs/coding/functional-coding/javascript/course/debugging/howto/","title":"How to"},{"body":"\n Course Link\n 1. Find Characters with Lazy Matching   A greedy match finds the longest possible part of a string that fits the regex pattern and returns it as a match.\n Defaulft for Regular Expression    A lazy match finds the smallest possible part of the string that satisfies the regex pattern.\n Use ?    Example 1\n  // string \u0026#34;titanic\u0026#34; // A greedy match /t[a-z]*i/ //return titani  // A lazy match /t[a-z]*?i/ //return ti // // return the HTML tag \u0026lt;h1\u0026gt; let text = \u0026#34;\u0026lt;h1\u0026gt;Winter is coming\u0026lt;/h1\u0026gt;\u0026#34;; let myRegex = /\u0026lt;.*?\u0026gt;/; // Change this line let result = text.match(myRegex); \n2. Match Beginning String Patterns  Use the caret character (^) inside a character set to create a negated character set in the form [^thingsThatWillNotBeMatched]. Outside of a character set, the caret is used to search for patterns at the beginning of strings.  let rickyAndCal = \u0026#34;Cal and Ricky both like racing.\u0026#34;; let calRegex = /^Cal/; // Change this line let result = calRegex.test(rickyAndCal); \n3. Match Ending String Patterns  Use $ at the end of the regex  let theEnding = \u0026#34;This is a never ending story\u0026#34;; let storyRegex = /story$/; storyRegex.test(theEnding); // Returns true let noEnding = \u0026#34;Sometimes a story will have to end\u0026#34;; storyRegex.test(noEnding); // Returns false \n4. Match All Letters and Numbers  Use shortcut character classes (shorthand character classes) A shortcut of \\[A-Za-z0-9_]\\ is \\w Example 1  let longHand = /[A-Za-z0-9_]+/; let shortHand = /\\w+/; let numbers = \u0026#34;42\u0026#34;; let varNames = \u0026#34;important_var\u0026#34;; longHand.test(numbers); // Returns true shortHand.test(numbers); // Returns true longHand.test(varNames); // Returns true shortHand.test(varNames); // Returns true  Example 2  // Use the shorthand character class \\w to count the number of alphanumeric characters in various quotes and strings let quoteSample = \u0026#34;The five boxing wizards jump quickly.\u0026#34;; let alphabetRegexV2 = /\\w/g; // Change this line let result = quoteSample.match(alphabetRegexV2).length; \n5. Match Everything But Letters and Numbers  A shortcut of [^A-Za-z0-9_] is \\W Use the shorthand character class \\W to count the number of non-alphanumeric characters in various quotes and strings Example 1  let shortHand = /\\W/; let numbers = \u0026#34;42%\u0026#34;; let sentence = \u0026#34;Coding!\u0026#34;; numbers.match(shortHand); // Returns [\u0026#34;%\u0026#34;] sentence.match(shortHand); // Returns [\u0026#34;!\u0026#34;]  Example 2  // Use the shorthand character class \\W to count the number of non-alphanumeric characters in various quotes and strings let quoteSample = \u0026#34;The five boxing wizards jump quickly.\u0026#34;; let nonAlphabetRegex = /\\W/g; let result = quoteSample.match(nonAlphabetRegex).length; \n6. Match All Numbers  A shortcut of character class [0-9] is \\d, which looks for a single character of any number between zero and nine  // Use the shorthand character class \\d to count how many digits are in movie titles. Written out numbers (\u0026#34;six\u0026#34; instead of 6) do not count. let movieName = \u0026#34;2001: A Space Odyssey\u0026#34;; let numRegex = /\\d/g; let result = movieName.match(numRegex).length; \n7. Match All Non-Numbers  A shortcut for non-digits [^0-9] is \\D  //Use the shorthand character class for non-digits \\D to count how many non-digits are in movie titles let movieName = \u0026#34;2001: A Space Odyssey\u0026#34;; let noNumRegex = /\\D/g; // Change this line let result = movieName.match(noNumRegex).length; \n8. Restrict Possible Usernames 📓  You need to check all the usernames in a database. Here are some simple rules that users have to follow when creating their username.\n   Usernames can only use alpha-numeric characters.    The only numbers in the username have to be at the end. There can be zero or more of them at the end. Username cannot start with the number.    Username letters can be lowercase and uppercase.    Usernames have to be at least two characters long. A two-character username can only use alphabet letters as characters.     let username = \u0026#34;JackOfAllTrades\u0026#34;; let userCheck = /^[a-z]([0-9][0-9]+|[a-z]+\\d*)$/i; // Change this line let result = userCheck.test(username); \n9. Match Whitespaces or Spaces between Letters  You can search for whitespace using \\s. This pattern not only matches whitespace, but also carriage return, tab, form feed, and new line characters. You can think of it as similar to the character class [\\r\\t\\f\\n\\v]. Example 1  let whiteSpace = \u0026#34;Whitespace. Whitespace everywhere!\u0026#34; let spaceRegex = /\\s/g; whiteSpace.match(spaceRegex); // Returns [\u0026#34; \u0026#34;, \u0026#34; \u0026#34;]  Example 2  //Change the regex countWhiteSpace to look for multiple whitespace characters in a string. \n10. Match Non-Whitespace Characters  Search for non-whitespace using \\S This pattern will not match whitespace, carriage return, tab, form feed, and new line characters. You can think of it being similar to the character class [^ \\r\\t\\f\\n\\v]  let whiteSpace = \u0026#34;Whitespace. Whitespace everywhere!\u0026#34; let nonSpaceRegex = /\\S/g; whiteSpace.match(nonSpaceRegex).length; // Returns 32 ","excerpt":"Course Link\n 1. Find Characters with Lazy Matching   A greedy match finds the longest possible part …","ref":"/docs/coding/functional-coding/javascript/course/regular-expression/part2/","title":"Part 2"},{"body":"\n Course Link\n 1. Create Strings using Template Literals  Template literals allow you to create multi-line strings and to use string interpolation features to create strings. Use backticks (`), not quotes (' or \u0026ldquo;), to wrap the string You won\u0026rsquo;t have to use concatenation with the + operator, instead, you could use the ${variable} syntax as a placeholder Example 1  const person = { name: \u0026#34;Zodiac Hasbro\u0026#34;, age: 56 }; // Template literal with multi-line and string interpolation const greeting = `Hello, my name is ${person.name}! I am ${person.age}years old.`; console.log(greeting); // prints // Hello, my name is Zodiac Hasbro! // I am 56 years old.  Example 2   Use template literal syntax with backticks to display each entry of the result object\u0026rsquo;s failure array.\nEach entry should be wrapped inside an li element with the class attribute text-warning, and listed within the resultDisplayArray.\n const result = { success: [\u0026#34;max-length\u0026#34;, \u0026#34;no-amd\u0026#34;, \u0026#34;prefer-arrow-functions\u0026#34;], failure: [\u0026#34;no-var\u0026#34;, \u0026#34;var-on-top\u0026#34;, \u0026#34;linebreak\u0026#34;], skipped: [\u0026#34;id-blacklist\u0026#34;, \u0026#34;no-dup-keys\u0026#34;] }; function makeList(arr) { \u0026#34;use strict\u0026#34;; const resultDisplayArray = []; for (let i =0;i \u0026lt;arr.length; i++){ resultDisplayArray.push(`\u0026lt;li class=\u0026#34;text-warning\u0026#34;\u0026gt;${arr[i]}\u0026lt;/li\u0026gt;` // Note: no need to add string quote \u0026#39; or \u0026#34;\u0026#34; at the beginning and end. ` and ` are enough  ); }; return resultDisplayArray; } const resultDisplayArray = makeList(result.failure); \n2. Write Concise Object Literal Declarations Using Object Property Shorthand  Example 1  const getMousePosition = (x, y) =\u0026gt; ({ x: x, y: y }); // ES6 const getMousePosition = (x, y) =\u0026gt; ({ x, y });  Example 2  const createPerson = (name, age, gender) =\u0026gt; { \u0026#34;use strict\u0026#34;; return { name, age, gender } }; \n3. Write Concise Declarative Functions with ES6  We can remove the : and function keyword when defining functions in objects. Example 1  // ES5 const person = { name: \u0026#34;Taylor\u0026#34;, sayHello: function() { return `Hello! My name is ${this.name}.`; } }; // ES6: const person = { name: \u0026#34;Taylor\u0026#34;, sayHello() { return `Hello! My name is ${this.name}.`; } };  Example 2  // Only change code below this line const bicycle = { gear: 2, setGear: function(newGear) { this.gear = newGear; } }; // Only change code above this line bicycle.setGear(3); console.log(bicycle.gear); // ES6 refactor // Only change code below this line const bicycle = { gear: 2, setGear(newGear) { this.gear = newGear; } }; // Only change code above this line bicycle.setGear(3); console.log(bicycle.gear); \n4. Use class Syntax to Define a Constructor Function  ES6 provides a new syntax to create objects, using the class keyword It should be noted that the class syntax is just syntax, and not a full-fledged class-based implementation of an object-oriented paradigm, unlike in languages such as Java, Python, Ruby, etc The class keyword declares a new function, to which a constructor is added. This constructor is invoked when new is called to create a new object The constructor method is a special method for creating and initializing an object created with a class. UpperCamelCase should be used by convention for ES6 class names, as in SpaceShuttle used below Example 1  // In ES5, we usually define a constructor function and use the new keyword to instantiate an object var SpaceShuttle = function(targetPlanet){ this.targetPlanet = targetPlanet; } var zeus = new SpaceShuttle(\u0026#39;Jupiter\u0026#39;); // ES6 class syntax simply replaces the constructor function creation: class SpaceShuttle { constructor(targetPlanet) { this.targetPlanet = targetPlanet; } } const zeus = new SpaceShuttle(\u0026#39;Jupiter\u0026#39;);  Example 2  class Vegetable{ constructor(name){ this.name = name; } } const carrot = new Vegetable(\u0026#39;carrot\u0026#39;); console.log(carrot.name); // Should display \u0026#39;carrot\u0026#39; \nThe quotes today on freeCodeCamp\n  It is never too late to be what you might have been — Mary Anne Evans Life shrinks or expands in proportion with one\u0026rsquo;s courage — Anaïs Nin   ","excerpt":"Course Link\n 1. Create Strings using Template Literals  Template literals allow you to create …","ref":"/docs/coding/functional-coding/javascript/course/es6/part2/","title":"Part 2"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/course/es6/","title":"ES6"},{"body":"\n Course Link\n 1. Write Reusable JavaScript with Functions function reusableFunction() { console.log(\u0026#34;Hi World\u0026#34;) }; reusableFunction(); 2. Scope In JavaScript, scope refers to the visibility of variables.\n Variables which are declared within a function, as well as the function parameters have local scope. That means, they are only visible within that function. It is possible to have both local and global variables with the same name. When you do this, the local variable takes precedence over the global variable.  var someVar = \u0026#34;Hat\u0026#34;; function myFun() { var someVar = \u0026#34;Head\u0026#34;; return someVar; } myFun() //return \u0026#34;Head\u0026#34;   Does var make a difference?\n  var x = 1 declares variable x in current scope (aka execution context). If the declaration appears in a function - a local variable is declared; if it\u0026rsquo;s in global scope - a global variable is declared.\n  x = 1, on the other hand, is merely a property assignment. It first tries to resolve x against scope chain. If it finds it anywhere in that scope chain, it performs assignment; if it doesn\u0026rsquo;t find x, only then does it creates x property on a global object (which is a top level object in a scope chain). Now, notice that it doesn\u0026rsquo;t declare a global variable, it creates a global property.\n    Why var matters?\n  If you\u0026rsquo;re in the global scope then there\u0026rsquo;s not much difference. Read Kangax\u0026rsquo;s answer for explanation\n  If you\u0026rsquo;re in a function then var will create a local variable, \u0026ldquo;no var\u0026rdquo; will look up the scope chain until it finds the variable or hits the global scope (at which point it will create it):\n    // These are both globals var foo = 1; bar = 2; function() { var foo = 1; // Local  bar = 2; // Global  // Execute an anonymous function  (function() { var wibble = 1; // Local  foo = 2; // Inherits from scope above (creating a closure)  moo = 3; // Global  }()) } 3. Understanding Undefined Value returned from a Function  A function can include the return statement but it does not have to. In the case that the function doesn\u0026rsquo;t have a return statement, when you call it, the function processes the inner code but the returned value is undefined\n var sum = 0; function addSum(num) { sum = sum + num; } addSum(3); // sum will be modified but returned value is undefined  queue  function nextInLine(arr, item) { arr.push(item); var last_element = arr.shift(); return last_element; } // Setup var testArr = [1,2,3,4,5]; // Display code console.log(\u0026#34;Before: \u0026#34; + JSON.stringify(testArr)); console.log(nextInLine(testArr, 6)); console.log(\u0026#34;After: \u0026#34; + JSON.stringify(testArr)); 4. Use Conditional Logic with If Statements function trueOrFalse(wasThatTrue) { if (wasThatTrue) { return \u0026#34;Yes, that was true\u0026#34; } return \u0026#34;No, that was false\u0026#34; } 5. Use Else If Statements  The function is executed from top to bottom so you will want to be careful of what statement comes first\n // foo function function foo(x) { if (x \u0026lt; 1) { return \u0026#34;Less than one\u0026#34;; } else if (x \u0026lt; 2) { return \u0026#34;Less than two\u0026#34;; } else { return \u0026#34;Greater than or equal to two\u0026#34;; } } // 2 bar function function bar(x) { if (x \u0026lt; 2) { return \u0026#34;Less than two\u0026#34;; } else if (x \u0026lt; 1) { return \u0026#34;Less than one\u0026#34;; } else { return \u0026#34;Greater than or equal to two\u0026#34;; } } foo(0) // \u0026#34;Less than one\u0026#34; bar(0) // \u0026#34;Less than two\u0026#34; 6. Comparison with Operators  Comparison with the Equality Operator  1 == 1 // true 1 == 2 // false 1 == \u0026#39;1\u0026#39; // true \u0026#34;3\u0026#34; == 3 // true  Comparison with the Strict Equality Operator  3 === 3 // true 3 === \u0026#39;3\u0026#39; // false  typeof 3 // returns \u0026#39;number\u0026#39; typeof \u0026#39;3\u0026#39; // returns \u0026#39;string\u0026#39;  Strict equality === is the counterpart to the equality operator ==. However, unlike the equality operator, which attempts to convert both values being compared to a common type, the strict equality operator does not perform a type conversion.\nIf the values being compared have different types, they are considered unequal, and the strict equality operator will return false.\n  Comparison with the Inequality Operator  1 != 2 // true 1 != \u0026#34;1\u0026#34; // false 1 != \u0026#39;1\u0026#39; // false 1 != true // false 0 != false // false   The inequality operator (!=) is the opposite of the equality operator. It means \u0026ldquo;Not Equal\u0026rdquo; and returns false where equality would return true and vice versa. Like the equality operator, the inequality operator will convert data types of values while comparing.    Comparison with the Strict Inequality Operator  3 !== 3 // false 3 !== \u0026#39;3\u0026#39; // true 4 !== 3 // true  The strict inequality operator (!==) is the logical opposite of the strict equality operator. It means \u0026ldquo;Strictly Not Equal\u0026rdquo; and returns false where strict equality would return true and vice versa. Strict inequality will not convert data types.\n  Comparison with the Greater Than Operator  5 \u0026gt; 3 // true 7 \u0026gt; \u0026#39;3\u0026#39; // true 2 \u0026gt; 3 // false \u0026#39;1\u0026#39; \u0026gt; 9 // false  Comparison with the Greater Than Or Equal To Operator  6 \u0026gt;= 6 // true 7 \u0026gt;= \u0026#39;3\u0026#39; // true 2 \u0026gt;= 3 // false \u0026#39;7\u0026#39; \u0026gt;= 9 // false  Comparisons with the Logical And Operator \u0026amp;\u0026amp;  if (num \u0026gt; 5 \u0026amp;\u0026amp; num \u0026lt;8) { return \u0026#34;weekend\u0026#34;; } return \u0026#34;work\u0026#34;;  Comparisons with the Logical Or Operator ||  function testLogicalOr(val) { if (val \u0026gt; 20 || val \u0026lt;10) { return \u0026#34;Outside\u0026#34;; } return \u0026#34;Inside\u0026#34;; } testLogicalOr(15); 7. Selecting from Many Options with Switch Statements   If you have many options to choose from, use a switch statement. A switch statement tests a value and can have many case statements which define various possible values. Statements are executed from the first matched case value until a break is encountered. Case values are tested with strict equality (===). The break tells JavaScript to stop executing statements. If the break is omitted, the next statement will be executed.   switch(lowercaseLetter) { case \u0026#34;a\u0026#34;: console.log(\u0026#34;A\u0026#34;); break; case \u0026#34;b\u0026#34;: console.log(\u0026#34;B\u0026#34;); break; }  Adding a Default Option in Switch Statements    In a switch statement you may not be able to specify all possible values as case statements. Instead, you can add the default statement which will be executed if no matching case statements are found. Think of it like the final else statement in an if/else chain.   switch (num) { case value1: statement1; break; case value2: statement2; break; ... default: defaultStatement; break; }  Multiple Identical Options in Switch Statements  function sequentialSizes(val) { var answer = \u0026#34;\u0026#34;; switch(val) { case 1: case 2: case 3: answer = \u0026#34;Low\u0026#34;; break; case 4: case 5: case 6: answer = \u0026#34;Mid\u0026#34;; break; case 7: case 8: case 9: answer = \u0026#34;High\u0026#34;; break; }  Replacing If Else Chains with Switch   If you have many options to choose from, a switch statement can be easier to write than many chained if/else if statements.\n function chainToSwitch(val) { var answer = \u0026#34;\u0026#34;; switch (val) { case \u0026#34;bob\u0026#34;: answer = \u0026#34;Marley\u0026#34;; break; case 42: answer = \u0026#34;The Answer\u0026#34;; break; case 1: answer = \u0026#34;There is no #1\u0026#34;; break; case 99: answer = \u0026#34;Missed me by this much!\u0026#34;; break; case 7: answer = \u0026#34;Ate Nine\u0026#34;; break; } return answer } chainToSwitch(7); 8. Returning Boolean Values from Functions function isLess(a, b) { return a \u0026lt; b } isLess(10, 15); 9. Return Early Pattern for Functions  When a return statement is reached, the execution of the current function stops and control returns to the calling location.\n function myFun() { console.log(\u0026#34;Hello\u0026#34;); return \u0026#34;World\u0026#34;; console.log(\u0026#34;byebye\u0026#34;) } myFun(); \\\\ The above outputs \u0026#34;Hello\u0026#34; to the console, returns \u0026#34;World\u0026#34;, but \u0026#34;byebye\u0026#34; is never output, because the function exits at the return statement 10. BlackJack Exercise var count = 0; function cc(card) { switch(card) { case 2: case 3: case 4: case 5: case 6: count+=1; break; case 10: case \u0026#34;J\u0026#34;: case \u0026#34;Q\u0026#34;: case \u0026#34;K\u0026#34;: case \u0026#34;A\u0026#34;: count--; break; } if (count \u0026gt; 0) { return count + \u0026#34; Bet\u0026#34;; } else { return count + \u0026#34; Hold\u0026#34;; } } cc(2); cc(3); cc(7); cc(\u0026#39;K\u0026#39;); cc(\u0026#39;A\u0026#39;); 11. Go Golf Exercise var names = [\u0026#34;Hole-in-one!\u0026#34;, \u0026#34;Eagle\u0026#34;, \u0026#34;Birdie\u0026#34;, \u0026#34;Par\u0026#34;, \u0026#34;Bogey\u0026#34;, \u0026#34;Double Bogey\u0026#34;, \u0026#34;Go Home!\u0026#34;]; function golfScore(par, strokes) { if (strokes == 1) { return \u0026#34;Hole-in-one!\u0026#34;; } else if (strokes \u0026lt;= par -2) { return \u0026#34;Eagle\u0026#34;; } else if (strokes == par -1){ return \u0026#34;Birdie\u0026#34;; } else if (strokes == par) { return \u0026#34;Par\u0026#34;; } else if (strokes == par +1){ return \u0026#34;Bogey\u0026#34;; } else if (strokes == par +2){ return \u0026#34;Double Bogey\u0026#34; } else { return \u0026#34;Go Home!\u0026#34; } } golfScore(5, 4); ","excerpt":"Course Link\n 1. Write Reusable JavaScript with Functions function reusableFunction() { …","ref":"/docs/coding/functional-coding/javascript/course/basics/functions/","title":"Functions"},{"body":"\nHow to run JavaScript using Node.js?  Install Node.js Open a terminal and run  node  Node.js is an asynchronous event-driven JavaScript runtime designed to build scalable network applications.\n ","excerpt":"\nHow to run JavaScript using Node.js?  Install Node.js Open a terminal and run  node  Node.js is an …","ref":"/docs/coding/functional-coding/javascript/practices/nodejs/","title":"Node.js"},{"body":"\nSnorkel  Snorkel website Snorkel tutorials Snorkel documentation  Installation pip install snorkel or conda:\nconda install snorkel -c conda-forge ","excerpt":"\nSnorkel  Snorkel website Snorkel tutorials Snorkel documentation  Installation pip install snorkel …","ref":"/docs/data/dataset/build-data/","title":"Build Data"},{"body":"","excerpt":"","ref":"/docs/coding/expressitive-coding/","title":"Expressive Coding"},{"body":"\nLicense \nTo the extent possible under law, Terkel Gjervig has waived all copyright and related or neighboring rights to this work.\nCreative coding Creative coding is a different discipline than programming systems. The goal is to create something expressive instead of something functional. Interaction design, information visualization and generative art are all different types of creative coding – which has become a household term describing artworks articulated as code.\nDon\u0026rsquo;t know where to start? Check out Creative Coding course on Frontend Masters.\nWant to go depper? Check out Advanced Creative Coding with WebGL \u0026amp; Shaders on Frontend Masters.\n Contents  Books Online Books Courses Tools  Frameworks • Libraries • Ecosystems Visual Programming Languages Sound Programming Languages Web Programming • Libraries Projection Mapping • VJing Online Hardware Other   Learning Resources  Videos Talks Articles  Shaders • OpenGL • WebGL Canvas Hardware Other   Interactive Quick References • Cheat-Sheets   Communities  Subreddits Slack Other   Math Machine learning • Computer Vision • Ai Inspiration Events Schools • Workshops Blogs • Websites Related  Books  Generative Art: A Practical Guide - Practical guide using Processing. Generative Design - Visualize, Program, and Create with Processing. The Nature of Code - Simulating natural systems with Processing. Programming Design Systems - Practical introduction to the new foundations of graphic design. Learning Modern 3D Graphics Programming - Series of tutorials on using OpenGL to do graphical rendering. Programming Interactivity - Designer\u0026rsquo;s Guide to Processing, Arduino, and openFrameworks. openFrameworks Essentials - openFrameworks beginner Guide for programmer, visual artist, or designer. Mastering openFrameworks: Creative Coding Demystified - Advanced in depth guide to openFrameworks. Algorithms for Visual Design Using the Processing Language - Experiment with design problems to create 3D animations, GUIs, and more. Foundation HTML5 Animation with JavaScript - Everything you need to know to create animation using the HTML5 canvas. Playing with chaos - Programming Fractals and Strange Attractors in JavaScript. Ray Tracing in One Weekend - Mini book about Ray Tracing. Processing 2: Creative Programming Cookbook - Guides you to explore the Processing environment using practical and useful recipes. Data-driven Graphic Design - Creative Coding for Visual Communication. Real-Time Rendering - Learn how to use modern techniques to generate synthetic three-dimensional images in a fraction of a second. Graphics Shaders: Theory and Practice - Introduction to shader programming in general, but focusing on the GLSL shading language. Anton\u0026rsquo;s OpenGL 4 Tutorials - Practical guide to starting 3d programming with OpenGL. Physics for JavaScript Games, Animation, and Simulations - Teaches JavaScript programmers how to incorporate real physics into their HTML5 games, animations, and simulations. Math for Programmers - Book teaches you to solve mathematical problems in code. Synthèse d\u0026rsquo;images avec OpenGL (ES) - Book in french, which covers OpenGL, OpenGL ES and WebGL. Hands-On Music Generation with Magenta - Design and use machine learning models for music generation using Magenta and make them interact with existing music creation tools  Online Books  The Book of Shaders - Step-by-step guide through the abstract and complex universe of fragment shaders. WebGL Fundamentals - WebGL from the ground up. No magic. WebGL 2 Fundamentals - WebGL2 from the ground up. No magic. Learn OpenGL - Extensive tutorial resource for learning Modern OpenGL. Scratchapixel 2.0 - Learn Computer Graphics From Scratch. ofBook - Community-written book/guide on openFrameworks. OGLdev - Collection of modern OpenGL tutorials by Etay Meiri. OpenGL Tutorial - Site dedicated to tutorials for OpenGL 3.3 and later. Open.gl - Guide that teach you the basics of using OpenGL. Pixel Shaders - Interactive Introduction to Graphics Programming. OpenGLBook - Free OpenGL programming tutorial in online book format. Graphics Programming Projects - Book about 3D computational graphics by Morgan McGuire. On Generative Algorithms - Notes about generating various organic patterns, with examples and Python code, by Anders Hoff. Computer Graphics from Scratch - A raytracing and rasterization textbook that teaches you how OpenGL and DirectX works. A Primer on Bézier Curves - A free book for when you really need to know how to do Bézier things. 3D Game Shaders For Beginners - Step-by-step guide to real-time shading techniques. XEM WebGL Guide - Step-by-step guide to WebGL.  Courses  Create 3D Graphics in JS Using WebGL - Get started creating content with WebGL without any frameworks. Learn HTML5 Graphics and Animation - Introduction to the canvas 2D drawing API. Interactive 3D Graphics - Udacity course that teach you the principles of 3D computer graphics. Interactive Computer Graphics - Computer graphics course from Coursera. Kadenze Creative Coding - Selection of Kadenze courses covering p5.js, TensorFlow, Max/Jitter, and ChucK. Think. Create. Code - EDX course to learn programming with ProcessingJS. Creative Programming for Digital Media \u0026amp; Mobile Apps - Coursera course on creative coding with processing. Imaginary Institute - Learn how to create gorgeous interactive graphics. Future Learn: Creative Coding - Use computer programming as a creative discipline to generate sounds, images, animations and more. Intro to JS: Drawing \u0026amp; Animation - Use JavaScript and the ProcessingJS library to create drawings and animations. Advanced JS: Natural Simulations - Combine JS, ProcessingJS, and mathematical concepts to simulate nature in your programs Interactive Data Visualization with Processing - Learn how to read, map, and illustrate data with Processing. Programming Data Visualizations: A Coding Toolkit for Processing - Join information designer Nicholas Felton in the world of Processing. Introduction to Data Visualization - Join Nicholas Felton for a smart, comprehensive, and inspiring intro to data visualization. Programming Graphics I, 2, 3 - Learn generative art and Processing with art with Joshua Davis. Creative Coding with Canvas \u0026amp; WebGL - Workshop by Matt DesLauriers. that teaches you about generative art, interactive animations, 3D graphics, and shaders. Advanced Creative Coding with WebGL \u0026amp; Shaders - Workshop by Matt DesLauriers that go deeper into graphics programming, math and shaders.  Tools Frameworks • Libraries • Ecosystems  Processing [Cross-platform] - Computer programming language and IDE for visual arts. Cinder [Cross-platform] - Open source library for professional-quality creative coding in C++. openFrameworks [Cross-platform] - Open source C++ toolkit for creative coding. C4 [iOS] - Open-source creative coding framework for iOS. Unity [Mac, Win] - Game engine, but useful for creative coding and installations. PlayCanvas [Cross-platform] - Open source, realtime collaborative WebGL engine. hg_sdf [Cross-platform] - GLSL library for building signed distance functions. HYPE [Cross-platform] - HYPE_processing, is a collection of classes that performs heavy lifting tasks while using a minimal amount of code writing. nannou [Cross-platform] - Open-source creative coding framework for the Rust language thi.ng [Cross-platform] - Open source collection of computational design tools for the Clojure and ClojureScript languages PixelKit [iOS, Mac] - Open source, live graphics, Swift framework, powered by Metal. OPENRNDR [Cross-platform] - Open source library for creative coding written in Kotlin. Phaser [Cross-platform] - HTML5 framework for building games, uses both a Canvas and WebGL renderer. Canvas-sketch [Cross-platform] - HTML5 framework for making generative artwork in JavaScript and the browser.  Visual Programming Languages  vvvv [Win] - Hybrid visual/textual live-programming environment for easy prototyping and development. NodeBox [Mac, Win] - Cross-platform, node-based GUI for efficient data visualizations and generative design. TouchDesigner [Mac, Win] - Visual development platform to create realtime projects. Quartz Composer [Mac] - Development tool for processing and rendering graphical data. Vuo [Mac] - Live interactive-media programming environment. Max [Mac, Win] - Visual programming language for media. Pure Data [Cross-platform] - Open source visual programming language for multimedia. i-score [Cross-platform] - Interactive sequencer to control creative coding libraries and toolkits. tooll [Win] - Open source tool for creating interactive 3d content and animations. XOD [Cross-platform] - Open source visual programming language and environment for microcontroller-based projects. Isadora [Cross-platform] - Scene based media control software with integrated projection mapper. cables [Cross-platform/Web] - Your model kit for creating beautiful interactive content. Currently in private beta, invites can be requested. eternal [Web] - Programs as graphs and graphs as compositional tools for creation Notch Builder [Win] - Node-based authoring tool with a strong focus on real-time graphics. Currently in beta. Synopsis - A suite of open source software for computational cinematography. JOY.JS - Realtime visual coding tool, easy to understand and aimed at beginners. Pixel Nodes [iPad] - Live graphics node editor, powered by PixelKit.  Sound Programming Languages  SuperCollider [Multi-platform] - Platform for audio synthesis and algorithmic composition. ChucK - Strongly-timed, concurrent, and on-the-fly music programming language. TidalCycles - Domain specific language for live coding of pattern. Sonic Pi - The live coding music synth for everyone. Csound - A sound and music computing system. Orca - Live coding environment to quickly create procedural sequencers.  Web Programming • Libraries  three.js - JavaScript 3D library. regl - Functional WebGL. Stackgl - Open software ecosystem for WebGL, built on top of browserify and npm. Paper.js - The swiss army knife of vector graphics scripting. Pixi.js - HTML 5 2D rendering engine that uses webGL with canvas fallback. p5.js - JavaScript library that starts with the original goal of Processing. Pts.js - JavaScript library for visualization and creative-coding. Fabric.js - Javascript canvas library, SVG-to-canvas parser. Maker.js - Parametric line drawing for SVG, CNC \u0026amp; laser cutters. OpenJSCAD - Programmatic 3D modeling in JavaScript. Sketch.js - Minimal JavaScript creative coding framework. Two.js - Two-dimensional drawing api geared towards modern web browsers. ClayGL - WebGL graphic library for building scalable Web3D applications. Proton - A lightweight and powerful javascript particle engine. lightgl.js - A lightweight WebGL library. picogl.js - A minimal WebGL 2 rendering library. Alfrid - A WebGL tool set. Babylon.js - complete JavaScript framework for building 3D games with HTML 5 and WebGL. twigl - A Tiny WebGL helper Library. luma.gl - WebGL2 Components for Data Visualization. css-doodle - A web component for drawing patterns with CSS. OGL.js - JavaScript 3D library (WebGL) Zdog - A pseudo-3D engine for canvas \u0026amp; SVG Oimo.js - Lightweight 3d physics engine for javascript Ammo.js - Direct port of the Bullet physics engine to JavaScript using Emscripten  Projection Mapping • VJing  MadMapper [Mac] - Video mapping projections and Light mapping. VDMX [Mac] - Realtime multimedia performance application. Modul8 [Mac] - Real time video mixing and compositing. Resolume [Mac, Win] - Mixing of digital video and effects in a realtime. CoGe VJ [Mac] - VJ software designed for realtime HD video mixing and compositing with a modular user interface. VirtualMapper - Realtime preview tool for projection mapping. Millumin [Mac] - A software to create and perform interactive audiovisual shows. Smode [Win] - A real-time 2D/3D creation, compositing and video-mapping engine. Veejay [Linux] - A live performance tool featuring simple non-linear editing and mixing from multiple sources (files, devices, streams\u0026hellip;)  Online  Shadertoy - Build and share shaders with the world and get inspired. GLSLbin - Fragment shader sandbox with support for glslify. GLSL Sandbox - Online shader editor and gallery. Shdr Editor - Online shader editor. CodePen - Show case of advanced techniques with editable source code. Shadershop - Interface for programming GPU shaders. Vertexshaderart - Online shader editor and gallery. Cyos - Online shader editor. GlslEditor - Simple WebGL Fragment Shader Editor. OpenProcessing - Create and experiment with algorithmic design, Processing and P5.js. P5.js Editor - Online web editor for P5.js. LiveCodeLab - Run-as-you-type tool for VJs, musicians, teachers, students, kids. Turtletoy - Minimalistic API and online showcase for generative code. (Javascript) ShaderGif - Open source home for art made with code (WebGL1/2, JavaScript Canvas \u0026amp; P5.js). P5LIVE - p5.js live-coding environment. NEORT - Digital art platform for creative coders (Fragment Shader, Javascript Canvas).  Hardware  Arduino - Open source microcontroller kits for building digital devices and interactive objects. Raspberry Pi - Small single-board computers. Puck.js - Open source JavaScript microcontroller you can program wirelessly. BeagleBoard - Low-power open source single-board computers. Makey Makey - Turn everyday objects into touchpads and combine them with the internet. Tessel - Easy to use microcontroller that runs JavaScript. Leap Motion - Sensor device that supports hand and finger motions as input. AxiDraw - Simple, modern, and precise pen plotter. Phidgets - Sensors, input devices and controllers for computers. Teensy - USB-based microcontroller development system. Lightform - AR projection mapping with built-in depth sensor.  Other  Structure Synth [Cross-platform] - Application for generating 3D structures by specifying a design grammar. F3 [Mac] - Powerful 3D design app that enables you to live code 3D form. Fragment [Mac]- App to live code GLSL graphics. ShaderTool [Win] - Modern shader IDE for programmers and FX artists. Syphon [Mac] - Allows applications to share frames with one another in realtime. KodeLife - Real-time GPU shader editor, live-code performance tool and graphics prototyping sketchpad. ISF - GLSL shaders for use in interactive applications. glslViewer - Live-coding console tool that renders GLSL Shaders. DrawBot [Mac] - Education oriented 2d graphics programming environment based on python. Klak - A collection of scripts for creative coding with Unity. basil.js - Scripting (JS) in InDesign for designers and artists in the spirit of Processing.  Learning Resources Videos  The Coding Train - Daniel Shiffman makes videos about creative coding. MFGD - Fragment Shaders - YouTube playlist about fragment shaders. Shaders Laboratory - YouTube channel about shaders. Makin' Stuff Look Good - YouTube channel about shaders case studies. -openFrameworks Tutorial Series - YouTube series to learning openFrameworks openFrameworks tutorial - YouTube playlist about openFrameworks - not updated [2015]. Shader Tutorial Series - YouTube playlist about Shaders, using Visual Studio Code. Kha Tutorial Series - YouTube playlist about the Kha framework, built in Haxe. Fun with WebGL 2.0 - YouTube playlist about WebGL 2.0. Modern OpenGL 3.0+ Tutorials - YouTube playlist about modern OpenGL. Vertexshaderart - YouTube playlist about vertex shaders. Diving in Three.js - YouTube playlist diving into three.js. Shadertoy Tutorials - YouTube playlist teaching you how to make shaders, starting with zero knowledge using shadertoy. WebGL Lightning - Introduction to WebGL lightning with Greg Tatum.  Talks  Intro to WebGL Slides Video - Intro to WebGL with three.js. Inigo Quilez Live - Collection of live coding videos by Íñigo Quílez. There is also canvas - Bruno Imbrizi go through the use of canvas for creative coding at WebExpo 2016. Interactive slides here. Draw. Move. Fail. Repeat. - Slides by @williamapan from his Creative developer workshop at Gobelins. OpenGL 3D Game Tutorials - Beginners tutorial series about creating 3D games OpenG. How We Do This Shit - Talk on how tech-based artists do this financially. Making WebGL Dance - How I Learnt to Stop Worrying and Love Linear Algebra. The Pixel Factory - Talk about WebGL, GPUs and Math by Steven Wittens. Poetic Computation - Inspiring talk by Zach Lieberman. Generative Machines - FITC talk by Matt DesLauriers about his passion for generative art.  Articles • Tutorials Shaders • OpenGL • WebGL  Introduction to shaders - Part 1 of an introduction to shaders using threejs. Three.js 101 - Introduction to three.js from a creative coder perspective. Experimenting with Three.js shaders and the ShaderMaterial - Introduction to custom mesh shader materials. lwjgl: Shaders - Shader tutorial in the context of lwjgl-basics. Shaders: A primer - A primer on shaders. Shaders: Second stage - The second part to the previous. WebGL Lessons — Fragment Shaders - A brief introduction to fragment shaders. WebGL Lessons — ThreeJS Shaders - Using custom vertex and fragment shaders in ThreeJS. ThreeJS post-proces example - example of post-processing effects in ThreeJS. Ray Marching and Signed Distance Functions - Introduction to ray tracing. Introduction to Ray Tracing - A simple method for creating 3D images. GLSL lighting walkthrough - Phong shading tutorial with glslify. Three glslify example - Example on how to use three.js with glslify. WebGL Beyond Dom - Greg Tatum explain the basic of WebGL using Regl. FBO particles - Article about FBO/GPGPU particles by @nicoptere. Ray marching (with THREE.js) - Article about ray marching with three.js by @nicoptere. Custom shaders with Three.JS - Introduction to custom shaders, uniforms, textures and lighting in three.js. An intro to modern OpenGL - First part of an introduction to modern OpenGL. Modern OpenGL Series - Good introduction to some of the OpenGL terms. Smooth minimum - Article about the smooth based primitive union. Modeling with distance functions - Collection of distance functions in one centralized place. Volumetric rendering - Explains how to create complex 3D shapes inside volumetric shaders. Real-time Rendering - Book, blog and collection of resources regarding real-time rendering. OpenGL 4 Shaders - Short and sweet introduction to OpenGL shaders by Anton Gerdelan. On ray casting, ray tracing, ray marching and the like - The title says it all. Introduction by Adok. Sun and Black Cat - Articles on shaders and other computer graphics related topics. Writing a small software renderer - Really good introduction to how basic software rendering works. WebGL Tutorials - Website with a really good collection of WebGL tutorials. Generating Geometry: 1, 2, 3 - Beginner introduction on how to create geometry object. Three.js sine animation - Learn how to add sine waves to a circle with three.js. (oF version) Into Vertex Shaders - Series of tutorials about WebGL, Three.js, and Three.bas. The Spaces of WebGL - Brief overview over the different coordinate systems through out the 3D graphics pipeline. WebGL Workshop - Short and sweet online introduction to WebGL. THREE.js \u0026amp; instanced geometry - Fluffy predator with three.js and instanced geometry. Particle Effects via Billboards - How to create a particle effects with billboarding and WebGL. Beautifully Animate Points with WebGL and regl - How to create GPGPU particles with regl. WebGL Tutorial: Directional Shadow Mapping without extensions - Introduction to the concepts behind real time directional light shadow mapping. WebGL Quest - A tutorial and a list of useful resources to use WebGL raymarching and distance functions easily. Exploring bump mapping with WebGL - Introduction to different bump mapping techniques. OpenGL/GLSL Shader Programing - Deck on OpenGL/GLSL shader programing. Particles in a Simplex Noise Flow Field - Perlin noise flow field tutorial. Flow Fields, Part 1 Part 2 - Introduction to flow fields also known as vector fields. Graphics for Games - Introduction to 3D graphics programming including shaders, math post-processing etc. from Newcastle University. Three.js Basics - Introduction to Three.js by Eric Haines. An Interactive Introduction to WebGL and three.js - Slides from the SIGGRAPH 2017 WebGL workshop. How to Start Learning Computer Graphics Programming - Advice and thoughts on how to get started by Eric Arnebäck. What Every Coder Should Know About Gamma - Deep dive into the importance of gamma.  Canvas  HTML Canvas Deep Dive - Profound introduction to the canvas API. 31 days of Canvas tutorials - Collection of canvas tutorials by Seb Lee-Delisle.  Hardware  Pen Plotter Art \u0026amp; Algorithms Part 1, 2 - How to use the AxiDraw pen plotter with JavaScript.  Other  Cat Like Coding - In depth tutorials on math, algorithms and Unity. Fun Programming - Learn creative coding writing simple programs. Creative-coding on iOS with C4 - Introduction to C4 published on Creative Applications. COSMOS - An end-to-end tutorial on the design, programming and launch of an app using C4. Particle Physics - Particle physics explained. Visualizing Algorithms - Looks at the use of visualization to understand, explain and debug algorithms. Adventures in Game Development World - Easy to understand collection of articles on game developement, but relevant to creative coding as well. Shepherding random numbers - Tiny guide to shepherding random numbers. Amit’s Game Programming Information - Collection of resources on stuff like path-finding, Ai, math etc. Tips to Improve Your Generative Artwork - Tips to make your art look better. Working With Color in Generative Art - Tips on how to get color right.  Interactive  Shader-school - Workshop for GLSL shaders and graphics programming. Webgl-workshop - The sequel to shader-school: Learn the WebGL API. Fragment-oundry - Interactive fragment shader tutorial. SDF Tutorial 1: box \u0026amp; balloon - Shadertoy tutorial on raytracing. HOWTO: Ray Marching - Shadertoy tutorial on Ray Marching. Raymarch Tutorial2 - Shadertoy raymarch tutorial. GLSL 2D Tutorials - Shadertoy GLSL 2D Tutorial. Bubble Breakdown - Shader breakdown by Perlin. Let\u0026rsquo;s Make A Ray Marcher - Interactive Shader-Toy on writing a ray marcher. Raymarching - Interactive Shader-Toy raymarching tutorial.  Quick References • Cheatsheets  Shaderific GLSL - OpenGL ES shading language reference. The Book of Shaders Glossary - Shader glossary by theme. gltut glossary pages: 1, 2, 3, 4, 5, 6, 7, 8 - OpenGL 3D programming glossary. Canvas Cheatsheet - Quick and visual canvas cheatsheet. WebGL Cheatsheet - WebGL 1.0 API reference card. Glossary of Computer Graphics - Glossary of terms relating computer graphics. GLSL Reference Guide - OpenGL Shading Language quick reference guide. 3D Maths Cheat Sheet - Math cheatsheet by Anton Gerdelan, from his OpenGL book. docs.GL - Improvement of the official OpenGL documentation. OpenGL Shading Language - Khronos Group GLSL wiki. OpenGL 4.3 Reference Card - PDF Reference Card for the OpenGL 4.3 API. Easings - Interactive easing functions cheatsheet. The newbie\u0026rsquo;s PBR Cheat Sheet - Short and sweet visual overview on PBR. PixelSpirit - GLSL library on the back of tarot cards, for learning and reference. Procedural Patterns And Noises - Collection of procedural patterns and procedural noises. Three.js Reference - Reference from the Udacity Interactive 3D Graphics course. Visual Noises - Visualize noise algorithms in 1D and 2D. Trigonoparty - Simple trigonometry visualisation.  Communities Subreddits  r/creativecoding - Sharing and discussing the use of computer programming as a creative discipline. r/raytraycing - Subreddit on raytracing. r/opengl - News and discussion about OpenGL on all platforms. r/graphicsprogramming - Subreddit on graphics programming. r/processing - Subreddit on Processing. r/shaders - Subreddit on shaders. r/proceduralgeneration - Subreddit on procedural generation. r/MachineLearning - Subreddit on machine learning.  Slack  Creative-Dev Slack - Creative Development Slack. Generative Art Slack - Generative Art Slack. Creative Coding Club - Creative Coding Club Slack. Creative Coding - Creative Coding Slack. openFrameworks - openFrameworks Slack.  Other  The Creative Coding Podcast - Iain and Seb discuss the ins and outs of creative coding. realtimevfx.com - Real Time VFX Community. Data Stories - Podcast on data visualization. 3D Programming Weekly Articles - Great collection of shader and math related resources. Pass The Pen - A community of front-end developers who build collaborative creative coding projects on CodePen. Creative Tech Weekly - A weekly newsletter of resources around creative technology.  Math  Math as code - Cheat-sheet for mathematical notation in code form. Coding Math - Teaches you the math you need to understand as a programmer. Math snippets - Math snippets with graphic programming in mind. Formul Animations - The principles of painting with maths. Learning Maths again - Collection of JS and GLSL math snippets. Eases - Grab-bag of modular easing equations. Math for Motion - Visualization of different motion equations. Matrix Multiplication - Matrix multiplication visualized. Algebra rules - The most useful rules of basic algebra. Immersive Math - Fully interactive linear algebra. Image Kernels - Interactive and visual introduction to image kernels. Sine and Cosine - Interactive explination of sine and cosine. Perlin Noise - Perlin noise explained in detail. Vector Math for 3D Computer Graphics - Tutorial on vector algebra and matrix algebra from the viewpoint of computer graphics. Desmos - Graph functions, plot data, evaluate equations, explore transformations, and much more. MFGD - Math for game developers YouTube playlist. Essence of linear algebra - Essence of linear algebra YouTube playlist. Mathematics of Animation - Slides about the mathematics of animation (repo). Sketching with Math and Quasi Physics - Beautiful and visual introduction to math and quasi physics. Gene Kogan: Perlin Noise - introduction to 2D and 3D perlin noise. Matrix Math and You - High level introduction to matrices. Mathematical Symbols - List of all mathematical symbols and signs. The magnificent 2d matrix - Interactive tool to better understand transformation matrices. Game Dev Movement cheatsheet with examples - JavaScript math snippets for movement. Maths \u0026amp; trigonometry cheat sheet for 2D \u0026amp; 3D games - Maths cheat-sheet for 2D and 3D game-makers. Tiny 3D - The smallest possible perspective engine on a 2D canvas. Matrices for Creative Coding - Introduction to matrices by Greg Tatum. Making Things With Maths - Talk by Steven Wittens about bezier curves, procedural generation, physics engines and fractals. MyPhysicsLab - Interactive real-time physics simulations, with formulars and code. Intuitive Math - Explanations of fields like Linear Algebra and Geometry designed to help you develop a visual intuition for what is going on. L-systems - A Haskell package for L-systems. Linear Interpolation - Introduction to linear interpolation (also known as mix/lerp). Practical use of Vector Math in Games - In-depth article on vectors for game math.  Machine learning • Computer Vision • Ai  ml4a - Machine learning for artists. Keras.js - Run Keras models (tensorflow backend) in the browser, with GPU support. Tesseract.js - Pure Javascript Multilingual OCR. Google ML - Cloud machine learning by Google. TensorFlow - Open source software library for machine intelligence. ConvNetJS - Deep Learning in your browser. Wekinator - Allows anyone to use machine learning. Machine Learning - Coding Train repo with links to machine learning resources. CreativeAi.net - Space to share creative Ai projects. AI Playbook - Ai microsite intended to help newcomers get started. Teachable Machine - Explore how machine learning works, live in the browser. TensorFlow.js - JavaScript library for training and deploying ML models in the browser and on Node.js. Hello TensorFlow - Fully commented TensorFlow.js demo. ml5.js - Friendly machine learning for the web. Model Zoo - Discover open source deep learning code and pretrained models. Runway - Toolkit that adds artificial intelligence capabilities to design and creative platforms. Lobe - Build, train, and ship custom deep learning models using a simple visual interface. ModelDepot - Platform for discovering, sharing, and discussing easy to use and pre-trained machine learning models.  Inspiration  OpenProcessing - Algorithmic Designs Created with Processing, p5js and processingjs. Dwitter - Social network for short JavaScript demos. Chrome Experiments - Showcase of web experiments written by the creative coding community. Codedoodl.es - Showcase of curated creative coding sketches. For your Processing - Projects and tutorials about Processing. Art From Code - Code sketches by Keith Peters. Generator.x - Flickr group about generative strategies in art \u0026amp; design. Generative Art - Flickr group about generative art. Inspiring Online - Open source micro blog about inspiring and creative works published online. People You Should Follow on CodePen - List of interesting people worth following. Raven Kwok - Tumblr by visual artist Raven Kwok. P5Art - Really good collection of experiments in Processing. Echophon - Tumblr with visual inspiration. Bees \u0026amp; Bombs - Tumblr with gifs by Dave. DevArt - Celebration of art made with code by artists that push the possibilities of creativity. Folds2d - Tumblr with curves, surfaces, scalar and vector fields. W:BLUT Inspiration - Collection of gifs, links and images by W:Blut.  Events  OFFF Festival - Digital design festival (Online Flash Film Festival). Resonate - Festical in Belgrade about cutting edge music, visual arts and digital culture. Gray Area Festival - Creative coding, art and technology festival. Signal Festival - Showcase of light art and emerging technologies in Prague, the Czech Republic. Eyeo Festival - Bring together creative coders, data designers and creators working at the intersection of data, art and technology. Mutek - Organization dedicated to digital creativity in sound, music, and audio-visual art. Node - An open platform for the exchange on culture, arts and technology. Digital Design Days - OFFF - 3 day event offering conferences, workshops, digital showcases \u0026amp; installations. CODAME ART+TECH - Projects and nonprofit events, to inspire through experience. Curated Creative Events - Hand-picked design, code, art, fashion and maker events. NextArt Night - Inspiring people through creative uses of tech. GROW - The Parisian rendez-vous for creative coders, GROW is about opening new possibilities in digital creation.  Museums • Galleries  ZKM — Zentrum für Kunst und Medien, Karlsruhe/Germany - ZKM organizes exhibitions and events on the effects of media, digitization, and globalization. Ars Electronica Center, Linz/Austria - Museum of the Future — a place where diverse blends of artistic genres, scientific domains and technological directions are displayed and processed. Technorama, Zurich/Switzerland - Technorama allows hands-on experiences of hundreds of natural phenomena and technology.  Schools • Workshops  UAL Creative Computing Institute - school in London working at the intersection of creativity and computational technologies School for Poetic Computation - School in New York that explore the intersections of code, design, hardware and theory. Copenhagen Institute of Interaction Design - Hosts a range of educational initiatives, most notably, the Interaction Design Programme and the CIID Summer School. Residencies, Fellowships, Summer Schools - Huge list of residencies, fellowships and summer schools around the world (Navigate with the bottom left tabs).  Blogs • Websites  CreativeApplications.Net [CAN] - Famous digital art blog. iquilezles.org - Home of Íñigo Quílez, specialised in GLSL and math snippets. bit-101.com - Blog by Keith Peters, specialised in creative coding. ibreakdownshaders - Explore the math behind shaders. adriancourrèges.com - Blog of software engineer Adrian Courrèges. Articles about game graphics studies etc. clicktorelease.com - Home of Jaume Sanchez Elias, with demos, talks, articles on WebGL and WebVR. syntopia - Blog about generative art and systems, by Mikael Hvidtfeldt Christensen. madebyevan.com - WebGL experiments and articles by Evan Wallace. songho.ca - Home of Song Ho Ahn, with a good collection of tutorials on OpenGL and math. simonschreibt.de - Game art tricks, design tricks by Simon schreibt. sighack.com - Blog about generative art algorithms and techniques, by Manohar Vanga. jsdo.it-archives - Compilation of WebGL experiments including comparisons on WebGL frameworks and physics engine (oimo.js, cannon.js, ammo.js) WebAudio Weekly - Newsletter to know everything about the WebAudio API  Related  Awesome opengl - Curated list of awesome OpenGL libraries, debuggers and resources. Awesome webgl - Curated list of awesome WebGL libraries, resources and much more. Awesome canvas - Curated list of awesome HTML5 canvas with examples, related articles and posts. Awesome audio visualization - Curated list about Audio Visualization. Awesome computer vision - Curated list of awesome computer vision resources. Awesome visualization research - Curated list of recommended research papers and other readings on data visualization. Awesome livecoding - Curated list of livecoding languages and tools. Awesome graphics - Curated list of computer graphics tutorials and resources. Graphics resources - Curated list of graphic programming resources. Magic tools - Curated list of game development resources to make magic happen. Hanecci’s link collection - Link collection of ray marching on the GPU. Awesome public datasets - Curated list of public avalible datasets, mostly free resources. Link collection of ray marching on the GPU - Curated list from 2013. 3D Machine Learning - A resource repository for 3D machine learning.  GANs  introduction-to-cyclegan-monet-paintings  ","excerpt":"License \nTo the extent possible under law, Terkel Gjervig has waived all copyright and related or …","ref":"/docs/coding/expressitive-coding/creative-coding/","title":"Creative Coding"},{"body":"","excerpt":"","ref":"/docs/healthcare/bioinfo/","title":"Bioinformatics"},{"body":"\n scikit-image  ","excerpt":"\n scikit-image  ","ref":"/docs/data/visual-art/image-processing/","title":"Image Processing"},{"body":"\n Cyberpunk Style with Matplotlib  ","excerpt":"\n Cyberpunk Style with Matplotlib  ","ref":"/docs/data/visual-art/matplotlib/","title":"Matploitlib"},{"body":"Analysis of large graphs  scikit-network ipycytoscape NetworkX Pytorch BigGraph  ","excerpt":"Analysis of large graphs  scikit-network ipycytoscape NetworkX Pytorch BigGraph  ","ref":"/docs/machinelearning/models/graph-nn/tools/graph-analysis/","title":"Graph Analysis"},{"body":" pytorch-Deep-Learning  ","excerpt":" pytorch-Deep-Learning  ","ref":"/docs/machinelearning/models/graph-nn/tools/tutorials/","title":"Tutorials"},{"body":"\n1. How to compare document similarity? A commonly used approach to match similar documents is based on counting the maximum number of common words between the documents.\nBut this approach has an inherent flaw. That is, as the size of the document increases, the number of common words tend to increase even if the documents talk about different topics.\nThe cosine similarity helps overcome this fundamental flaw in the ‘count-the-common-words’ or Euclidean distance approach.\n2. What is Cosine Similarity and why is it advantageous?  Cosine similarity is a metric used to determine how similar the documents are irrespective of their size.\n Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. In this context, the two vectors I am talking about are arrays containing the word counts of two documents.\n As a similarity metric, how does cosine similarity differ from the number of common words?\n When plotted on a multi-dimensional space, where each dimension corresponds to a word in the document, the cosine similarity captures the orientation (the angle) of the documents and not the magnitude. If you want the magnitude, compute the Euclidean distance instead.\n The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance because of the size (like, the word ‘cricket’ appeared 50 times in one document and 10 times in another) they could still have a smaller angle between them. Smaller the angle, higher the similarity.\n Documents in a 3-dimensional space\n3. What is soft cosine similarity?  Soft cosine similarity is similar to cosine similarity but in addition considers the semantic relationship between the words through its vector representation.\n Soft cosine similarity\nReferences  Cosine Similarity – Understanding the math and how it works (with python codes) Gensim Tutorial  ","excerpt":"1. How to compare document similarity? A commonly used approach to match similar documents is based …","ref":"/docs/machinelearning/nlp/nlp-tools/genism/","title":"Genism"},{"body":"","excerpt":"","ref":"/docs/coding/functional-coding/bash/","title":"Bash"},{"body":" Deep Learning  Ian Goodfellow and Yoshua Bengio and Aaron Courville\n The 65 books released by Springer  The Elements of Statistical Learning  Trevor Hastie, Robert Tibshirani, Jerome Friedman\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-0-387-84858-7\n Introductory Time Series with R  Paul S.P. Cowpertwait, Andrew V. Metcalfe\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-0-387-88698-5\n A Beginner’s Guide to R  Alain Zuur, Elena N. Ieno, Erik Meesters\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-0-387-93837-0\n Introduction to Evolutionary Computing  A.E. Eiben, J.E. Smith\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-662-44874-8\n Data Analysis  Siegmund Brandt\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-03762-2\n Linear and Nonlinear Programming  David G. Luenberger, Yinyu Ye\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-18842-3\n Introduction to Partial Differential Equations  David Borthwick\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-48936-0\n Fundamentals of Robotic Mechanical Systems  Jorge Angeles\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-01851-5\n Data Structures and Algorithms with Python  Kent D. Lee, Steve Hubbard\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-13072-9\n Introduction to Partial Differential Equations  Peter J. Olver\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-02099-0\n Methods of Mathematical Modelling  Thomas Witelski, Mark Bowen\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-23042-9\n LaTeX in 24 Hours  Dilip Datta\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-47831-9\n Introduction to Statistics and Data Analysis  Christian Heumann, Michael Schomaker, Shalabh\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-46162-5\n Principles of Data Mining  Max Bramer\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4471-7307-6\n Computer Vision  Richard Szeliski\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-84882-935-0\n Data Mining  Charu C. Aggarwal\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-14142-8\n Computational Geometry  Mark de Berg, Otfried Cheong, Marc van Kreveld, Mark Overmars\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-540-77974-2\n Robotics, Vision and Control  Peter Corke\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-54413-7\n Statistical Analysis and Data Display  Richard M. Heiberger, Burt Holland\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4939-2122-5\n Statistics and Data Analysis for Financial Engineering  David Ruppert, David S. Matteson\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4939-2614-5\n Stochastic Processes and Calculus  Uwe Hassler\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-23428-1\n Statistical Analysis of Clinical Data on a Pocket Calculator  Ton J. Cleophas, Aeilko H. Zwinderman\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-94-007-1211-9\n Clinical Data Analysis on a Pocket Calculator  Ton J. Cleophas, Aeilko H. Zwinderman\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-27104-0\n The Data Science Design Manual  Steven S. Skiena\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-55444-0\n An Introduction to Machine Learning  Miroslav Kubat\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-63913-0\n Guide to Discrete Mathematics  Gerard O’Regan\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-44561-8\n Introduction to Time Series and Forecasting  Peter J. Brockwell, Richard A. Davis\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-29854-2\n Multivariate Calculus and Geometry  Seán Dineen\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4471-6419-7\n Statistics and Analysis of Scientific Data  Massimiliano Bonamente\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4939-6572-4\n Modelling Computing Systems  Faron Moller, Georg Struth\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-84800-322-4\n Search Methodologies  Edmund K. Burke, Graham Kendall\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-6940-7\n Linear Algebra Done Right  Sheldon Axler\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-11080-6\n Linear Algebra  Jörg Liesen, Volker Mehrmann\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-24346-7\n Algebra  Serge Lang\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4613-0041-0\n Understanding Analysis  Stephen Abbott\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4939-2712-8\n Linear Programming  Robert J Vanderbei\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-7630-6\n Understanding Statistics Using R  Randall Schumacker, Sara Tomek\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-6227-9\n An Introduction to Statistical Learning  Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-7138-7\n Statistical Learning from a Regression Perspective  Richard A. Berk\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-44048-4\n Applied Partial Differential Equations  J. David Logan\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-12493-3\n Robotics  Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, Giuseppe Oriolo\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-84628-642-1\n Regression Modeling Strategies  Frank E. Harrell , Jr.\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-19425-7\n A Modern Introduction to Probability and Statistics  F.M. Dekking, C. Kraaikamp, H.P. Lopuhaä, L.E. Meester\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-84628-168-6\n The Python Workbook  Ben Stephenson\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-14240-1\n Machine Learning in Medicine — a Complete Overview  Ton J. Cleophas, Aeilko H. Zwinderman\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-15195-3\n Object-Oriented Analysis, Design and Implementation  Brahma Dathan, Sarnath Ramnath\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-24280-4\n Introduction to Data Science  Laura Igual, Santi Seguí\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-50017-1\n Applied Predictive Modeling  Max Kuhn, Kjell Johnson\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-6849-3\n Python For ArcGIS  Laura Tateosian\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-18398-5\n Concise Guide to Databases  Peter Lake, Paul Crowther\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4471-5601-7\n Digital Image Processing  Wilhelm Burger, Mark J. Burge\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4471-6684-9\n Bayesian Essentials with R  Jean-Michel Marin, Christian P. Robert\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-1-4614-8687-9\n Robotics, Vision and Control  Peter Corke\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-642-20144-8\n Foundations of Programming Languages  Kent D. Lee\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-70790-7\n Introduction to Artificial Intelligence  Wolfgang Ertel\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-58487-4\n Introduction to Deep Learning  Sandro Skansi\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-73004-2\n Linear Algebra and Analytic Geometry for Physical Sciences  Giovanni Landi, Alessandro Zampini\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-78361-1\n Applied Linear Algebra  Peter J. Olver, Chehrzad Shakiban\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-91041-3\n Neural Networks and Deep Learning  Charu C. Aggarwal\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-94463-0\n Data Science and Predictive Analytics  Ivo D. Dinov\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-72347-1\n Analysis for Computer Scientists  Michael Oberguggenberger, Alexander Ostermann\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-319-91155-7\n Excel Data Analysis  Hector Guerrero\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-030-01279-3\n A Beginners Guide to Python 3 Programming  John Hunt\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-030-20290-3\n Advanced Guide to Python 3 Programming  John Hunt\nhttp://link.springer.com/openurl?genre=book\u0026amp;isbn=978-3-030-25943-3\n","excerpt":"Deep Learning  Ian Goodfellow and Yoshua Bengio and Aaron Courville\n The 65 books released by …","ref":"/docs/swiss-knives/books/","title":"Books"},{"body":"\nMind  Author: A.M.Turing Paper  ","excerpt":"\nMind  Author: A.M.Turing Paper  ","ref":"/docs/machinelearning/ai/papers/mind/","title":"Mind"},{"body":"\nHigh-level training APIs in the PyTorch Ecosystem  Skorch Catalyst Fastai PyTorch Ignite PyTorch Lightning TorchBearer  Serve Model Serving on PyTorch\n Full Documentation  ","excerpt":"\nHigh-level training APIs in the PyTorch Ecosystem  Skorch Catalyst Fastai PyTorch Ignite PyTorch …","ref":"/docs/machinelearning/frameworks/pytorch/pytorch-toolkit/","title":"PyTorch"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/cv/","title":"CV"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/nlp/","title":"NLP"},{"body":"","excerpt":"","ref":"/docs/machinelearning/cv/tools/","title":"Tools"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/graph-nn/tools/","title":"Tools"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/nlp/nlp-tools/","title":"Tools"},{"body":"\nFibroblasts Fuel Immune Escape in the Tumor Microenvironment  Emiel A. De Jaeghere, Hannelore G. Denys, Olivier De Wever\nPublished: October 28, 2019\nTrends in Cancer\nDOI:https://doi.org/10.1016/j.trecan.2019.09.009 Read Here\n Cancer-Associated Fibroblast (CAF)-Dependent Mechanisms of Tumor Immune Escape\n","excerpt":"Fibroblasts Fuel Immune Escape in the Tumor Microenvironment  Emiel A. De Jaeghere, Hannelore G. …","ref":"/docs/healthcare/papers/fibroblasts/","title":"Fibroblasts"},{"body":"\nLicense To the extent possible under law, papers-we-love has waived all copyright and related or neighboring rights to this work.\nWhere to Find Papers  ICLR Deep Learning Papers Reading Roadmap awesome-deep-learning-papers 2 Minute Papers Bell System Technical Journal, 1922-1983 Best Paper Awards in Computer Science Facebook Google Scholar (choose a subcategory) Microsoft Research Functional Programming Books Review MIT\u0026rsquo;s Artificial Intelligence Lab Publications MIT\u0026rsquo;s Distributed System\u0026rsquo;s Reading Group arXiv Paper Repository SciRate cat-v.org y-archive netlib Services Engineering Reading List Readings in Distributed Systems Gradual Typing Bibliography Security Data Science Papers Research Papers from Robert Harper, Carnegie Mellon University Lobste.rs tagged as PDF The Morning Paper   Check out paper-we-love- wiki-page for links to blogs, books, exchanges that are worth a good read.\nCheck out more on YouTube and MixCloud (audio-only format) channels.\n How To Read a Paper  How to read an academic article Advice on reading academic papers How to read and understand a scientific paper Should I Read Papers? The Refreshingly Rewarding Realm of Research Papers  ","excerpt":"License To the extent possible under law, papers-we-love has waived all copyright and related or …","ref":"/docs/swiss-knives/find-papers/","title":"Find Papers"},{"body":"\nTable of Contents  Calculus Derivatives and integrals The paradox of the derivative Chain rule and product rule Derivatives of exponentials Implicit differentiation Limits, L\u0026rsquo;Hopital\u0026rsquo;s rule, and epsilon delta definitions Integration and the fundamental theorem of calculus The average of a continuous variable Higher order derivatives Taylor series References  Calculus  A philosophy about concrete finitely small nudge\n Fathers of calculus, 1:05     Derivatives and integrals  How to calculate the area of a circle?\n   The area of a circle can be approximated to the aggregated areas of many rectangles ($2\\pi rdr$, perimeter $2\\pi r$ as the length*width $dr$)\n  Area 6:45\n  The paradox of the derivative   Derivative: to calculate the derivative at one time point (e.g. velocity), we actually need two time points (to calculate $\\frac{Distance Change}{TimeChange}$)\n  Derivative, 8:16\n    Make the time point interval $\\to$ 0\n  The derivative as an instaneous rate of change = The best constant approximation of the rate of change\n  The slope of the line tangent to the point at t $\\to$\n  Derivative example, 12:30\n  Chain rule and product rule  Sum rule: The derivative of a sum is the sum of derivatives    $\\frac{d}{dx}(g(x)+h(x)) = \\frac{dg}{dx} + \\frac{dh}{dx}$\n  e.g. $\\frac{d}{dx}(sin(x)+x^2 = cos(x) + 2x$\n  Sum rule, 3:05\n  Product rule: try to use an area for visualization    Numerically: Left d(Right) + Right d(Left)\n  $f(x) = g(x)h(x)$\n  $df = g(x)dh + h(x)dg$\n  $\\frac{df}{dx} = g(x)\\frac{dh}{dx} + h(x)\\frac{dg}{dx}$\n  Product rule, 7:20\n  Function composition    Chain Rule: $\\frac{d}{dx}g(h(x)) = \\frac{dg}{dg}(h(x))\\frac{dh}{dx}(x)$\n  A small change in x $\\to$ A small change in the intermediate number $\\to$ Nudge the change in the final value\n  Chain rule, 11:37\n  Derivatives of exponentials  The Euler\u0026rsquo;s number e    $e = 2.71828$\n  $M(t) = e^t$\n  Numerically: $\\frac{dM}{dt}(t) =\\frac{e^0.00000001 -1}{0.00000001} =e^t(1.000000000)$\n  Geometrically: The slope of a tangent line to any point on the $e^t$ graph equals the height of that point at the horizontal axis\n  Constant e, 8:52\n  Use the chain rule for other exponential functions   $2 = e^{(ln(2))}$ $2^t = e^{(ln(2))t}$, the exponential function of 2 $ln(2)2^t = ln(2)e^{ln(2)t}$, the derivative  Implicit differentiation  Implicit curve: a plane curve defined by an implicit equation relating two coordinate variables, commonly x and y Example   $x^2 + y^2 =5$ the implicit curve function\n  $2xdx + 2ydy = 0$ the implicit differentiation process. $0$ means we want $x^2 + y^2$ not change\n  $\\frac{dx}{dy} = \\frac{-x}{y}$ the slope of the tangent line to the circle\n  Implicit curve, 3:03\n     A related rates problem: how the rates of change for each of the values depend on each other Example   $x(t)^2 + y(t)^2 =5$ pythagorean theorem, x and y are functions of time, the top of the ladder $y$ is dropping at $1m/s$, find out the rate of the bottom of the ladder that is moving from the wall at the initial moment\n  Related rates, 7:12\n     Two more multivariable calculus problem: try to have a clear understanding of how what tiny nudges are playing and how they depend on each other Example 1   $sin(x)y^2 =x$, represent a bunch of points $(x,y)$ on the curves\n  $sin(x)(2ydy) + y^2cos(x)dx = dx$ Geometrically, this means the left and the right side change must be the same to keep the points on the curves\n  $\\frac{dy}{dx} = \\frac{1-y^2}{2tan(x)y}$\n  Multi variable, 12:31\n     Example 2   $y =ln(x)$, $\\frac{dy}{dx} = \\frac{d(ln(x))}{dx}$\n  $e^y =x$, $\\frac{dy}{dx} = \\frac{1}{x}$\n  $\\frac{dy}{dx} = \\frac{1}{x}$\n  Multi variable 2, 14:31\n    Limits, L\u0026rsquo;Hopital\u0026rsquo;s rule, and epsilon delta definitions  The official definition of derivative  The rise-over-run slope between the starting point on the graph and the nudged point when the difference between the input and nudged input is close to 0 ($dx$) $$\\frac{df}{dx}(x)=\\lim_{dx\\to 0}\\frac{f(x+dx)-f(x)}{dx}$$ Replace dx with a commonly used variable h (or $\\Delta x$ ) $$\\frac{df}{dx}(x)=\\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h}$$     The epsilon delta definition   The formalization of the notion of limit (one value approach to another)\n  Baron Augustin-Louis Cauchy first used, Bernard Bolzano gave the definition\n  The dependent expression f(x) approaches the value L as the variable x approaches the value c if f(x) can be made as close as desired to L by taking x sufficiently close to c.\n  Epsilon delta, 9:23\n     L\u0026rsquo;Hopital\u0026rsquo;s rule  Johann Bernoulli $\\to$ Guillaume de l\u0026rsquo;Hôpital When you are solving a limit, and get $0/0$ or $∞/∞$, L\u0026rsquo;Hôpital\u0026rsquo;s rule is the tool you need Conditions:  $$\\lim_{x\\to c}f(x) =\\lim_{x\\to c}g(x) = 0$$ $$\\lim_{x\\to c}f(x) =\\lim_{x\\to c}g(x) = \\pm \\infty$$   Conclusion:  $$\\lim_{x\\to c}\\frac{f(x)}{g(x)} = \\lim_{x\\to c}\\frac{f'(x)}{g'(x)}$$      Integration and the fundamental theorem of calculus  Integral: the fundamental theorem of calculus   The sum of a large number of small values on the continuum between the lower bound a and upper bound b\n  Given a function $f(x)$, find $F(x)$, the antiderivative of $f(x)$\n  The reverse relation of derivative ($f(x)$ is the derivative of F ⟺ $f$ is an antiderivative of $f'$)\n  Calculate he integral of $f(x)$: $\\int_a^b f(x)dx = F(b) - F(a)$\n  Each function has a family of antiderivatives (the difference between the family members is the constant $C$)\n  Geometrically: integrals don\u0026rsquo;t measure the area per se, they measure the signed area\n  Integral, 15:32\n  Integral example, 20:25\n  Integral signed area, 20:45\n    The average of a continuous variable  Cyclic phenomenon are modelled using sin waves Example  Average height $= \\frac{Area}{Width} = \\frac{\\int_0^\\pi \\sin(x)dx}{\\pi}$    Higher order derivatives  Higher-order derivative, 5:38  Taylor series   Scottish mathematician James Gregory and formally introduced by the English mathematician Brook Taylor\n  Used for approximate functions: to find the polynomial functions for non-polynomial functions\n  A general nth-degree polynomial $f(x) = a_0 + a_1(x-c)+ a_2(x-c)^2 +a_3(x-c)^3+\u0026hellip;$\n Closed form: $f(x) = \\sum_{j=0}^{\\infty} a_j(x-c)^j$    $f(x) = \\frac{f(c)}{0!} +\\frac{f’(c)}{1!}(x-c) +\\frac{f’’(c)}{2!}(x-c)^2 + \\frac{f’’’(c)}{3!}(x-c)^3+\u0026hellip;$\n Closed form: $f(x) = \\sum_{j=0}^{\\infty} \\frac{f^{(j)}(c)}{j!}(x-c)^j$    Maclaurin\u0026rsquo;s series: when c=0\n   References  Essence of calculus L\u0026rsquo;Hôpital\u0026rsquo;s rule introduction Antiderivatives and indefinite integrals Taylor \u0026amp; Maclaurin polynomials intro (part 1) Taylor Series An Easy Way to Remember the Taylor Series Expansion  ","excerpt":"Table of Contents  Calculus Derivatives and integrals The paradox of the derivative Chain rule and …","ref":"/docs/math/intro/calculus/","title":"Calculus"},{"body":"\n A guide to convolution arithmetic for deep learning  ","excerpt":"\n A guide to convolution arithmetic for deep learning  ","ref":"/docs/machinelearning/models/deep-learning/cnn/","title":"CNN"},{"body":"\nCoursera Course Instructor Andrew Ng\nExercises Text data processing   Use word embeddings to solve a Word Analogy problem\nJupyter Notebook\n  Use word embeddings and Keras LSTM to solve a Sentiment Classification problem\nJupyter Notebook\n  Character-level language model\nJupyter Noteboook\n  Audio data processing   Trigger word detection\nJupyter Notebook\n  Music generation\nJupyter Notebook\n  Notes ","excerpt":"\nCoursera Course Instructor Andrew Ng\nExercises Text data processing   Use word embeddings to solve …","ref":"/docs/machinelearning/models/deep-learning/sequence-models/","title":"Sequence Models"},{"body":"\n1. What are word representations?  One-Hot encodings Featurized representaion: word embeddings  Word embedding is one of the most popular word representation. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc.    2. Summary of word embeddings     Word Embeddings     Transfer Learning yes   Training Set small   Entity recognition, text summarization, co-reference resolution, parsing Good   Language modeling and machine translation Bad   Visulization t-SNE    3. How does word embedding algorithms work?   How to use word embeddings to solve a Word Analogy problem?\n  How to load pre-trained word vectors, and Measure Similarity using cosine similarity\n  How to modify word embeddings to reduce their gender bias\n  Try the exercise on Coursera Coursera notebook\n  Take a look at my notebook\n  4. How to create an embedding layer and build a Kears LSTM model for sentiment classification?   Try the Emotify exercise on Coursera Coursera notebook\n(Input a sentence and find the most appropriate emoji)\n  Take a look at my notebook\n   Reference   Natural Language Processing \u0026amp; Word Embeddings, Coursera\n  Introduction to Word Embedding and Word2Vec\n  ","excerpt":"1. What are word representations?  One-Hot encodings Featurized representaion: word embeddings  Word …","ref":"/docs/machinelearning/models/deep-learning/sequence-models/word-embeddings/","title":"Word Embeddings"},{"body":"\n Keep calm and code on.\n ","excerpt":"\n Keep calm and code on.\n ","ref":"/docs/coding/","title":"Coding"},{"body":"\nLicense To the extent possible under law, sdmg15 has waived all copyright and related or neighboring rights to this work.\nIndex  When you get stuck News Magazines Coding practice for beginners Cryptocurrency For those who want to start a small project but can't find the ideas General Coding advice Coding Style General Tools Interview Preparation Documentaries MOOCs for learning something new Sites related to your preferred programming language (For me Java) Learn AI Seminar , research writing , talks etc Everything in one place YouTube Channels Good Articles Bash and Shell scripting Podcasts Building a Simple Compiler/Interpreter Watch others code Tutorials What should a programmer know Competitive programming Computer Books Video Tutorials Online Compiler and Sharing Code snippets Blogs of Developers For improving your English When you get bored from CS related stuff Open Source Websites Jobs  When you get stuck  Codementor : A mentorship community to learn from fellow developers via live 1:1 help and more. devRant : Community where you can rant and release your stress Learn Anything : Community curated knowledge graph of best paths for learning anything Quora : A place to share knowledge and better understand the world Stack Overflow : subscribe to their weekly newsletter and any other topic which you find interesting  News  ACM TechNews : TechNews Stratechery : Stratechery by Ben Thompson AlternativeTo : Crowdsourced software recommendations Ars Technica : posts unique quality articles Better Dev Links : Weekly links to help you become a better developer DevOpsLinks : An online community of thousands of developers and IT experts interested in DevOps GSMArena.com : news related to latest mobile phones and android. Hacker News Digest : curated automatically, delivered as frequently as you want Hacker News : news aggregator for programmers where civility is king, try a newsletter to get top news to your inbox: Hacker Newsletter : curated by hand, delivered weekly Hacker Noon : How hackers start their afternoons. High Scalability : Success stories of various companies on their apps, infra scaling. Lobsters : Lobsters is a technology-focused community centered around link aggregation and discussion. product hunt : Discover your next favorite thing Recode : Tech news that focuses on the business of Silicon Valley Reddit.com/r/programming : Subreddit with aggregated tech news and articles Slashdot : News, Social news (Originally \u0026ldquo;News for Nerds. Stuff that Matters\u0026rdquo;) StackShare : See what tools are popular with developers and companies and read about their technology decisions TechCrunch : dedicated to obsessively profiling startups, reviewing new Internet products, and breaking tech news The DEV Community : Where programmers share ideas and help each other grow. The Verge : More product oriented tech news WCCF Tech : curated news related to Computer Hardware, Software and everything else in the Tech World. XDA : Android Developers News Hashnode : Hashnode is a friendly and inclusive community for software developers  Magazines  MIT Technology Review : MIT\u0026rsquo;s tech review magazine. Nautilus : NewYorker for tech. LWN : Weekly news coverage of opensource technologies, programming, etc. ( Originally Linux Weekly News).  Coding practice for beginners  freeCodeCamp : Learn to code and build projects for nonprofits. Build your full stack web development portfolio today Blackbird School : Learn to code online with our beginner-friendly platform. Glitch : Great place to play around with code in an easy-to-set-up environment. Reddit.com/r/dailyprogrammer : interesting programming challenges where you can learn from looking at other\u0026rsquo;s code , even if you are not able to solve code you can look at how others solved. Programming by Doing : very good site for those who want to start with absolute basics CodeAbbey - a place where everyone can master programming : Best place to begin with problems that start at the easiest and gradually increase difficulty with each problem. Exercism.io : download and solve practice problems in over 30 different languages, and share your solution with others. InterviewBit | Coding Interview Questions : Gamifies the experience of practicing for your interview and includes lots of sample problems to solve. karan/Projects-Solutions : Solutions to most of the problems in the link above Lod - Cloud : The Linking Open Data cloud diagram Cave of programming : Learn to program, Upgrade your skills. Vim adventures : Learn VIM by playing Programming Tasks : large collection of small programs Pramp : It\u0026rsquo;s your turn to be the interviewer. when done, click on the swap roles button on the left Paqmind : Guides and challenges to learn programming gitignore : A collection of useful .gitignore templates for your project. Select from 442 Operating System, IDE, and Programming Language Codeacademy : Learn to code interactively, for free. treehouse : The fast, easy, and affordable way to build your skills. GeeksforGeeks : Learn to code, Study for placement, Do competitive coding.  CryptoCurrency  Blockchain demo : A visual demo of Blockchain technology Coin demo : CryptoCurrency demo Lopp Bitcoin Resources : Some Bitcoin Resources Blockchain Basics : Great introduction to blockchain GitCoin : Gitcoin is the easiest way to monetize or incentivize work in Open Source Software. Lite Paper : Cryptocurrencies \u0026amp; Blockchain made effortless  For those who want to start a small project but can\u0026rsquo;t find the ideas  freeCodeCamp | React project ideas : 27 fun app ideas you can build while learning React. martyr2s-mega-project-ideas-list : contains about 125 project ideas from beginner to intermediate level. karan/Projects : a large collection of small projects for beginners with Wrong \u0026ldquo;big projects\u0026rdquo; for beginners : How to choose where to start vicky002/1000-Projects : Mega List of practical projects that one can solve in any programming language! reddit.com/r/AppIdeas : A place to discuss ideas for applications, for bored developers. reddit.com/r/SomebodyMakeThis : A home for ideas by people who lack time, money, or skills.  General Coding advice  10-ways-to-be-a-better-developer : Ways to become a better dev! Code Review Best Practices : Kevin London\u0026rsquo;s blog Design Patterns : Design Patterns explained in detail with examples. Develop for Performance : High-performance computing techniques for software architects and developers How to become a programmer, or the art of Googling well : How to become a programmer, or the art of Googling well How to escape tutorial purgatory as a new developer — or at any time in your career : How to escape tutorial purgatory JS Project Guidelines : A set of best practices for JavaScript projects. Learn to Code With Me : A comprehensive site resource by Laurence Bradford for developers who aims to build a career in the tech world Lessons From A Lifetime Of Being A Programmer : The Codist Header Lessons From A Lifetime Of Being A Programmer Programming Principles : Categorized overview of Programming Principles \u0026amp; Patterns Software design pattern : The entire collection of Design Patterns. Things I Wish Someone Had Told Me When I Was Learning How to Code — Free Code Camp : What I’ve learned from teaching others What every computer science major should know : The Principles of Good Programming Working as a Software Developer : Henrik Warne\u0026rsquo;s blog The Open Web Application Security Project (OWASP) : OWASP is an open community dedicated to enabling organizations to conceive, develop, acquire, operate, and maintain applications that can be trusted.  Coding Style  Airbnb JS Style Guide : A mostly reasonable approach to JavaScript Airbnb Ruby Style Guide : A ruby style guide by Airbnb Ruby coding style guide : A community-driven Ruby coding style guide Angular 1 Style Guide : Officially endorsed style guide by John Pappa CS 106B Coding Style Guide : must see for those who create spaghetti Debugging Faqs : Check out how to debug your program Directory of CS Courses (many with online lectures) : Another online CS courses Directory of Online CS Courses : Free online CS courses Good C programming habits. • /r/C_Programming : C programming habits to adopt Google C++ Style Guide How to Report Bugs Effectively : Want to report a bug but you don\u0026rsquo;t how? Check out this post What are some bad coding habits you would recommend a beginner avoid getting into? : Bad habits to avoid when you get start PEP8 - Style Guide for Python Code : Style Guide for Python Code Standard JS Style Guide : JavaScript style guide, with linter \u0026amp; automatic code fixer Google Python Style Guide : Google Python Style Guide Aurelia Style Guide : An Aurelia style guide by Behzad Abbasi(Behzad888) Source Making : Design Patterns \u0026amp; Refactoring  General Tools  CodePad : Quickly Conduct Coding Interviews and Phone Screen Interviews. CodePen : Front End Developer Playground \u0026amp; Code Editor in the Browser Devicons : Cheatsheet for devs icons regex101 : Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript regexr : Another online tool to learn, build \u0026amp; test Regular Expressions Wit AI : Natural Language for Developers Seymour : Live Programming for the Classroom Code share : Share code in real-time with other developers Solid Tools for Developers : Online debugging tools for developers and system administrators OS Query : Easily ask questions about your Linux, Windows, and macOS infrastructure LaunchPad : Appollo launchepad for testing GraphQl queries IDE Onlang : Write in one language and get the same result in other languages. PullRequest : Code review as a service from vetted, professional reviewers Extends Class : Online developer tools: REST and SOAP clients, SQLite browser, testers (Regex, XPath, JSONPath) and other tools (Encoders, Converters and formatters) EmailDrop: Emaildrop is a free disposable email provider.  Bash and Shell scripting  Advanced Bash-Scripting Guide : An in-depth exploration of the art of shell scripting Bash Guide for Beginners : Bash Guide for Beginners Machtelt Garrels Bash Programming : by Mike G mikkey at dynamo.com.ar Bash Reference Manual : Bash Reference Manual BashGuide : BashGuide - Greg\u0026rsquo;s Wiki Conquering the Command Line : Unix and Linux Commands for Developers Airbon OS : Private Google Docs Alternative  Interview Preparation  /r/cscareerquestions : Here\u0026rsquo;s a pretty big list of programming interview questions I compiled while studying for big 4 interviews. I think you guys will find it useful! 10 Frequently asked SQL Query Interview Questions A Collection of Quant Riddles With Answers Algorithm design canvas Aptitude Questions and Answers : Quant and aptitude preparation A site for technical interview questions, brain teasers, puzzles, quizzles : whatever the heck those are) and other things that make you think! BeehYve : Student crowdsourced resources for any topic Big collection of interview preparation links • /r/cscareerquestions Big-O Algorithm Complexity Cheat Sheet BIG O Misconceptions Bitwise tricks ChiperSoft/InterviewThis : questions to ask during on a interview to know more about the company. Code Project : For those who code! Core Java Interview questions - Interview question on each topic C PUZZLES, Some interesting C problems CS9: Problem-Solving for the CS Technical Interview Delightful Puzzles Determining the big-O runtimes of these different loops? : really good stackoverflow question that covers basics of calculating runtime complexity. five-essential-phone-screen-questions - steveyegge2 Freshers Interviews Gainlo : Mock interview from professionals GeeksforGeeks | A computer science portal for geeks : also subscribe to their feeds to get links to their new articles. github.com/odino/interviews : list of important questions for interview Give your résumé a face lift Here\u0026rsquo;s How to Prepare for Tech Interviews • /r/cscareerquestions How to Answer \u0026ldquo;Tell Me a Little About Yourself\u0026rdquo; | The Art of Manliness How to Answer the Toughest 40 Job Interview Questions | ICS Job Portal How to Break Into the Tech Industry - a Guide to Job Hunting and Tech Interviews How to interview How to prepare for an interview - 1 IIT Delhi Placement Experience Interviewing At Jane Street : Interviewing At Jane Street Interview Archives - Java Honk Job Interview: How to Ace a Job Interview | The Art of Manliness Job interviews News, Videos, Reviews and Gossip - Lifehacker Job Interview Questions and Best Answers kimberli/interviews : study sheet for Interview LeetCode : A new way to learn.here you can prepare for your interview. Mission-peace/interview problems : A large collection of coding interview problems Pramp | A free on demand interview practice platform for Software Engineers : Practice coding interviews with real peers Problems | LeetCode OJ : Coding practice for interviews Programmer And Software Interview Questions Answers Reddit.com/user/ashish2199/m/puzzles : Logic Puzzles SQL interview questions : great SQL test SQL Joins explained using venn diagram svozniuk/java-interviews : Java interview questions The 25 most difficult HR questions Top 10 Algorithms for Coding Interview : Algorithms for Coding Interview Unix / Linux Cheat Sheet Unsolicited_advice_for_job_seekers_and_employers Visualising Data Structures and Algorithms through Animation We Help Coders Get Hired : website offering courses on system design, interview strategies, soft skills etc what_are_your_goto_questions_for_the_do_you_have? Why You Make Less Money • /r/cscareerquestions wu :: riddles(hard) : logic puzzles and riddles  Documentaries  Breaking the Code : Biography of Alan Turing Cracking The Code Interview : Cracking the Code Interview Cracking the Coding Interview : Cracking the Coding Interview, Fullstack Speaker Series Download: The True Story of the Internet : Play-list of discovery channel documentary on browser wars, dot com bubble and more. Harvard CS50 - Asymptotic Notation (video) : Asymptotic Notation explained by Harvard How does CPU execute program (video) : Take a look at how a CPU executes programs Machine Code Instructions (video) : Code instructions Machine that Changed the World - a very good documentary about history of computers  Part 1 is unavailable for free streaming due to widespread copyright claims. Part 2: Inventing the Future Part 3: The Paperback Computer Part 4: The Thinking Machine Part 5: The World at Your Fingertips   Mechanical Computer (All Parts) : a very good video from 1950s explaining how mechanical computers used to work without all the modern day electronics. Project Code Rush : The Beginnings of Netscape / Mozilla Documentary Revolution OS Linux Documentary : a film that traces the history of GNU, Linux, open source, and the free software movement. Teach Yourself Computer Science : Teach Yourself Computer Science The Code : Story of Linux documentary Triumph of the Nerds : Play-list The Internet\u0026rsquo;s Own Boy : The Story of Aaron Swartz  MOOCs for learning something new  Class Central : a directory of 100,000+ student reviews of thousands of MOOCs. Classpert : a website that gathers MOOCs and online courses from several providers, focusing on computer science and data science courses. Computer Science Resources : list of MOOCs for autodidacts Coursera.org : Take the world\u0026rsquo;s best courses, online. CS50 : A set of goods tutorials from cs50 edX : Free Online Courses, Advance Your Career, Improve Your Life. Kadenze | Creative Programming : Programming courses focused on art and creativity MIT OCW Electrical Engineering and Computer Science MOOC.fi : Free online courses from the University of Helsinki NPTEL : Free online courses by IIT with certificates prakhar1989/awesome-CS-courses : List containing large amount of CS courses  Sites related to your preferred programming language (For me C++)  Best books for learning java must read : Get basics of Java Bjarne Stroustrup\u0026rsquo;s C++ Style and Technique FAQ : The C++ FAQ Bjarne Stroustrup\u0026rsquo;s FAQ : The C++ FAQ C++11 - the new ISO C++ standard : The C++11 FAQ Compilers (video) : A set of videos on how the GC works Deep Dive Java : Garbage Collection is Good! Free Online Chapters of Inside the Java Virtual Machine by Bill Venners : Java Corner How Garbage Collection Works : Java memory management Implementation of Algorithms and Data Structures, Interview Questions and Answers IntelliJ Keyboard Shortcuts : Keyboard shortcuts to enhance your productivity when working in IntelliJ. Java Corner at Artima.com : Java Corner at Artima.com Java Lecture Notes : Java Student\u0026rsquo;s Resource Java Off Heap : Java Off the Heap house Java Revisited : good for learning about Java Language and interview preparation. Java-source : Java source Java Visualizer : helps visualize references, values of variables, etc JournalDev - Java, Java EE, Android, Web Development Tutorials : Java, Java EE, Android, Web Development Tutorials Learning Java : a free online textbook for learning Java Netbeans Keyboard Shortcuts : Keyboard shortcuts to enhance your productivity when working in Netbeans. Search Open Source Java API : view source of java library and learn how things are implemented. The C++ Programming Language : The C++ Programming Language. The Java Memory Model: The Java Memory Model The Java™ Tutorials : The best tutorials for Java. Understanding JVM Internals : Understanding JVM Internals what-is-garbage-collection : Demystify the garbage collection JavaWorld : Welcome to Javaworld XyzWs Java FAQs : large collection of java interview questions JavatPoint : Best website to get a basic Java programming tutorial  Learn AI  aima : The leading textbook in Artificial Intelligence (4th most cited publication of the century). Includes Github repositories and more AI resources! fast.ai : Free practical deep learning course for coders without grad-level maths! grakn.ai : The Database for AI Robots that learn : Robots that Learn Unsupervised Sentiment Neuron : Unsupervised Sentiment Neuron What\u0026rsquo;s the difference between AI- DP and ML? : Difference artificial intelligence, machine-learning, deep-learning-ai TensorFlow : An open-source software library for Machine Intelligence Scikit-learn : A Python module for machine learning build on top of SciPy DeepLearning.ai : Deep Learning course by Andrew Ng, Founder of coursera Coding the History of Deep Learning : Coding the History of Deep Learning Serpent AI : Game Agent Framework. Helping you create AIs / Bots to play any game you own! BETA Blog Floydhub : Colorizing B\u0026amp;W Photos with Neural Networks MLCOURSE.AI : Open Machine Learning course by OpenDataScience  Seminar , research writing , talks etc  Advice on Research and Writing : A collection of advice about how to do research and how to communicate effectively (primarily for computer scientists). PHD MS Articles : articles and views Seminar and reports : Everyone must read this tiny book before writing the seminar report Latex reference : Arbitrary reference Begin Latex in minutes : Brief Intro to LaTeX for beginners that helps you use LaTeX with ease Lshort : The Not So Short Introduction to LATEX2ε  Everything in one place  reddit.com/user/ashish2199/m/cs_student_subs : a multisubreddit of all subreddits of topics related to computer science and programming. Websites a programmer should visit : Response on Quora by ashish2199 Rico\u0026rsquo;s cheatsheets : A set of good cheatsheets API Documentation : A one-place well known API Documentation with searchable interface MDN : A place with all the documentation of the web standards cheat.sh : curl cheat.sh — the only cheat sheet you need — instant answers on programming questions with curl  YouTube Channels  C++Now (BoostCon) : C++Now (previously BoostCon) conference code::dive conference : code::dive conference organized by NOKIA Wrocław Technology Center Coding Blocks : Tutorials, how to\u0026rsquo;s, tips and tricks Computerphile : Must watch for every CS student ComputerHistory : for those who like to know how we reached where we are. CppCon : C++ Conference Facebook Developers Google Developers GoogleTechTalks : videos on trending topics and cool stuff happening in the tech industry. Gynvael Coldwin : Awesome reverse engineering and hacking(CTF) videocasts. Every wednesday are new live streams. HowToBecomeTV : contains good interviews of developers and people related to tech industry. Java : talks related to java JavaOne : Java Conference javidx9 : Game and graphics tutorials Meeting C++ YT Kanalseite : Talks on C++ MIT OpenCourseWare : MIT OpenCourseWare for learning in depth algorithms, data structures and computer engineering Netflix UI Engineering : great videos to watch for web developers, mobile developers and those interested in some of Netflix\u0026rsquo;s tech stack O\u0026rsquo;Reilly : interviews and talks of world\u0026rsquo;s best technical writers. Placement Grid : Interview and campus placement experience Scott Meyers: Past Talks Siraj Raval : Artificial Intelligence and deep learning tutorials videos ThinMatrix : blogs and tutorials developer making a 3d game in Java using opengl thoughtbot : talks on various topics Traversy Media :Web development and programming yegor256 GOTO Conference : tech talks from the GOTO Conference by Developers for Developers freeCodeCamp : freecodecamp youtube channel Bo Qian : Learn advanced c++ Geeksforgeeks : geeksforgeeks youtube Hacker earth : Hacker earth youtube Hak5 : Put together by a band of IT ninjas, security professionals and hardcore gamers, Hak5 isn\u0026rsquo;t your typical tech show. We take on hacking in the old-school sense. Khan Academy : Khan Academy youtube LearnCode.academy : 100% FREE Web Development tutorials, web site design tutorials and more. Including, but not limited to: HTML, CSS, JavaScript, CSS Layouts, Responsive Design, React.js, Node.js, Angular.js, Docker, Dev Rachit Jain : competetive programming sentdex : Python Programming tutorials, going further than just the basics. Learn about machine learning, finance, data analysis, robotics, web development, game development and more. Steve Griffith : The videos on this channel are largely about web design \u0026amp; development with a good dose of mobile development thrown in just for fun. The Coding Train : In this YouTube channel I publish \u0026ldquo;creative coding\u0026rdquo; video tutorials every week. Subjects covered range from the basics of programming languages like JavaScript (with p5.js) and Java (with Processing) to generative algorithms like physics simulation, computer vision, and data visualization. TheHappieCat : Videos on technology, storytelling, and being happie. Tutorials Point (India) Pvt. Ltd. : Tutorials Point originated from the idea that there exists a class of readers who respond better to online content and prefer to learn new skills at their own pace from the comforts of their drawing rooms. We bring simple to understand Text and Video tutorials at zero cost and cover many subjects including IT, Engineering, MBA, MCA, Management, Various Exams Preparation and Academic subjects. If you are really not extravagant and willing to save your money and time then we recommend you to try our tutorials.experience Udacity : Udacity, a pioneer in online education, is building \u0026ldquo;University by Silicon Valley\u0026rdquo;, a new type of online university V. Anton Spraul : Videos for people who want to understand software better, including explanations of how software performs some of its most important jobs and tools programmers can use to to solve programming problems. xdadevelopers : You have found the world-famous XDA-Developers.com YouTube Channel, known as XDA TV. We cover Android and Windows Mobile from HTC, Samsung, Motorola, Sony, and more. Learn about rooting your Android, how to build applications, and more. KudVenkat : Microsoft .NET technologies and SQL Server tutorials. The Net Ninja: Web development tutorials  Good Articles  40 Keys Computer Science Concepts Explained In Layman’s Terms A Gentle Introduction To Graph Theory A programmer friendly language that compiles to Lua. A Software Developer’s Reading List : Some good books and links in there. Code a TCP/IP stack : Let\u0026rsquo;s code a TCP/IP stack, 5: TCP Retransmission Codewords.recurse : The language of choice Data structure and Algorithms : List of some algorithms and datastructure with their solutions. Dive into the byte code Expectations of a Junior Developer Linux Inside List of algorithms Step by Step Guide to Database Normalization: A guide to database normalization. The Key To Accelerating Your Coding Skills Unicode We are reinventing the retail industry through innovative technology What every programmer absolutely, positively needs to know about encodings and character sets to work with text What every programmer should know about memory - PDF Why fast pages are important : Why App Speed Matters, Revenue qotoqot - improving-focus : How I got to 200 productive hours a month Pixel Beat - Unix : Parallel processing with unix tools Learning Vim : What I Wish I Knew Write a Kernel : Kernel 101 – Let’s write a Kernel Learning JavaScript Design Patterns : online version of the Learning JavaScript Design Patterns published by O\u0026rsquo;Reilly, released by the author Addy Osmani under CC BY-NC-ND 3.0 Working with Webhooks : a comprehensive guide on webhooks  Podcasts  Coding Blocks : A podcast covering topics such as best programming practices, design patterns, coding for performance, object oriented coding, database design and implementation, tips, tricks and a whole lot of other things. Developer On Fire : A podcast that shares the humanity of developers and tells stories of some of the amazing people in software, hosted by Dave Rael. Developer Tea : A podcast for developers designed to fit inside your tea break. Front End Happy Hour : A podcast featuring a panel of Software Engineers from Netflix, Evernote, Atlassian \u0026amp; LinkedIn talking over drinks about all things Front End development. Full Stack Radio : Everything from product design and user experience to unit testing and system administration. Groovy Podcast : A podcast dedicated to the Groovy programming language and its ecosystem. IPhreaks : A weekly group discussion about iOS development and related technology by development veterans. We discuss Apple, tools, practices, and code. JavaScript Jabber : A weekly discussion about JavaScript, front-end development, community, careers, and frameworks. Learn To Code With Me Podcast : A Season by season of tech podcast episodes by Laurence Bradford with topics ranging from Career in Tech to lessons in doing tech business MS Dev Show : Jason Young and Carl Schweitzer talk about the latest in developer news covering topics such as the Azure cloud, Windows, Windows Phone, Visual Studio, and cross-platform development using the Microsoft platform. React Native Radio : A weekly discussion of the tools, techniques, and technologies used to build mobile applications with JavaScript and React. Soft Skills Engineering : A weekly advice podcast for software developers about non-technical topics. Software Engineering Daily : A daily technical interview about software topics. Software Engineering Radio : A podcast targeted at the professional software developer. The goal is to be a lasting educational resource, not a newscast. Syntax : A Tasty Treats Podcast for Web Developers by Wes Bos \u0026amp; Scott Tolinski. The Bike Shed : Guests discuss their development experience and challenges with Ruby, Rails, JavaScript, and others. The Changelog : A weekly conversation that gets to the heart of open source technologies and the people who create them. The Cynical Developer : A podcast that aims to help you to improve your development knowledge and career, through explaining the latest and greatest in development technology and providing you with what you need to succeed as a developer. Covering Desktop, web and mobile development, mainly around the .Net Stack but often looking into other software and frameworks. Blockchain Insider by 11:FS : Podcast to learn about the Blockchain Technology Unchained Podcast to learn about the Blockchain Technology Talk python to me Podcast to learn about Python through interviews and discussions Python bytes Podcast to learn about the latest happenings and trends in Python  Building a Simple Compiler/Interpreter  ☃️ Possibly the smallest compiler ever : This is an ultra-simplified example of all the major pieces of a modern compiler written in easy to read JavaScript. Awesome Compilers : Curated list of awesome resources on Compilers, Interpreters and Runtimes. Growing a compiler : Learn how to grow a compiler Let’s Build A Simple Interpreter. Part 1. : Try to demystify compilers by building one Resources for Amateur Compiler Writers : Resources for Amateur Compiler Writers Structure and Interpretation of Computer Programs : Structure and Interpretation of Computer Programs Writing My First Compiler : Write out your first compiler An Intro to Compilers : How to Speak to Computers, Pre-Siri Write your own compiler : How to write your own compiler Crafting Interpreters A handbook for writing interpreters, first implementing a tree walking interpreter and later a bytecode virtual machine  Tutorials  A Hacker\u0026rsquo;s Guide to Git : for those wanting to learn git with a solid foundation Best Of - Gustavo Duarte : contains articles on various topics CMSI 281: Data Structures : light weight introduction to DS Collecting all the cheat sheets : cheat sheets for lots of programming languages C Programming Programming Community Curated C++ Resources : resources recommended by developers Deep C : very good presentation on C language Design Patterns: Elements of Reusable Object-Oriented Software : aka the \u0026ldquo;Gang Of Four\u0026rdquo; book, or GOF Dynamic programming - PrismoSkills : very good resource if want to learn how to solve DP problems. Git from the inside out Head First Design Patterns How to Program in C++ : Good resource for revising C++ topics and STL http://www.mysqltutorial.org/ indradhanush tutotials : Writing a Unix Shell Introduction to C Programming Learn UNIX in 10 minutes Learning the shell. Linux Journey : good site for learning linux Linux Tutorial : good resource for learning Linux More about Github-flavored markdown MySQL Essentials Open Data Structures : Excellent resource for learning about DS and algos, provides code in various languages C++, Java and pseudocode. OS Course Notes : Chapter wise course notes according to Galvin\u0026rsquo;s book Programming, Web Development, and DevOps news, tutorials and tools for beginners to experts SQL (Structured Query Language) in one page : SQL.SU : a very good SQL cheat sheet Subtle | Poor Man\u0026rsquo;s CI : Learn how continuous integration platforms work under the hood, by building one of your own on top of git with Node.js TCP/IP Illustrated Series The Bash Guide : very good guide for learning the Bash Shell The Descent to C : for those moving to C from some higher programming language like java or python. The Linux Command Line: A Complete Introduction The Unix Programming Environment TopCoder Tutorials Tutorialspoint : Text and Video Tutorials for UPSC, IAS, PCS, Civil Services, Banking, Aptitude, Questions, Answers, Explanation, Interview, Entrance, Exams, Solutions UNIX and Linux System Administration Handbook, 4th Edition VimTutor+ : Learn VIM from the browser. W3Schools Online Web Tutorials Unix Shell : Unix shell scripting with ksh/bash Snap SVG : The JavaScript SVG library for the modern web vim.rtorr : Vim Cheat Sheet Open Vim : Interactive Vim tutorials Algorithm Using Dynamic Programming and A : Designing a Tree Diff Algorithm Using Dynamic Programming and A* Learn Python : Free Interactive Python Tutorial C++17 : A guide of C++17 The Bash Academy : The Bash Academy is an initiative to promote the bash shell language and educate people on its use. Learn Shell Programming : This website is intended for everyone who wishes to learn programming with Unix/Linux shell interpreters. Java tutorial : A programming community \u0026amp; a great place to find the best online programming courses and tutorials. Explain Shell: Match command-line arguments to their help text Speaking io : Tips for public speaking  Watch others code  Education Ecosystem : screencast of people building application, websites, games, etc. Twitch.tv : The programming community of twitch.  What should a programmer know  GitHub.com Build software better, together : Place to showcase your project and collaborate with others. (Must know Git in order to use it effectively) Gitlab offers free unlimited (private) repositories and unlimited collaborators Programmer Competency Matrix : article for knowing what our level as a programmer is.  Competitive programming  Topic Wise Problem For Competitive Programmer : Topic wise Practise Problem Archived Problems - Project Euler : Problems Archives Art of Problem Solving : Is math class too easy for you? You\u0026rsquo;ve come to the right place! CodeChef : The only programming contests Web 2.0 platform Codefights : Test your coding skills Codeforces : Programming Competition,Programming Contest,Online Computer Programming Codewars : Rank up by completing code kata Codility : Verify and improve coding skills Codingame : Learn coding through games and challenges! Facebook Hacker Cup : Facebook\u0026rsquo;s Programming Contest, past problems solutions and FAQ Google Code Jam Practice and : past contest problems for practice HackerEarth - Programming challenges and Developer jobs HackerRank : Practice coding. Compete. Find jobs. PKU ACM ICPC Practice problems : Judge online for ACMACPC Sphere Online Judge (SPOJ) : Become a true programming master Learn how to code and build efficient algorithms Topcoder : Deliver Faster through Crowdsourcing URI Online Judge : Practice coding, Compete and be a better coder. UVa Online Judge : hundreds of problems supporting multiple languages. WakaTime : leaderboards of coding metrics collected via editor plugins  Computer Books  Become a Programmer, Motherfucker (list of books) : Exhaustive list of books from Zed A. Shaw. Best books for GATE CSE cses.fi/book.html github.com/vhf/free-programming-books : More than 500 free ebooks on almost any language you can think of GitBook : GitBook helps your team write, collaborate and publish content online. Data Science course : Python Data Science Handbook Goal Kicker : Programming Notes for Professionals books The GraphQL Guide : The complete guide to GraphQL, the new REST ✨  Video Tutorials  codedamn : front end web dev tutorials Code School : A PluralSight Company and an Interactive learning destination for aspiring and experienced Developers CodingMadeEasy : C++ tutorials CS1: Higher Computing - Richard Buckland UNSW : a very good introductory CS course Derek Banas : good quality tutorials Design and Analysis of Algorithms DevTips : web dev tutorials FreeCourses : Free courses about programming Kathryn Hodge : Has good videos for beginners mycodeschool : Data structures and algorithms tutorials Pluralsight : Learn Software Development, DevOps and Data Science through multiple short courses thenewboston : good but with too much talk as compared to actual content Tushar Roy : Algorithm and Data structure tutorial by an Indian Youtuber. Vim Tutorial Videos - Flarfnoogins : good video tutorial for learning vim XDA-University - Helping You Learn Android Development Khan Academy : learn about computer science for free Functional programming : John Carmack on Functional Programming (2013) Video about vims : A serie of tutorials about Vim  Online Compiler and Sharing Code snippets  CodePad : Code editor to try, test and run 25+ languages Codesandbox.io : CodeSandbox makes it easier to create, share and reuse React projects with others. Godbolt.org : Excellent tool for exploring the assembly output of different compilers with and without optimization. Ideone.com : online compiler and debugging tool for more than 60 programming languages JSFiddle : Test your JavaScript, CSS, HTML or CoffeeScript with online code editor JSBin : Front end playground, Output is not framed, so it allow you to share those snippet that will break inside iframe. Judge0 IDE : Online compiler with 40+ interpreters and compilers. Pastebin.com : Pastebin can store texts like code, notes, and snippets online for a set period of time which can be shared instantly. C9.io : Your development environment, in the cloud Github Gist : Instantly share code, notes, and snippets. Coder : A Web-based development environment using Visual Studio Code as code editor  Blogs of Developers  Algo-Geeks : Programming Puzzles, Math Tricks, Algorithms etc Amit Merchant : Tutorials, tips \u0026amp; tricks and rants about programming and design. Andy Heathershaw : Personal website and blog of software developer Andy Heathershaw Antonio081014\u0026rsquo;s Algorithms Codes : The world is under the RULE. Archives — Ask a Manager : HR related stuff Armin Ronacher\u0026rsquo;s Thoughts and Writings : blog on Python and open source blog.might.net : the blog of might dot net Brendon Gregg - Linux Kernel Dev : the blog of Brendon D. Gregg Clean Coder Blog : blog of author of book \u0026ldquo;Clean Code\u0026rdquo; CodeAhoy : Blog on software and human factors. 100% Tested on Humans. CoderGears Blog Insights from : the CoderGears Team Coding Geek - A blog about IT, programming and Java : A blog about IT, programming and Java Coding Horror : one the best coding blog CSE Blog : quant, math, computer science puzzles Daedtech.com : Stories about software Dan Dreams of Coding Daniel Lemire\u0026rsquo;s Blog : Daniel Lemire\u0026rsquo;s blog Eli Bendersky : everything from Python to LLVM Geek Land : My precious collectibles HackerEarth Blog : The hackerearth blog IT Enthusiast : IT Enthusiast Joel on Software : The blog of the CEO of StackOverflow Late Developer : Random thoughts of an old C++ guy 1ucasvb\u0026rsquo;s laboriginal math and physics visualization : Lucas Vieira Barbosa\u0026rsquo;s lab original math and physics visualization Math ∩ Programming : Math ∩ Programming My Tech Interviews : PREPARE FOR A TECHNICAL INTERVIEW Paul Graham Essays : Paul Grahan Essays Programming Blog : programming blog of Yegor Bugayenko Programming in the 21st Century : programming in the twenty-first century rudhakar Rayavaram : Sudhakar Rayavaram Blog\u0026rsquo;s Runhe Tian Coding Practice : Technical interview questions from Apple, Google, Facebook, Amazon and Microsoft Small Programming Challenges and Puzzles : Project Nayuki stevehanov.ca : I know how to make and sell software online, and I can share my tips with you. Takipi Blog : mainly focuses on Java and JVM languages XDA - Android Developer Forum : Android Open Source Developers Forum The Net Ninja: Web development tutorials  For improving your English  Englishclub.com/learn-english Guide to Grammar and Writing : for those who want to improve their english language skills Punctuation and Capitalization Rules Purdue University Online Writing Lab (OWL) Quia - English  When you get bored from CS related stuff  Barcroft TV : Daily short documentaries about the incredible variety of people that make up the world Big Think : Expert driven, actionable, educational content, featuring experts ranging from Bill Clinton to Bill Nye ColdFusion : Past, present, and future of technology CrashCourse : small courses on various subjects Every Frame a Painting : High quality analysis of films and filmmaking National Geographic : High volume of high quality content from all over the world r/ProgrammerHumor : Subreddit dedicated to exactly what it sounds like Reddit the front page of the internet : Where free time goes to die Ridddle : A youtube channel about science, mainly, but not only, the universe and space. Regex Crossword : A simple crossword game where clues are regex that must be mached. SciShow : Answers to interesting questions that you\u0026rsquo;ve always wondered about SmarterEveryDay : Lots of amazing scientific information about the world around us, usually captured with a high-speed camera TED : Great talks about technology, entertainment, and design TestTube News : Interesting information about news from around the world How to live for long time ? : The secret of longevity Vsauce : The best youtube channel Ox A cuk : How to live a happy life lonelyspeck : Expose to the Right for Astrophotography in Light Pollution – Palos Verdes, Los Angeles, California  Open Source Websites  Open Hatch : OpenHatch is a non-profit dedicated to matching prospective free software contributors with communities, tools, and education. Source Forge : SourceForge hosts nearly 280,000 projects (at last count). It serves more than 2 million downloads a day and includes apps and tools in a wide variety of categories. Google Code : Google offers free hosting for open source projects using the Subversion or Mercurial version control systems. It offers 2 GB of storage, integrated code review tools, a wiki, and an issue tracker. The Google Code site also provides links to Google\u0026rsquo;s many publicly available APIs and other developer tools. Launch Pad : Maintained by Canonical, LaunchPad is particularly targeted at projects that run on Ubuntu. It provides hosting for more than 21,000 projects that use the Bazaar version control system. Google Open Source : Google Open Source Red Hat Developer : The world\u0026rsquo;s leading provider of open source solutions Open Source : Open Source Google Summer of Code : Google Summer of Code is a global program focused on bringing more student developers into open source software development. Students work with an open source organization on a 3 month programming project during their break from school. Open Source Web Design : Open Source Web Design is a platform for sharing standards-compliant free web design templates. We give web publishers a voice through good design. Mozilla Winter of Security : The Winter of Security (MWOS) is a program organized by Mozilla\u0026rsquo;s Security teams to involve students with Security projects. Students who have to perform a semester project as part of their university curriculum can apply to one of the MWOS project. Eclipse Lab : Eclipse Labs is a community of open source projects that build technology based on the Eclipse platform. It provides the infrastructure services typically required by open source projects, such as code repositories, bug tracking, project web sites/wiki. Eclipse Labs is hosted by Google Code Project Hosting, so it will be very familiar to developers already using Google Code Project Hosting. Bit Bucket : Like GitHub, BitBucket hosts both public and private projects. On this site, open source projects and private projects with fewer than five users are free. It hosts more than 48,000 repositories, many of which are searchable on the site. Media Wiki : MediaWiki is a free software open source wiki package written in PHP, originally for use on Wikipedia. It is now also used by several other projects of the non-profit Wikimedia Foundation and by many other wikis, including this website, the home of MediaWiki. Code Curiosity : CodeCuriosity is a platform that encourages contributions to open source. Everyone is rewarded for their efforts, no matter how big or small they are. Code Triage : Help out your favorite open source projects and become a better developer while doing it. Issue Hub : Contribute to Open Source. Search issue labels to find the right project for you Up for Grabs : This is a list of projects which have curated tasks specifically for new contributors. These are a great way to get started with a project, or to help share the load of working on open source projects. First Timers Only : Contributing to open source for the first time can be scary and a little overwhelming. Perhaps you’re a Code Newbie or maybe you’ve been coding for a while but haven’t found a project you felt comfortable contributing to. Your First PR : Your First PR helps you get started contributing to Open Source by showcasing great starter issues on GitHub and elsewhere.  Jobs  AngelList : AngelList is a website for startups, angel investors, and job-seekers looking to work at startups. CareerBuilder : CareerBuilder is one of the largest job boards, providing job listings, resume posting, and career advice and resources to job seekers. Dice : Dice is the leading site for tech job seekers. You can search by company, job title, keyword, employment type, and location. Devsnap : Devsnap is a job aggregator for developer jobs. Glassdoor : Find the job that\u0026rsquo;s right for you. Search all the open positions on the web. Get your own personalized salary estimate. Indeed : Find international jobs on Indeed and get a market salary for your dedication and devotion. Instahyre : Your dream job is now here. Showcase yourself to a curated list of top companies. Complete privacy and no spam. Mentat : Get your dream job 10x faster. Never apply for a job ever again, talk directly to decision makers and hiring managers. The Muse : Find everything you need to succeed from dream jobs to career advice. You can do a lot here on The Muse like exploring companies, browsing jobs, career advice, discover careers, career coaching. Try it. Paysa : Paysa helps you in finding new and interesting jobs according to your wish. SimplyHired : Simply Hired is a free job search engine (and mobile app) that takes the hassle out of getting hired and provides you with all the information you need to make a sound career move. SwissDev Jobs : Tech job board for Software Engineers that want to work in Switzerland. Undercover Recruiter : Become Recruiter, Candidate or Employer. You can get your job easily here. Who is Hiring : An awesome resource for searching, filtering and finding new and attractive jobs according to your needs and interests. ZipRecruiter : The Smartest Way to Get Hired. RemoteML : Remote Machine Learning jobs. Linkedin jobs : Very nice research tool for programming jobs  Special Thanks  A special thanks to Ashish Padalkar (@ashish2199) for contributing a great amount of data and structure to the initial repository Original Post.  ","excerpt":"License To the extent possible under law, sdmg15 has waived all copyright and related or neighboring …","ref":"/docs/swiss-knives/developer-website/","title":"Developer's Websites"},{"body":"\n Jekyll in Ruby. This option is clearly the most popular, and it is the only one integrated into GitHub (builds are simpler). Even though I have no experience with Ruby, I wanted to choose this option initially. But then I discovered that Jekyll is not supported on Windows. Moreover, you cannot even use Ruby packages without downloading and installing 1GB Linux subsystem. It became apparent that this ecosystem does not care for Windows users (which I am one of). Hexo in javascript. This option is less popular, but will probably rise in the nearest future. Using javascript for generating websites is a great idea, because any client-side code has to be in javascript anyway, so it is more convenient to use one language in both areas. I have suffered enough from javascript on my daily job, so I decided to avoid this too. Pelican in Python. This option is probably even less popular than Hexo. Python is a great language for a variety of tasks, and my experience with it is strongly positive. It is very user-friendly, truly cross-platform, does not have tons of stupid legacy stuff like javascript.  ","excerpt":"Jekyll in Ruby. This option is clearly the most popular, and it is the only one integrated into …","ref":"/docs/web/static-website/","title":"Static Websites"},{"body":"\nInstallation pip install --upgrade autopep8\npyproject.toml # configuration file example: [tool.autopep8] max_line_length = 79 ignore = \u0026#34;E501,W6\u0026#34; # or [\u0026#34;E501\u0026#34;, \u0026#34;W6\u0026#34;] in-place = true recursive = true aggressive = 3 ","excerpt":"\nInstallation pip install --upgrade autopep8\npyproject.toml # configuration file example: …","ref":"/docs/coding/functional-coding/python/format/autopep8/","title":"auto8pep"},{"body":"\nProblems of REINFORCE There are three issues:\n  The update process is very inefficient! We run the policy once, update once, and then throw away the trajectory.\n  The gradient estimate $\\hat{g}$ is very noisy. By chance the collected trajectory may not be representative of the policy.\n  There is no clear credit assignment! A trajectory may contain many good/bad actions and whether these actions are reinforced depends only on the final total output.\n  Solutions Noise Reduction  Problem  Too many trajectories  There could easily be well over millions of trajectories for simple problems and infinite for continuous problems. So a lot of times, the result of a sampled trajectory comes down to chance, and doesn\u0026rsquo;t contain that much information about our policy. The hope is that after training for a long time, the tiny signal accumulates.     Solution  Simply sample more trajectories 😬  using distributed computing estimate the policy gradient by averaging across all the different trajectories we can collect all the total rewards and get a sense of how they are distributed      Source\nRewards Normalization   In many cases, the distribution of rewards shifts as learning happens. Reward = 1 might be really good in the beginning, but really bad after 1000 training episode.\n  Learning can be improved if we normalize the rewards, where $\\mu$ is the mean, and $\\sigma$ the standard deviation.\n  $R_i \\leftarrow \\frac{R_i -\\mu}{\\sigma} \\qquad$\n $ \\mu = \\frac{1}{N}\\sum_i^N R_i \\qquad$ $\\sigma = \\sqrt{\\frac{1}{N}\\sum_i (R_i - \\mu)^2}R$    when all the $R_i$ are the same, $\\sigma =0$, we can set all the normalized rewards to 0 to avoid numerical problems\n  This batch-normalization technique is also used in many other problems in AI (e.g. image classification), where normalizing the input can improve learning.\n  Intuitively, normalizing the rewards roughly corresponds to picking half the actions to encourage/discourage, while also making sure the steps for gradient ascents are not too large/small. 🎲\n    Credit Assignment At time-step $t$\n  Even before an action is decided, the agent has already received all the rewards up until step $t-1$. So we can think of that part of the total reward as the reward from the past. The rest is denoted as the future reward.\n $(\\overbrace{\u0026hellip;+r_{t-1}}^{\\require{cancel}\\bcancel{R^{\\rm past}_t}} + \\overbrace{r_{t}+\u0026hellip;}^{R^{\\rm future}_t})$    Because we have a Markov process, the action at time-step $t$ can only affect the future reward, so the past reward shouldn’t be contributing to the policy gradient.\n So to properly assign credit to the action $a_t$, we should ignore the past reward. So a better policy gradient would simply have the future reward as the coefficient $g=\\sum_t \\color{blue}{R_t^{\\rm future}} \\color{black}{\\nabla_{\\theta}\\log \\pi_\\theta(a_t|s_t)}$    Mathematically, ignoring past rewards might change the gradient for each specific trajectory, but it doesn\u0026rsquo;t change the averaged gradient.\n So even though the gradient is different during training, on average we are still maximizing the average reward. In fact, the resultant gradient is less noisy, so training using future reward should speed things up! 🚀    Importance Sampling   The trajectories we generated using the policy $\\pi_\\theta$. It had a probability $P(\\tau;\\theta)$, to be sampled.\n  Now Just by chance, the same trajectory can be sampled under the new policy, with a different probability $\\color{blue} {P(\\tau;\\theta')}$.\n  Imagine we want to compute the average of some quantity, say $f(\\tau)$. We could simply generate trajectories from the new policy, compute $f(\\tau)$ and average them.\n  Mathematically, this is equivalent to adding up all the $f(\\tau)$, weighted by a probability of sampling each trajectory under the new policy.\n $\\sum_\\tau \\color{blue} {P(\\tau;\\theta')} f(\\tau)$    we could modify this equation, by multiplying and dividing by the same number, $P(\\tau;\\theta)$ and rearrange the terms\n $\\sum_\\tau \\overbrace{P(\\tau;\\theta)}^{ \\begin{matrix} \\scriptsize \\textrm{sampling under}\\ \\scriptsize \\textrm{old policy } \\pi_\\theta \\end{matrix} } \\overbrace{\\frac{ \\color{blue} {P(\\tau;\\theta')}}{P(\\tau;\\theta)}}^{ \\begin{matrix} \\scriptsize \\textrm{re-weighting}\\ \\scriptsize \\textrm{factor} \\end{matrix} } f(\\tau)$ we can reinterpret the first part as the coefficient for sampling under the old policy, with an extra re-weighting factor, in addition to just averaging.    we can use old trajectories for computing averages for new policy, as long as we add this extra re-weighting factor, that takes into account how under or over–represented each trajectory is under the new policy compared to the old one.\n The same tricks are used frequently across statistics, where the re-weighting factor is included to unbias surveys and voting predictions.    The re-weighting factor $\\frac{\\color{blue} {P(\\tau;\\theta')}}{P(\\tau;\\theta)} =\\frac {\\pi_{\\theta'}(a_1|s_1), \\pi_{\\theta'}(a_2|s_2), \\pi_{\\theta'}(a_3|s_3),\u0026hellip;} {\\pi_\\theta(a_1|s_1) , \\pi_\\theta(a_2|s_2), \\pi_\\theta(a_2|s_2), \u0026hellip;}$\n  Because each trajectory contains many steps, the probability contains a chain of products of each policy at different time-step.\n  A Problem: when some of policy gets close to zero, the re-weighting factor can become close to zero, or worse, close to 1 over 0 which diverges to infinity.\n When this happens, the re-weighting trick becomes unreliable.    A Solution: In practice, we want to make sure the re-weighting factor is not too far from 1 when we utilize importance sampling\n  Proximal Policy Optimization (PRO)  closely related to Trust Region Policy Optimization (TRPO) developed by OpenAI  Algorithm  First, collect some trajectories based on some policy $\\pi_\\theta$ , and initialize theta prime $\\theta'=\\theta$ Next, compute the gradient of the clipped surrogate function using the trajectories Update $\\theta$ using gradient ascent  $\\theta'\\leftarrow\\theta' +\\alpha \\nabla_{\\theta'}L_{\\rm sur}^{\\rm clip}(\\theta', \\theta)$   Then we repeat step 2-3 without generating new trajectories. Typically, step 2-3 are only repeated a few times Set $\\theta=\\theta'$ go back to step 1, repeat.  Test Policy Gradient Quiz Suppose we are training an agent to play a computer game.\n There are only two possible action: 0 = Do nothing, 1 = Move  There are three time-steps in each game, and our policy is completely determined by one parameter $\\theta$, such that the probability of \u0026ldquo;moving\u0026rdquo; is $\\theta$, and the probability of doing nothing is $1-\\theta$ Initially $\\theta=0.5$. Three games are played, the results are:   Game 1: actions: (1,0,1) rewards: (1,0,1)\n  Game 2: actions: (1,0,0) rewards: (0,0,1)\n  Game 3: actions: (0,1,0) rewards: (1,0,1)\n     Question 1: What are the future rewards for the first game?  (1+0+1, 1+0, 1) = (2, 1, 1)\n  Question 2: What is the policy gradient computed from the second game, using future rewards?  -2\n    Ref  Proximal Policy Optimization Algorithms \u0026ndash; by OpenAI  ","excerpt":"Problems of REINFORCE There are three issues:\n  The update process is very inefficient! We run the …","ref":"/docs/machinelearning/courses/reinforcement-learning/c3-policy/p03-proximal/","title":"Proximal Policy Optimization"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/","title":"Courses"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/","title":"Foundation"},{"body":"\nCreate new env conda create --name rl python=3.6 source activate rl # install packages pip install -r requirements.txt Add new env to Jupyter # Create an IPython kernel for the `rl` environment. python -m ipykernel install --user --name rl --display-name \u0026#34;rl\u0026#34; ","excerpt":"\nCreate new env conda create --name rl python=3.6 source activate rl # install packages pip install …","ref":"/docs/coding/practices/env/conda/","title":"conda"},{"body":"\nPolicies   A deterministic policy: a mapping $\\pi: S \\to A$\n For each state $s \\in S$, it yields the action $a \\in A$ that the agent will choose while in state $s$. input: state output: action Example  $\\pi(low) = recharge$ $\\pi(high) = search$      A stochastic policy: a mapping $\\pi: S \\times A \\to [0,1]$\n  For each state $s \\in S$ and action $a \\in A$, it yields the probability $\\pi(a|s)$ that the agent chooses action $a$ while in state $s$.\n  input: state and action\n  output: probability that the agent takes action $A$ while in state $S$\n  $\\pi(a|s) =\\Bbb{P}(A_t =a | S_t = s) $\n  Example\n low  $\\pi(recharge | low) = 0.5$ $\\pi(wait | low) = 0.4$ $\\pi(search | low) = 0.1$   high  $\\pi(search | high) = 0.6$ $\\pi(wait | high) = 0.4$        Gridworld Example In this gridworld example, once the agent selects an action,\n it always moves in the chosen direction (contrasting general MDPs where the agent doesn\u0026rsquo;t always have complete control over what the next state will be), the reward can be predicted with complete certainty (contrasting general MDPs where the reward is a random draw from a probability distribution). the value of any state can be calculated as the sum of the immediate reward and the (discounted) value of the next state.  Grid Word images from Udacity nd893\nState-Value Functions The state-value function for a policy is denoted $v_\\pi$. For each state $s \\in {S}$, it yields the expected return if the agent starts in state $s$ and then uses the policy to choose its actions for all time steps.\n The value of state $s$ under policy $\\pi$: $v_{\\pi}(s) = \\Bbb{E}_{\\pi}[G_t|S_t = s]$  Bellman Equations   Bellman equations attest to the fact that value functions satisfy recursive relationships.\n  Read More at Chapter 3.5 and 3.6\n  It expresses the value of any state $s$ in terms of the expected immediate reward and the expected value of the next state\n $V_{\\pi}(s) = \\Bbb{E}_{\\pi}[ R_{t+1} + {\\gamma}v_{\\pi}(S_{t+1}) | S_t) = s] $    In the event that the agent\u0026rsquo;s policy $\\pi$ is deterministic, the agent selects action $\\pi(s)$ when in state $s$, and the Bellman Expectation Equation can be rewritten as the sum over two variables ($s'$ and $r$):\n $v_{\\pi}(s) = \\sum_{s'\\in{S^{+}}, r \\in{R}} p(s', r|s, \\pi{s})(r+ \\gamma v_{\\pi}(s')) $ In this case, we multiply the sum of the reward and discounted value of the next state $(r+ \\gamma v_{\\pi}(s')) $ by its corresponding probability $p(s', r|s, \\pi{s})$ and sum over all possibilities to yield the expected value.    If the agent\u0026rsquo;s policy $\\pi$ is stochastic, the agent selects action $a$ with probability when in state $s$, and the Bellman Expectation Equation can be rewritten as the sum over three variables\n $v_{\\pi}(s) = \\sum_{s'\\in{S^{+}}, r \\in{R}, a \\in{A_{(s)}}} \\pi(a|s) p(s', r|s, a) (\\gamma + \\gamma v_{\\pi}(s')) $\n-In this case, we multiply the sum of the reward and discounted value of the next state $(\\gamma + \\gamma v_{\\pi}(s'))$ by its corresponding probability $\\pi(a|s) p(s', r|s, a)$ and sum over all possibilities to yield the expected value.    Action-value Functions  The action-value function for a policy: $q_{\\pi}$. The value $q_{\\pi}(s,a)$ is the value of taking action $a$ in state $s$ under a policy $\\pi$ For each state $s \\in S$ and action $a \\in A$, it yields the expected return if the agent starts in state $s$, takes action $a$, and then follows the policy for all future time steps. $q_{\\pi}(s,a) = \\Bbb{E}_{\\pi}[G_t |S_t =s, A_t = a ]$  Optimality  A policy $\\pi$ is defined to be better than or equal to a policy $\\pi$ if and only if $v_{\\pi \\prime} (s) \\ge v_{\\pi} (s)$ for all. An optimal policy $\\pi_\\ast$ satisfies $\\pi_\\ast \\ge \\pi$ is guaranteed to exist but may not be unique. How do you define better policy?  Positive reward, which gives agent more motivation    Optimal State-value Function All optimal policies have the same state-value function $v_\\ast$\nOptimal Action-value Function All optimal policies have the same action-value function $q_\\ast$\nOptimal Policies  Interaction ${\\to}$ $q_\\ast$ $\\to$ $\\pi_\\ast$ Once the agent determines the optimal action-value function $q_\\ast$, it can quickly obtain an optimal polity $\\pi_ast$ by setting $\\pi(s) = argmax_{a \\in A_{(s)}} q_\\ast (s,a)$: Select the maximal actiona value $q$ at each step  Quiz Calculate State-value Function $v_{\\pi}$   Assuming $\\gamma = 1$, calculate $v_{\\pi}(s_4)$ and $v_{\\pi}(s_1)$\n  Solve the problem using Bellman Equations Image from Udacity nd893\n  Answer: $v_{\\pi}(s_4) = 1 $ and $v_{\\pi}(s_1) = 2$\n  About Deterministic Policy True or False?:\nFor a deterministic policy $\\pi$:\n$v_{\\pi}(s) = q_{\\pi}(s,\\pi(s)) $ holds for all $s \\in S$.\nAnswer: True.\n It also follows from how we have defined the action-value function. The value of the state-action pair $s$, $\\pi(s)$ is the expected return if the agent starts in state $s$, takes action $\\pi(s)$, and henceforth follows the policy $\\pi$. In other words, it is the expected return if the agent starts in state $s$, and then follows the policy $\\pi$, which is exactly equal to the value of state $s$.  Optimal Policies Consider a MDP (in the below table), with a corresponding optimal action-value function. Which of the following describes a potential optimal policy that corresponds to the optimal action-value function?\n    a1 a2 a3     s1 1 3 4   s2 2 2 1   s3 3 1 1    Answer\n   State $s1$: the agent will always selects action $a3$    State $s2$: the agent is free to select either $a1$ or $a2$    State $s3$: the agent must select $a1$    ","excerpt":"Policies   A deterministic policy: a mapping $\\pi: S \\to A$\n For each state $s \\in S$, it yields the …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f03-rl-solutions/","title":"RL Solutions"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/clustering/","title":"Clustering"},{"body":"\nDeep Learning  CS 839: Special Topics in Deep Learning  University of Wisconsin-Madison    ","excerpt":"\nDeep Learning  CS 839: Special Topics in Deep Learning  University of Wisconsin-Madison    ","ref":"/docs/machinelearning/courses/deeplearning/","title":"Deep Learning"},{"body":"\n60 Common commands  alias basename bg cat cd chmod chown clear cp crontab df diff dirname du echo emacs editor env export fg find grep gunzip gzip history jobs kill killall less ln ls man mkdir mv nano editor nohup open passwd ping printenv ps pwd rmdir sort su sudo tail tar top touch traceroute type umask uname uniq vim editor wc which who whoami xargs  Ref  The Linux Handbook  ","excerpt":"\n60 Common commands  alias basename bg cat cd chmod chown clear cp crontab df diff dirname du echo …","ref":"/docs/coding/functional-coding/bash/commands/","title":"Commands"},{"body":"\n1. Autoimpute Autoimpute is designed to be user friendly and flexible.\n tutorials github  Usage  Installation  pip install autoimpute  Three imputers  from autoimpute.imputations import SingleImputer, MultipleImputer, MiceImputer si = SingleImputer() # pass through data once mi = MultipleImputer() # pass through data multiple times # mice mice = MiceImputer() # pass through data multiple times and iteratively optimize imputations in each column  Impute the easy way  # mice mice = MiceImputer() mice.fit_transform(data)  Impute the complex way  # create a complex instance of the MiceImputer # Here, we specify strategies by column and predictors for each column # We also specify what additional arguments any `pmm` strategies should take imp = MiceImputer( n=10, strategy={\u0026#34;salary\u0026#34;: \u0026#34;pmm\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;bayesian binary logistic\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;norm\u0026#34;}, predictors={\u0026#34;salary\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;gender\u0026#34;: [\u0026#34;salary\u0026#34;, \u0026#34;education\u0026#34;, \u0026#34;weight\u0026#34;]}, imp_kwgs={\u0026#34;pmm\u0026#34;: {\u0026#34;fill_value\u0026#34;: \u0026#34;random\u0026#34;}}, visit=\u0026#34;left-to-right\u0026#34;, return_list=True ) # Because we set return_list=True, imputations are done all at once, not evaluated lazily. # This will return M*N, where M is the number of imputations and N is the size of original dataframe. imp.fit_transform(data)  Impute using supervised machine learning methods  apply scikit-learn and stats models to multiply imputed datasets (using the MiceImputer under the hood). Now supporting linear regression and binary logistic regression.    from autoimpute.analysis import MiLinearRegression # By default, use statsmodels OLS and MiceImputer() simple_lm = MiLinearRegression() # fit the model on each multiply imputed dataset and pool parameters simple_lm.fit(X_train, y_train) # get summary of fit, which includes pooled parameters under Rubin\u0026#39;s rules # also provides diagnostics related to analysis after multiple imputation simple_lm.summary() # make predictions on a new dataset using pooled parameters predictions = simple_lm.predict(X_test) # Control both the regression used and the MiceImputer itself mice_imputer_arguments = dict( n=3, strategy={\u0026#34;salary\u0026#34;: \u0026#34;pmm\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;bayesian binary logistic\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;norm\u0026#34;}, predictors={\u0026#34;salary\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;gender\u0026#34;: [\u0026#34;salary\u0026#34;, \u0026#34;education\u0026#34;, \u0026#34;weight\u0026#34;]}, imp_kwgs={\u0026#34;pmm\u0026#34;: {\u0026#34;fill_value\u0026#34;: \u0026#34;random\u0026#34;}}, visit=\u0026#34;left-to-right\u0026#34; ) complex_lm = MiLinearRegression( model_lib=\u0026#34;sklearn\u0026#34;, # use sklearn linear regression mi_kwgs=mice_imputer_arguments # control the multiple imputer ) # fit the model on each multiply imputed dataset complex_lm.fit(X_train, y_train) # get summary of fit, which includes pooled parameters under Rubin\u0026#39;s rules # also provides diagnostics related to analysis after multiple imputation complex_lm.summary() # make predictions on new dataset using pooled parameters predictions = complex_lm.predict(X_test) \nImputation Methods    Univariate Multivariate Time Series / Interpolation     Mean Linear Regression Linear   Median Binomial Logistic Regression Quadratic   Mode Multinomial Logistic Regression Cubic   Random Stochastic Regression Polynomial   Norm Bayesian Linear Regression Spline   Categorical Bayesian Binary Logistic Regression Time-weighted    Predictive Mean Matching NextObs Carried Backward    Local Residual Draws Last Obs Carried Forward    Main features  Utility functions to examine patterns in missing data Missingness classifier and automatic missing data test set generator Numerous imputation methods for continuous, categorical, and time-series data Single and multiple imputation frameworks to apply imputation methods Custom visualization support for utility functions and imputation methods Analysis methods and pooled parameter inference using multiply imputed datasets Adherence to scikit-learn API design for imputation and analysis classes Integration with pandas, scikit-learn, statsmodels, pymc3, and more  2. fancyimpute  github Installation by pip.  conda is not supported.    pip install fancyimpute \nUsage from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler # X is the complete data matrix # X_incomplete has the same values as X except a subset have been replace with NaN # Use 3 nearest rows which have a feature to fill in each row\u0026#39;s missing features X_filled_knn = KNN(k=3).fit_transform(X_incomplete) # matrix completion using convex optimization to find low-rank solution # that still matches observed values. Slow! X_filled_nnm = NuclearNormMinimization().fit_transform(X_incomplete) # Instead of solving the nuclear norm objective directly, instead # induce sparsity using singular value thresholding X_incomplete_normalized = BiScaler().fit_transform(X_incomplete) X_filled_softimpute = SoftImpute().fit_transform(X_incomplete_normalized) # print mean squared error for the imputation methods above nnm_mse = ((X_filled_nnm[missing_mask] - X[missing_mask]) ** 2).mean() print(\u0026#34;Nuclear norm minimization MSE: %f\u0026#34; % nnm_mse) softImpute_mse = ((X_filled_softimpute[missing_mask] - X[missing_mask]) ** 2).mean() print(\u0026#34;SoftImpute MSE: %f\u0026#34; % softImpute_mse) knn_mse = ((X_filled_knn[missing_mask] - X[missing_mask]) ** 2).mean() print(\u0026#34;knnImpute MSE: %f\u0026#34; % knn_mse) \nAlgorithms   SimpleFill: Replaces missing entries with the mean or median of each column.\n  KNN: Nearest neighbor imputations which weights samples using the mean squared difference on features for which two rows both have observed data.\n  SoftImpute: Matrix completion by iterative soft thresholding of SVD decompositions. Inspired by the softImpute package for R, which is based on Spectral Regularization Algorithms for Learning Large Incomplete Matrices by Mazumder et. al.\n  IterativeImputer: A strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion. A stub that links to scikit-learn\u0026rsquo;s IterativeImputer.\n  IterativeSVD: Matrix completion by iterative low-rank SVD decomposition. Should be similar to SVDimpute from Missing value estimation methods for DNA microarrays by Troyanskaya et. al.\n  MatrixFactorization: Direct factorization of the incomplete matrix into low-rank U and V, with an L1 sparsity penalty on the elements of U and an L2 penalty on the elements of V. Solved by gradient descent.\n  NuclearNormMinimization: Simple implementation of Exact Matrix Completion via Convex Optimization by Emmanuel Candes and Benjamin Recht using cvxpy. Too slow for large matrices.\n  BiScaler: Iterative estimation of row/column means and standard deviations to get doubly normalized matrix. Not guaranteed to converge but works well in practice. Taken from Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares.\n  ","excerpt":"1. Autoimpute Autoimpute is designed to be user friendly and flexible.\n tutorials github  Usage …","ref":"/docs/coding/functional-coding/python/imputation/","title":"Imputation"},{"body":"\nJraph  GitHub   Jraph (pronounced giraffe) is a lightweight library for working with graph neural networks in jax. It provides a data structure for graphs, a set of utilites for working with graphs, and a \u0026lsquo;zoo\u0026rsquo; of forkable graph neural network models.\n Usage  Installation  pip install git+git://github.com/deepmind/jraph.git Overview Jraph is designed to provide utilities for working with graphs in jax, but doesn\u0026rsquo;t prescribe a way to write or develop graph neural networks.\n graph.py provides a lightweight data structure, GraphsTuple, for working with graphs. utils.py provides utilies for working with GraphsTuples in jax.  Utilities for batching datasets of GraphsTuples. Utilities to support jit compilation of variable shaped graphs via padding and masking. Utilities for defining losses on partitions of inputs.   models.py provides examples of different types of graph neural network message passing. These are designed to be lightweight, easy to fork and adapt. They do not manage parameters for you - for that, consider using haiku or flax. See the examples for more details.  Image source\n","excerpt":"Jraph  GitHub   Jraph (pronounced giraffe) is a lightweight library for working with graph neural …","ref":"/docs/machinelearning/frameworks/flax/jraph/","title":"Jraph"},{"body":"\nCDK Debugging in VSCode  Blog post GitHub code  ","excerpt":"\nCDK Debugging in VSCode  Blog post GitHub code  ","ref":"/docs/cloud/aws/cdk/","title":"CDK"},{"body":"\nWhat is pigeonhole principle? If $n$ items are put into $m$ containers, with $n \u0026gt; m$ then at least one container must contain more than one item.\npigeonhole principle\nWhat is the probability of two people among $k$ people having the same birthday?  If $k \u0026gt; 366$, $P = 1$ If $k\u0026lt;366$, what is the minimal $k$ to get $P \\approx 0.5$?  $P_{no match} = \\frac{365 \\cdot 364 \\dots (365-k+1)}{365^k}$ $P_{match} = 1- P_{no match}$  $0.51$, $k =23$ $0.97$, $k =50$ $0.99999$, $k =100$     Let\u0026rsquo;s build some intuition of $P_{match} = \\binom{k}{2}$  $\\binom{23}{2} = \\frac{23 \\cdot 22}{2} =253$      Probability Properties  $P_{(A^c)} = 1-P_{(A)}$ $P_{(A)} \\le P_{(B)}$ if $A$ is contained in $B$ ($A \\in B$)  $B= A {\\bigcup} (B \\bigcap A^c)$, disjoint $P_{(B)} = P_{(A)} + P_{(B \\bigcap A^c)} \\ge P_{(A)}$   $P_{A \\bigcup B} =P_{(A)} + P_{(B)} - P_{(A \\bigcap B)}$ $P_{A \\bigcup B \\bigcup} =P_{(A)} + P_{(B)} + P_{(C)} - P_{(A \\bigcap B)}- P_{(A \\bigcap C)}- P_{(B \\bigcap C)} + P_{(A \\bigcap B \\bigcap C)}$ General Case\n  Inclusion–exclusion illustrated by a Venn diagram for three sets\nDe Montmort\u0026rsquo;s Problem  1713 matching problem for gambling  $n$ cards, labeled $1, 2, 3, \u0026hellip;, n$, let $A_j$ be the event with matches   $P_{(A_1 \\bigcup A_2 \\bigcup \\dots \\bigcup A_n)} \\approx 1- \\frac{1}{e}$  ","excerpt":"What is pigeonhole principle? If $n$ items are put into $m$ containers, with $n \u0026gt; m$ then at …","ref":"/docs/math/intro/probability/s110_l03_birthday/","title":"Birthday"},{"body":"\nCourses  Intro to Data Structures and Algorithms, Udacity Advanced Data Structures  Read  A Data Scientist’s Guide to Data Structures \u0026amp; Algorithms, Part 1  ","excerpt":"\nCourses  Intro to Data Structures and Algorithms, Udacity Advanced Data Structures  Read  A Data …","ref":"/docs/data/structure/","title":"Data Structure"},{"body":"","excerpt":"","ref":"/docs/coding/practices/","title":"Practices"},{"body":"\n Course Link\n 1. Specify Upper and Lower Number of Matches  You can specify the lower and upper number of patterns with quantity specifiers. Quantity specifiers are used with curly brackets { }. You put two numbers between the curly brackets - for the lower and upper number of patterns. Example 1  // Match only the letter a appearing between 3 and 5 times in the string \u0026#34;eh\u0026#34;, your regex would be `/a{3,5}h/` let A4 = \u0026#34;eeeh\u0026#34;; let A2 = \u0026#34;eeh\u0026#34;; let multipleA = /e{3,5}h/; multipleA.test(A4); // Returns true multipleA.test(A2); // Returns false  Example 2  // Change the regex ohRegex to match the entire phrase \u0026#34;Oh no\u0026#34; only when it has 3 to 6 letter h\u0026#39;s let ohStr = \u0026#34;Ohhh no\u0026#34;; let ohRegex = /Oh{3,6} no/; let result = ohRegex.test(ohStr); \n2. Specify Only the Lower Number of Matches  You can specify the lower and upper number of patterns with quantity specifiers using curly brackets. Sometimes you only want to specify the lower number of patterns with no upper limit To only specify the lower number of patterns, keep the first number followed by a comma Example 1  // For example, to match only the string \u0026#34;hah\u0026#34; with the letter a appearing at least 3 times, your regex would be /ha{3,}h/. let A4 = \u0026#34;haaaah\u0026#34;; let A2 = \u0026#34;haah\u0026#34;; let A100 = \u0026#34;h\u0026#34; + \u0026#34;a\u0026#34;.repeat(100) + \u0026#34;h\u0026#34;; let multipleA = /ha{3,}h/; multipleA.test(A4); // Returns true multipleA.test(A2); // Returns false multipleA.test(A100); // Returns true  Example 2  // Change the regex haRegex to match the word \u0026#34;Hazzah\u0026#34; only when it has four or more letter z\u0026#39;s. let haStr = \u0026#34;Hazzzzah\u0026#34;; let haRegex = /Haz{4,}ah/; // Change this line let result = haRegex.test(haStr); \n3. Specify Exact Number of Matches  You can specify the lower and upper number of patterns with quantity specifiers using curly brackets. Sometimes you only want a specific number of matches. To specify a certain number of patterns, just have that one number between the curly brackets. Example 1  // Match only the word \u0026#34;hah\u0026#34; with the letter a 3 times, your regex would be /ha{3}h/. let A4 = \u0026#34;haaaah\u0026#34;; let A3 = \u0026#34;haaah\u0026#34;; let A100 = \u0026#34;h\u0026#34; + \u0026#34;a\u0026#34;.repeat(100) + \u0026#34;h\u0026#34;; let multipleHA = /ha{3}h/; multipleHA.test(A4); // Returns false multipleHA.test(A3); // Returns true multipleHA.test(A100); // Returns false  Example 2  // Change the regex timRegex to match the word \u0026#34;Timber\u0026#34; only when it has four letter m\u0026#39;s. let timStr = \u0026#34;Timmmmber\u0026#34;; let timRegex = /Tim{4}ber/; let result = timRegex.test(timStr); 4. Check for All or None  Sometimes the patterns you want to search for may have parts of it that may or may not exist. However, it may be important to check for them nonetheless You can specify the possible existence of an element with a question mark, ?. This checks for zero or one of the preceding element. You can think of this symbol as saying the previous element is optional Example 1:  // Use the question mark to match American and British English spellings let american = \u0026#34;color\u0026#34;; let british = \u0026#34;colour\u0026#34;; let rainbowRegex= /colou?r/; rainbowRegex.test(american); rainbowRegex.test(british);  Example 2  // Change the regex favRegex to match both the American English (favorite) and the British English (favourite) version of the word. let favWord = \u0026#34;favorite\u0026#34;; let favRegex = /favou?rite/; // Change this line let result = favRegex.test(favWord); \n5. Positive and Negative Lookahead 🔭   Lookaheads are patterns that tell JavaScript to look-ahead in your string to check for patterns further along\n  This can be useful when you want to search for multiple patterns over the same string\n  There are two kinds of lookaheads:\n positive lookahead  A positive lookahead will look to make sure the element in the search pattern is there, but won\u0026rsquo;t actually match it A positive lookahead is used as ?=... where the ... is the required part that is not matched   negative lookahead  A negative lookahead will look to make sure the element in the search pattern is not there A negative lookahead is used as ?!... where the ... is the pattern that you do not want to be there. The rest of the pattern is returned if the negative lookahead part is not present      Example 1\n  let quit = \u0026#34;qu\u0026#34;; let noquit = \u0026#34;qt\u0026#34;; let quRegex= /q(?=u)/; let qRegex = /q(?!u)/; quit.match(quRegex); // Returns [\u0026#34;q\u0026#34;] noquit.match(qRegex); // Returns [\u0026#34;q\u0026#34;] // quit.match(qRegex) // Returns null noquit.match(quRegex) // Returns null  Example 2  // Use lookaheads in the pwRegex to match passwords that are greater than 5 characters long, do not begin with numbers, and have two consecutive digits let sampleWord = \u0026#34;astronaut\u0026#34;; let pwRegex = /^\\D(?=\\w{5})(?=\\w*\\d{2})/ // Change this line let result = pwRegex.test(sampleWord); \n6. Check For Mixed Grouping of Characters 🔖   Check for groups of characters using a Regular Expression and to achieve that we use parentheses ()\n  Example 1 🐧 🐧\n  //Find either Penguin or Pumpkin in a string /P(engu|umpk)in/g  Example 2  // Fix the regex so that it checks for the names of Franklin Roosevelt or Eleanor Roosevelt in a case sensitive manner and it should make concessions for middle names. let myString = \u0026#34;Eleanor Roosevelt\u0026#34;; let myRegex = /(Eleanor|Franklin).* Roosevelt/; // Change this line let result = myRegex.test(myString); \n7. Reuse Patterns Using Capture Groups  Some patterns you search for will occur multiple times in a string. It is wasteful to manually repeat that regex. There is a better way to specify when you have multiple repeat substrings in your string. You can search for repeat substrings using capture groups – ( repeat pattern ) To specify where that repeat string will appear, you use a backslash \\and then a number. This number starts at 1 and increases with each additional capture group you use. An example would be \\1 to match the first group. Using the .match() method on a string will return an array with the string it matches, along with its capture group  let repeatStr = \u0026#34;regex regex\u0026#34;; let repeatRegex = /(\\w+)\\s\\1/; repeatRegex.test(repeatStr); // Returns true repeatStr.match(repeatRegex); // Returns [\u0026#34;regex regex\u0026#34;, \u0026#34;regex\u0026#34;] let repeatNum = \u0026#34;42 42 42\u0026#34;; let reRegex = /^(\\d+)\\s\\1\\s\\1$/; // Change this line let result = reRegex.test(repeatNum); \n8. Use Capture Groups to Search and Replace  You can search and replace text in a string using .replace() on a string. The inputs for .replace() is first the regex pattern you want to search for. The second parameter is the string to replace the match or a function to do something Example 1  let wrongText = \u0026#34;The sky is silver.\u0026#34;; let silverRegex = /silver/; wrongText.replace(silverRegex, \u0026#34;blue\u0026#34;); // Returns \u0026#34;The sky is blue.\u0026#34;  Example 2: access capture groups in the replacement string with dollar signs $  \u0026#34;Code Camp\u0026#34;.replace(/(\\w+)\\s(\\w+)/, \u0026#39;$2 $1\u0026#39;); // Returns \u0026#34;Camp Code\u0026#34;  Write a regex fixRegex using three capture groups that will search for each word in the string \u0026ldquo;one two three\u0026rdquo;. Then update the replaceText variable to replace \u0026ldquo;one two three\u0026rdquo; with the string \u0026ldquo;three two one\u0026rdquo; and assign the result to the result variable. Make sure you are utilizing capture groups in the replacement string using the dollar sign ($) syntax  let str = \u0026#34;one two three\u0026#34;; let fixRegex = /(\\w+)\\s(\\w+)\\s(\\w+)/; // let replaceText = \u0026#34;$3 $2 $1\u0026#34;; // let result = str.replace(fixRegex, replaceText); \n9. Remove Whitespace from Start and End  Sometimes whitespace characters around strings are not wanted but are there. Typical processing of strings is to remove the whitespace at the start and end of it. Write a regex and use the appropriate string methods to remove whitespace at the beginning and end of strings. Note: The String.prototype.trim() method would work here, but you\u0026rsquo;ll need to complete this challenge using regular expressions.  let hello = \u0026#34; Hello, World! \u0026#34;; let wsRegex = /^\\s+|\\s+$/g; // Change this line let result = hello.replace(wsRegex, \u0026#34;\u0026#34;) // Change this line ","excerpt":"Course Link\n 1. Specify Upper and Lower Number of Matches  You can specify the lower and upper …","ref":"/docs/coding/functional-coding/javascript/course/regular-expression/part3/","title":"Part 3"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/course/regular-expression/","title":"Regular Expression"},{"body":"\n Course Link\n 1. Use getters and setters to Control Access to an Object 🔖   Getter functions are meant to simply return (get) the value of an object\u0026rsquo;s private variable to the user without the user directly accessing the private variable.\n  Setter functions are meant to modify (set) the value of an object\u0026rsquo;s private variable based on the value passed into the setter function. This change could involve calculations, or even overwriting the previous value completely.\n  // Use the class keyword to create a Thermostat class. The constructor accepts a Fahrenheit temperature.  // Now create a getter and a setter in the class, to obtain the temperature in Celsius.  // Remember that C = 5/9 * (F - 32) and F = C * 9.0 / 5 + 32, where F is the value of temperature in Fahrenheit, and C is the value of the same temperature in Celsius.  // Note: When you implement this, you will track the temperature inside the class in one scale, either Fahrenheit or Celsius. class Thermostat { constructor(fahrenheit) { this.fahrenheit = fahrenheit; } get temperature() { return (5 / 9) * (this.fahrenheit - 32); } set temperature(celsius) { this.fahrenheit = (celsius * 9.0) / 5 + 32; } } // Only change code above this line  const thermos = new Thermostat(76); // Setting in Fahrenheit scale let temp = thermos.temperature; // 24.44 in Celsius thermos.temperature = 26; temp = thermos.temperature; // 26 in Celsius \n2. Create a Module Script  ES6 introduced a way to easily share code among JavaScript files. This involves exporting parts of a file for use in one or more other files, and importing the parts you need, where you need them. In order to take advantage of this functionality, you need to create a script in your HTML document with a type of module  \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Only change code below this line --\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Only change code above this line --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \n3. Use export to Share a Code Block  Imagine a file called math_functions.js that contains several functions related to mathematical operations. One of them is stored in a variable, add, that takes in two numbers and returns their sum. You want to use this function in several different JavaScript files. In order to share it with these other files, you first need to export it.  const add = (x, y) =\u0026gt; { return x + y; } export { add }; 4. Reuse JavaScript Code Using import  import allows you to choose which parts of a file or module to load.  import { add } from \u0026#39;./math_functions.js\u0026#39;; import { add, subtract } from \u0026#39;./math_functions.js\u0026#39;; \n5. Use * to Import Everything from a File  Suppose you have a file and you wish to import all of its contents into the current file The above import statement will create an object called myMathModule. The object will contain all of the exports from math_functions.js in it, so you can access the functions like you would any other object property.  import * as myMathModule from \u0026#34;./math_functions.js\u0026#34;; myMathModule.add(2,3); myMathModule.subtract(5,3); \n6. Create an Export Fallback with export default  In the export lesson, you learned about the syntax referred to as a named export. This allowed you to make multiple functions and variables available for use in other files. There is another export syntax known as export default. Usually you will use this syntax if only one value is being exported from a file. It is also used to create a fallback value for a file or module. Since export default is used to declare a fallback value for a module or file, you can only have one value be a default export in each module or file. You cannot use export default with var, let, or const  // named function export default function add(x, y) { return x + y; } // anonymous function export default function(x, y) { return x + y; } \n7. Import a Default Export  To import a default export, you need to use a different import syntax. In the following example, add is the default export of the math_functions.js file. The syntax differs in one key place. The imported value, add, is not surrounded by curly braces ({}). add here is simply a variable name for whatever the default export of the math_functions.js file is. You can use any name here when importing a default.  import add from \u0026#34;./math_functions.js\u0026#34;; \n8. Create a JavaScript Promise  Promise is a constructor function, so you need to use the new keyword to create one. It takes a function, as its argument, with two parameters - resolve and reject, which are methods used to determine the outcome of the promise. The syntax looks like this:  const myPromise = new Promise((resolve, reject) =\u0026gt; { }); const makeServerRequest = new Promise((resolve, reject) =\u0026gt; {}) \n9. Complete a Promise with resolve and reject  A promise has three states: pending, fulfilled, and rejected. The promise you created in the last challenge is forever stuck in the pending state because you did not add a way to complete the promise. The resolve and reject parameters given to the promise argument are used to do this. resolve is used when you want your promise to succeed reject is used when you want it to fail.  const myPromise = new Promise((resolve, reject) =\u0026gt; { if(condition here) { resolve(\u0026#34;Promise was fulfilled\u0026#34;); } else { reject(\u0026#34;Promise was rejected\u0026#34;); } });  The example above uses strings for the argument of these functions, but it can really be anything. Often, it might be an object, that you would use data from, to put on your website or elsewhere.  const makeServerRequest = new Promise((resolve, reject) =\u0026gt; { // responseFromServer represents a response from a server  let responseFromServer; if(responseFromServer) { resolve(\u0026#34;We got the data\u0026#34;) } else { reject(\u0026#34;Data not received\u0026#34;) } }); \n10. Handle a Fulfilled Promise with then  Promises are most useful when you have a process that takes an unknown amount of time in your code (i.e. something asynchronous), often a server request. When you make a server request it takes some amount of time, and after it completes you usually want to do something with the response from the server. This can be achieved by using the then method. The then method is executed immediately after your promise is fulfilled with resolve.  // result comes from the argument given to the resolve method. myPromise.then(result =\u0026gt; { // do something with the result. });  Example  const makeServerRequest = new Promise((resolve, reject) =\u0026gt; { // responseFromServer is set to true to represent a successful response from a server  let responseFromServer = true; if(responseFromServer) { resolve(\u0026#34;We got the data\u0026#34;); makeServerRequest.then(result =\u0026gt;{ console.log(result) }) } else { reject(\u0026#34;Data not received\u0026#34;); } }); \n11. Handle a Rejected Promise with catch  catch is the method used when your promise has been rejected. It is executed immediately after a promise\u0026rsquo;s reject method is called.  myPromise.catch(error =\u0026gt; { // do something with the error. });  Example  const makeServerRequest = new Promise((resolve, reject) =\u0026gt; { // responseFromServer is set to false to represent an unsuccessful response from a server  let responseFromServer = false; if(responseFromServer) { resolve(\u0026#34;We got the data\u0026#34;); } else { reject(\u0026#34;Data not received\u0026#34;); makeServerRequest.catch(error =\u0026gt; { console.log(error); }) } }); makeServerRequest.then(result =\u0026gt; { console.log(result); }); \nThe quote today on freeCodeCamp is from Bruce Lee.\nImage from Wikipedia\n","excerpt":"Course Link\n 1. Use getters and setters to Control Access to an Object 🔖   Getter functions are …","ref":"/docs/coding/functional-coding/javascript/course/es6/part3/","title":"Part 3"},{"body":"\n Course Link\n 1. Build JavaScript Objects  Objects are similar to arrays, except that instead of using indexes to access and modify their data, you access the data in objects through what are called properties.\n var myDog = { \u0026#34;name\u0026#34;: \u0026#34;Snoopy\u0026#34;, \u0026#34;legs\u0026#34;: 4, \u0026#34;tails\u0026#34;: 1, \u0026#34;friends\u0026#34;: [\u0026#34;Woodstock\u0026#34;,\u0026#34;Charlie\u0026#34;] }; 2. Accessing Object Properties  Use dot notation   When you know the name of the property you\u0026rsquo;re trying to access ahead of time\n var myObj = { prop1: \u0026#34;val1\u0026#34;, prop2: \u0026#34;val2\u0026#34; }; var prop1val = myObj.prop1; // val1 var prop2val = myObj.prop2; // val2  Use Bracket Notation   E.g. when the property of the object you are trying to access has a space in its name)\n // Setup var testObj = { \u0026#34;an entree\u0026#34;: \u0026#34;hamburger\u0026#34;, \u0026#34;my side\u0026#34;: \u0026#34;veggies\u0026#34;, \u0026#34;the drink\u0026#34;: \u0026#34;water\u0026#34; }; // Access var entreeValue = testObj[\u0026#34;an entree\u0026#34;]; var drinkValue = testObj[\u0026#34;the drink\u0026#34;];  Accessing Object Properties with Variables   For iterating through an object\u0026rsquo;s properties or when accessing a lookup table.\n var testObj = { 12: \u0026#34;Namath\u0026#34;, 16: \u0026#34;Montana\u0026#34;, 19: \u0026#34;Unitas\u0026#34; }; var playerNumber=16; var player = testObj[playerNumber];  Updating Object Properties Add New Properties to a JavaScript Object  var myDog = { \u0026#34;name\u0026#34;: \u0026#34;Coder\u0026#34;, \u0026#34;legs\u0026#34;: 4, \u0026#34;tails\u0026#34;: 1, \u0026#34;friends\u0026#34;: [\u0026#34;freeCodeCamp Campers\u0026#34;] }; myDog.name = \u0026#34;Hppy Coder\u0026#34; myDog.bark = [\u0026#34;woof\u0026#34;];  Delete Properties from a JavaScript Object  delete myDog.bark;  Using Objects for Lookups   When you know that your input data is limited to a certain range.\n function phoneticLookup(val) { var result = \u0026#34;\u0026#34;; var result_table ={ \u0026#34;alpha\u0026#34;: \u0026#34;Adams\u0026#34;, \u0026#34;bravo\u0026#34;: \u0026#34;Boston\u0026#34;, \u0026#34;charlie\u0026#34;: \u0026#34;Chicago\u0026#34;, \u0026#34;delta\u0026#34;: \u0026#34;Denver\u0026#34;, \u0026#34;echo\u0026#34;: \u0026#34;Easy\u0026#34;, \u0026#34;foxtrot\u0026#34;: \u0026#34;Frank\u0026#34; } result = result_table[val]; return result; } phoneticLookup(\u0026#34;charlie\u0026#34;);  Testing Objects for Properties  function checkObj(obj, checkProp) { if obj.hasOwnProperty(checkProp) { return obj[checkProp]; } else { return \u0026#34;Not Found\u0026#34;, } }  Manipulating Complex Objects  var myMusic = [ { \u0026#34;artist\u0026#34;: \u0026#34;Billy Joel\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Piano Man\u0026#34;, \u0026#34;release_year\u0026#34;: 1973, \u0026#34;formats\u0026#34;: [ \u0026#34;CD\u0026#34;, \u0026#34;8T\u0026#34;, \u0026#34;LP\u0026#34; ], \u0026#34;gold\u0026#34;: true }, //comma  // Add a record here  { \u0026#34;artist\u0026#34;: \u0026#34;Billy Joel\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Piano Man 2\u0026#34;, \u0026#34;release_year\u0026#34;: 1974, \u0026#34;formats\u0026#34;: [ \u0026#34;CD\u0026#34;, \u0026#34;8T\u0026#34;, \u0026#34;LP\u0026#34; ], \u0026#34;gold\u0026#34;: true } ];  Accessing Nested Objects  // Setup var myStorage = { \u0026#34;car\u0026#34;: { \u0026#34;inside\u0026#34;: { \u0026#34;glove box\u0026#34;: \u0026#34;maps\u0026#34;, \u0026#34;passenger seat\u0026#34;: \u0026#34;crumbs\u0026#34; }, \u0026#34;outside\u0026#34;: { \u0026#34;trunk\u0026#34;: \u0026#34;jack\u0026#34; } } }; var gloveBoxContents = myStorage.car.inside[\u0026#34;glove box\u0026#34;];  Accessing Nested Arrays  // Setup var myPlants = [ { type: \u0026#34;flowers\u0026#34;, list: [ \u0026#34;rose\u0026#34;, \u0026#34;tulip\u0026#34;, \u0026#34;dandelion\u0026#34; ] }, { type: \u0026#34;trees\u0026#34;, list: [ \u0026#34;fir\u0026#34;, \u0026#34;pine\u0026#34;, \u0026#34;birch\u0026#34; ] } ]; var secondTree = myPlants[1].list[1]; // pine 3. Record Collection Exercise Basic JavaScript: Record CollectionPassed You are given a JSON object representing a part of your musical album collection. Each album has several properties and a unique id number as its key. Not all albums have complete information. Write a function which takes an album\u0026#39;s id (like 2548), a property prop (like \u0026#34;artist\u0026#34; or \u0026#34;tracks\u0026#34;), and a value (like \u0026#34;Addicted to Love\u0026#34;) to modify the data in this collection. If prop isn\u0026#39;t \u0026#34;tracks\u0026#34; and value isn\u0026#39;t empty (\u0026#34;\u0026#34;), update or set the value for that record album\u0026#39;s property. Your function must always return the entire collection object. There are several rules for handling incomplete data: If prop is \u0026#34;tracks\u0026#34; but the album doesn\u0026#39;t have a \u0026#34;tracks\u0026#34; property, create an empty array before adding the new value to the album\u0026#39;s corresponding property. If prop is \u0026#34;tracks\u0026#34; and value isn\u0026#39;t empty (\u0026#34;\u0026#34;), push the value onto the end of the album\u0026#39;s existing tracks array. If value is empty (\u0026#34;\u0026#34;), delete the given prop property from the album. function lookUpProfile(name, prop){ for (var i =0; i \u0026lt;contacts.length; i++){ if (contacts[i].firstName === name){ if (contacts[i].hasOwnProperty(prop)){ return contacts[i][prop] } return \u0026#34;No such property\u0026#34; } } return \u0026#34;No such contact\u0026#34; } ","excerpt":"Course Link\n 1. Build JavaScript Objects  Objects are similar to arrays, except that instead of …","ref":"/docs/coding/functional-coding/javascript/course/basics/objects/","title":"Objects"},{"body":"Bar Plot import matplotlib.pyplot as plt def plot_count(df, feature, title=\u0026#39;\u0026#39;, size=2): f, ax = plt.subplots(1,1, figsize=(4*size,3*size)) total = float(len(df)) sns.countplot(df[feature],order = df[feature].value_counts().index, palette=\u0026#39;Set2\u0026#39;) plt.title(title) for p in ax.patches: height = p.get_height() ax.text(p.get_x()+p.get_width()/2., height + 3, \u0026#39;{:1.2f}%\u0026#39;.format(100*height/total), ha=\u0026#34;center\u0026#34;) plt.show() ","excerpt":"Bar Plot import matplotlib.pyplot as plt def plot_count(df, feature, title=\u0026#39;\u0026#39;, size=2): f, …","ref":"/docs/coding/functional-coding/python/plot/","title":"Plot"},{"body":"","excerpt":"","ref":"/docs/machinelearning/frameworks/","title":"Frameworks"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/classification/","title":"Classification"},{"body":"\nWarnings  WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable  ","excerpt":"\nWarnings  WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using …","ref":"/docs/coding/practices/error_collection/pyspark/","title":"Pyspark"},{"body":"\nLicense To the extent possible under law, GNNPapers has waived all copyright and related or neighboring rights to this work.\nContent  1. Survey 2. Models  \u0026emsp;2.1 Basic Models \u0026ensp;2.2 Graph Types   \u0026emsp;2.3 Pooling Methods \u0026ensp;2.4 Analysis   \u0026emsp;2.5 Efficiency   3. Applications  \u0026emsp;3.1 Physics \u0026ensp;3.2 Chemistry and Biology   \u0026emsp;3.3 Knowledge Graph \u0026ensp;3.4 Recommender Systems   \u0026emsp;3.5 Computer Vision \u0026ensp;3.6 Natural Language Processing   \u0026emsp;3.7 Generation \u0026ensp;3.8 Combinatorial Optimization   \u0026emsp;3.9 Adversarial Attack \u0026ensp;3.10 Graph Clustering   \u0026emsp;3.11 Graph Classification \u0026ensp;3.12 Reinforcement Learning   \u0026emsp;3.13 Traffic Network \u0026ensp;3.14 Few-shot and Zero-shot Learning   \u0026emsp;3.15 Program Representation \u0026ensp;3.16 Social Network   \u0026emsp;3.17 Graph Matching \u0026ensp;   Survey papers   Introduction to Graph Neural Networks. Synthesis Lectures on Artificial Intelligence and Machine Learning, Morgan \u0026amp; Claypool Publishers, 2020. book\nZhiyuan Liu, Jie Zhou.\n  Graph Neural Networks: A Review of Methods and Applications. arxiv 2018. paper\nJie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun.\n  A Comprehensive Survey on Graph Neural Networks. arxiv 2019. paper\nZonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu.\n  Deep Learning on Graphs: A Survey. arxiv 2018. paper\nZiwei Zhang, Peng Cui, Wenwu Zhu.\n  Relational Inductive Biases, Deep Learning, and Graph Networks. arxiv 2018. paper\nBattaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others.\n  Geometric Deep Learning: Going beyond Euclidean data. IEEE SPM 2017. paper\nBronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre.\n  Computational Capabilities of Graph Neural Networks. IEEE TNN 2009. paper\nScarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.\n  Neural Message Passing for Quantum Chemistry. ICML 2017. paper\nGilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E.\n  Non-local Neural Networks. CVPR 2018. paper\nWang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming.\n  The Graph Neural Network Model. IEEE TNN 2009. paper\nScarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.\n  Models Basic Models   Supervised Neural Networks for the Classification of Structures. IEEE TNN 1997. paper\nAlessandro Sperduti and Antonina Starita.\n  Graphical-Based Learning Environments for Pattern Recognition. SSPR/SPR 2004. paper\nFranco Scarselli, Ah Chung Tsoi, Marco Gori, Markus Hagenbuchner.\n  A new model for learning in graph domains. IJCNN 2005. paper\nMarco Gori, Gabriele Monfardini, Franco Scarselli.\n  Graph Neural Networks for Ranking Web Pages. WI 2005. paper\nFranco Scarselli, Sweah Liang Yong, Marco Gori, Markus Hagenbuchner, Ah Chung Tsoi, Marco Maggini.\n  Neural Network for Graphs: A Contextual Constructive Approach. IEEE TNN 2009. paper\nAlessio Micheli.\n  Spectral Networks and Locally Connected Networks on Graphs. ICLR 2014. paper\nJoan Bruna, Wojciech Zaremba, Arthur Szlam, Yann LeCun.\n  Deep Convolutional Networks on Graph-Structured Data. arxiv 2015. paper\nMikael Henaff, Joan Bruna, Yann LeCun.\n  Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. NIPS 2016. paper\nMichaël Defferrard, Xavier Bresson, Pierre Vandergheynst.\n  Diffusion-Convolutional Neural Networks. NIPS 2016. paper\nJames Atwood, Don Towsley.\n  Gated Graph Sequence Neural Networks. ICLR 2016. paper\nYujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel.\n  Learning Convolutional Neural Networks for Graphs. ICML 2016. paper\nMathias Niepert, Mohamed Ahmed, Konstantin Kutzkov.\n  Semantic Object Parsing with Graph LSTM. ECCV 2016. paper\nXiaodan Liang, Xiaohui Shen, Jiashi Feng, Liang Lin, Shuicheng Yan.\n  Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017. paper\nThomas N. Kipf, Max Welling.\n  Inductive Representation Learning on Large Graphs. NIPS 2017. paper\nWilliam L. Hamilton, Rex Ying, Jure Leskovec.\n  Geometric deep learning on graphs and manifolds using mixture model cnns. CVPR 2017. paper\nFederico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodolà, Jan Svoboda, Michael M. Bronstein.\n  Graph Attention Networks. ICLR 2018. paper\nPetar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio.\n  Covariant Compositional Networks For Learning Graphs. ICLR 2018. paper\nRisi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, Shubhendu Trivedi.\n  Graph Partition Neural Networks for Semi-Supervised Classification. ICLR 2018. paper\nRenjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander L. Gaunt, Raquel Urtasun, Richard Zemel.\n  Inference in Probabilistic Graphical Models by Graph Neural Networks. ICLR Workshop 2018. paper\nKiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya, Raquel Urtasun, Richard Zemel, Xaq Pitkow.\n  Structure-Aware Convolutional Neural Networks. NeurIPS 2018. paper\nJianlong Chang, Jie Gu, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, Chunhong Pan.\n   more   Bayesian Semi-supervised Learning with Graph Gaussian Processes. NeurIPS 2018. paper\nYin Cheng Ng, Nicolò Colombo, Ricardo Silva.\n  Adaptive Graph Convolutional Neural Networks. AAAI 2018. paper\nRuoyu Li, Sheng Wang, Feiyun Zhu, Junzhou Huang.\n  Dual Graph Convolutional Networks for Graph-Based Semi-Supervised Classification. WWW 2018. paper\nChenyi Zhuang, Qiang Ma.\n  Learning Steady-States of Iterative Algorithms over Graphs. ICML 2018. paper\nHanjun Dai, Zornitsa Kozareva, Bo Dai, Alex Smola, Le Song.\n  Graph Capsule Convolutional Neural Networks. ICML 2018 Workshop. paper\nSaurabh Verma, Zhi-Li Zhang.\n  Capsule Graph Neural Network. ICLR 2019. paper\nZhang Xinyi, Lihui Chen.\n  Graph Wavelet Neural Network. ICLR 2019. paper\nBingbing Xu, Huawei Shen, Qi Cao, Yunqi Qiu, Xueqi Cheng.\n  Deep Graph Infomax. ICLR 2019. paper\nPetar Veličković, William Fedus, William L. Hamilton, Pietro Liò, Yoshua Bengio, R Devon Hjelm.\n  Predict then Propagate: Graph Neural Networks meet Personalized PageRank. ICLR 2019. paper\nJohannes Klicpera, Aleksandar Bojchevski, Stephan Günnemann.\n  LanczosNet: Multi-Scale Deep Graph Convolutional Networks. ICLR 2019. paper\nRenjie Liao, Zhizhen Zhao, Raquel Urtasun, Richard Zemel.\n  Invariant and Equivariant Graph Networks. ICLR 2019. paper\nHaggai Maron, Heli Ben-Hamu, Nadav Shamir, Yaron Lipman.\n  GMNN: Graph Markov Neural Networks. ICML 2019. paper\nMeng Qu, Yoshua Bengio, Jian Tang.\n  Position-aware Graph Neural Networks. ICML 2019. paper\nJiaxuan You, Rex Ying, Jure Leskovec.\n  Disentangled Graph Convolutional Networks. ICML 2019. paper\nJianxin Ma, Peng Cui, Kun Kuang, Xin Wang, Wenwu Zhu.\n  Stochastic Blockmodels meet Graph Neural Networks. ICML 2019. paper\nNikhil Mehta, Lawrence Carin, Piyush Rai.\n  Learning Discrete Structures for Graph Neural Networks. ICML 2019. paper\nLuca Franceschi, Mathias Niepert, Massimiliano Pontil, Xiao He.\n  MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. ICML 2019. paper\nSami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayr Harutyunyan, Greg Ver Steeg, Aram Galstyan.\n  DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph Classification. KDD 2019. paper\nJun Wu, Jingrui He, Jiejun Xu.\n  Graph Representation Learning via Hard and Channel-Wise Attention Networks. KDD 2019. paper\nHongyang Gao, Shuiwang Ji.\n  Graph Learning-Convolutional Networks. CVPR 2019. paper\nBo Jiang, Ziyan Zhang, Doudou Lin, Jin Tang.\n  Data Representation and Learning with Graph Diffusion-Embedding Networks. CVPR 2019. paper\nBo Jiang, Doudou Lin, Jin Tang, Bin Luo.\n  Label Efficient Semi-Supervised Learning via Graph Filtering. CVPR 2019. paper\nQimai Li, Xiao-Ming Wu, Han Liu, Xiaotong Zhang, Zhichao Guan.\n  SPAGAN: Shortest Path Graph Attention Network. IJCAI 2019. paper\nYiding Yang, Xinchao Wang, Mingli Song, Junsong Yuan, Dacheng Tao.\n  Topology Optimization based Graph Convolutional Network. IJCAI 2019. paper\nLiang Yang, Zesheng Kang, Xiaochun Cao, Di Jin, Bo Yang, Yuanfang Guo.\n  Hierarchical Graph Convolutional Networks for Semi-supervised Node Classification. IJCAI 2019. paper\nFenyu Hu, Yanqiao Zhu, Shu Wu, Liang Wang, Tieniu Tan.\n  Masked Graph Convolutional Network. IJCAI 2019. paper\nLiang Yang, Fan Wu, Yingkui Wang, Junhua Gu, Yuanfang Guo.\n  Dual Self-Paced Graph Convolutional Network: Towards Reducing Attribute Distortions Induced by Topology. IJCAI 2019. paper\nLiang Yang, Zhiyang Chen, Junhua Gu, Yuanfang Guo.\n  Bayesian graph convolutional neural networks for semi-supervised classification. AAAI 2019. paper\nYingxue Zhang, Soumyasundar Pal, Mark Coates, Deniz Üstebay.\n  GeniePath: Graph Neural Networks with Adaptive Receptive Paths. AAAI 2019. paper\nZiqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song, Yuan Qi.\n  Gaussian-Induced Convolution for Graphs. AAAI 2019. paper\nJiatao Jiang, Zhen Cui, Chunyan Xu, Jian Yang.\n  Fisher-Bures Adversary Graph Convolutional Networks. UAI 2019. paper\nKe Sun, Piotr Koniusz, Zhen Wang.\n  N-GCN: Multi-scale Graph Convolution for Semi-supervised Node Classification. UAI 2019. paper\nSami Abu-El-Haija, Amol Kapoor, Bryan Perozzi, Joonseok Lee.\n  Confidence-based Graph Convolutional Networks for Semi-Supervised Learning. AISTATS 2019. paper\nShikhar Vashishth, Prateek Yadav, Manik Bhandari, Partha Talukdar.\n  Lovasz Convolutional Networks. AISTATS 2019. paper\nPrateek Yadav, Madhav Nimishakavi, Naganand Yadati, Shikhar Vashishth, Arun Rajkumar, Partha Talukdar.\n  Provably Powerful Graph Networks. NeurIPS 2019. paper\nHaggai Maron, Heli Ben-Hamu, Hadar Serviansky, Yaron Lipman.\n  Graph Agreement Models for Semi-Supervised Learning. NeurIPS 2019. paper\nOtilia Stretcu, Krishnamurthy Viswanathan, Dana Movshovitz-Attias, Emmanouil Platanios. Sujith Ravi, Andrew Tomkins.\n  Graph-Based Semi-Supervised Learning with Non-ignorable Non-response. NeurIPS 2019. paper\nFan Zhou, Tengfei Li, Haibo Zhou, Hongtu Zhu, Ye Jieping.\n  A Flexible Generative Framework for Graph-based Semi-supervised Learning. NeurIPS 2019. paper\nJiaqi Ma, Weijing Tang, Ji Zhu, Qiaozhu Mei.\n  Semi-Implicit Graph Variational Auto-Encoders. NeurIPS 2019. paper\nArman Hasanzadeh, Ehsan Hajiramezanali, Krishna Narayanan, Nick Duffield, Mingyuan Zhou, Xiaoning Qian.\n  Hyperbolic Graph Neural Networks. NeurIPS 2019. paper\nQi Liu, Maximilian Nickel, Douwe Kiela.\n  Hyperbolic Graph Convolutional Neural Networks. NeurIPS 2019. paper\nInes Chami, Zhitao Ying, Christopher Ré, Jure Leskovec.\n  Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels. NeurIPS 2019. paper\nSimon Du, Kangcheng Hou, Russ Salakhutdinov, Barnabas Poczos, Ruosong Wang, Keyulu Xu.\n  SNEQ: Semi-supervised Attributed Network Embedding with Attention-based Quantisation. AAAI 2020. paper\nTao He, Lianli Gao, Jingkuan Song, Xin Wang, Kejie Huang, Yuan-­‐Fang Li.\n  Going Deep: Graph Convolutional Ladder-Shape Networks. AAAI 2020. paper\nRuiqi Hu, Shirui Pan, Guodong Long, Qinghua Lu, Liming Zhu, Jing Jiang.\n  Co-GCN for Multi-View Semi-Supervised Learning. AAAI 2020. paper\nShu Li, Wen-­‐Tao Li, Wei Wang.\n  Graph Representation Learning via Ladder Gamma Variational Autoencoders. AAAI 2020. paper\nArindam Sarkar, Nikhil Mehta, Piyush Rai.\n  GSSNN: Graph Smoothing Splines Neural Networks. AAAI 2020. paper\nShichao Zhu, Lewei Zhou, Shirui Pan, Chuan Zhou, Guiying Yan, Bin Wang.\n  Effective Decoding in Graph Auto-Encoder using Triadic Closure. AAAI 2020. paper\nHan Shi, Haozheng Fan, James T. Kwok.\n  An Attention-based Graph Neural Network for Heterogeneous Structural Learning. AAAI 2020. paper\nHuiting Hong, Hantao Guo, Yucheng Lin, Xiaoqing Yang, Zang Li, Jieping Ye.\n  Fast and Deep Graph Neural Networks. AAAI 2020. paper\nClaudio Gallicchio, Alessio Micheli.\n  Hypergraph Label Propagation Network. AAAI 2020. paper\nYubo Zhang, Nan Wang, Yufeng Chen, Changqing Zou, Hai Wan, Xibin Zhao, Yue Gao.\n  Learning Signed Network Embedding via Graph Attention. AAAI 2020. paper\nYu Li, Yuan Tian, Jiawei Zhang, Yi Chang.\n  GraLSP: Graph Neural Networks with Local Structural Patterns. AAAI 2020. paper\nYilun Jin, Guojie Song, Chuan Shi.\n  ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations. AAAI 2020. paper\nEkagra Ranjan, Soumya Sanyal, Partha Pratim Talukdar.\n  Multi‐Stage Self­‐Supervised Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes. AAAI 2020. paper\nKe Sun, Zhouchen Lin, Zhanxing Zhu.\n  Collaborative Graph Convolutional Networks: Unsupervised Learning Meets Semi-­‐Supervised Learning. AAAI 2020. paper\nBinyuan Hui, Pengfei Zhu, Qinghua, Hu.\n  A Multi­‐Scale Approach for Graph Link Prediction. AAAI 2020. paper\nLei Cai, Shuiwang Ji.\n  Adaptive Structural Fingerprints for Graph Attention Networks. ICLR 2020. paper\nKai Zhang, Yaokang Zhu, Jun Wang, Jie Zhang.\n  Strategies for Pre-training Graph Neural Networks. ICLR 2020. paper\nWeihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec.\n  DropEdge: Towards Deep Graph Convolutional Networks on Node Classification. ICLR 2020. paper\nYu Rong, Wenbing Huang, Tingyang Xu, Junzhou Huang.\n  Directional Message Passing for Molecular Graphs. ICLR 2020. paper\nJohannes Klicpera, Janek Groß, Stephan Günnemann.\n  DeepSphere: a graph-based spherical CNN. ICLR 2020. paper\nMichaël Defferrard, Martino Milani, Frédérick Gusset, Nathanaël Perraudin.\n  Geom-GCN: Geometric Graph Convolutional Networks. ICLR 2020. paper\nHongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang.\n  Curvature Graph Network. ICLR 2020. paper\nZe Ye, Kin Sum Liu, Tengfei Ma, Jie Gao, Chao Chen.\n  Measuring and Improving the Use of Graph Information in Graph Neural Networks. ICLR 2020. paper\nYifan Hou, Jian Zhang, James Cheng, Kaili Ma, Richard T. B. Ma, Hongzhi Chen, Ming-Chang Yang.\n  Memory-Based Graph Networks. ICLR 2020. paper\nAmir Hosein Khasahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Quaid Morris.\n  Pruned Graph Scattering Transforms. ICLR 2020. paper\nVassilis N. Ioannidis, Siheng Chen, Georgios B. Giannakis.\n  Neural Execution of Graph Algorithms. ICLR 2020. paper\nPetar Veličković, Rex Ying, Matilde Padovano, Raia Hadsell, Charles Blundell.\n  GraphSAINT: Graph Sampling Based Inductive Learning Method. ICLR 2020. paper\nHanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, Viktor Prasanna.\n  Graph inference learning for semi-supervised classification. ICLR 2020. paper\nChunyan Xu, Zhen Cui, Xiaobin Hong, Tong Zhang, Jian Yang, Wei Liu.\n   Graph Types   DyRep: Learning Representations over Dynamic Graphs. ICLR 2019. paper\nRakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, Hongyuan Zha.\n  Hypergraph Neural Networks. AAAI 2019. paper\nYifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, Yue Gao.\n  Heterogeneous Graph Attention Network. WWW 2019. paper\nXiao Wang, Houye Ji, Chuan Shi, Bai Wang, Peng Cui, P. Yu, Yanfang Ye.\n  Representation Learning for Attributed Multiplex Heterogeneous Network. KDD 2019. paper\nYukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, Jie Tang.\n  ActiveHNE: Active Heterogeneous Network Embedding. IJCAI 2019. paper\nXia Chen, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Zhao Li, Xiangliang Zhang.\n  GCN-LASE: Towards Adequately Incorporating Link Attributes in Graph Convolutional Networks. IJCAI 2019. paper\nZiyao Li, Liang Zhang, Guojie Song.\n  Dynamic Hypergraph Neural Networks. IJCAI 2019. paper\nJianwen Jiang, Yuxuan Wei, Yifan Feng, Jingxuan Cao, Yue Gao.\n  Exploiting Interaction Links for Node Classification with Deep Graph Neural Networks. IJCAI 2019. paper\nHogun Park, Jennifer Neville.\n  Exploiting Edge Features in Graph Neural Networks. CVPR 2019. paper\nLiyu Gong, Qiang Cheng.\n  HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs. NeurIPS 2019. paper\nNaganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, Partha Talukdar.\n  Graph Transformer Networks. NeurIPS 2019. paper\nSeongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, Hyunwoo Kim.\n  Recurrent Space-time Graph Neural Networks. NeurIPS 2019. paper\nAndrei Nicolicioiu, Iulia Duta, Marius Leordeanu.\n  EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs. AAAI 2020. paper\nAldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hiroki Kanezashi, Tim Kaler, Tao B. Schardl, Charles E. Leiserson.\n  Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting. AAAI 2020. paper\nChao Song, Youfang Lin, Shengnan Guo, Huaiyu Wan.\n  Type-aware Anchor Link Prediction across Heterogeneous Networks based on Graph Attention Network. AAAI 2020. paper\nXiaoxue Li, Yanmin Shang, Yanan Cao, Yangxi Li, Jianlong Tan, Yanbing Liu.\n  Composition-based Multi-Relational Graph Convolutional Networks. ICLR 2020. paper\nShikhar Vashishth, Soumya Sanyal, Vikram Nitin, Partha Talukdar.\n  Inductive representation learning on temporal graphs. ICLR 2020. paper\nda Xu, chuanwei ruan, evren korpeoglu, sushant kumar, kannan achan.\n  Hyper-SAGNN: a self-attention based graph neural network for hypergraphs. ICLR 2020. paper\nRuochi Zhang, Yuesong Zou, Jian Ma.\n  Pooling Methods   An End-to-End Deep Learning Architecture for Graph Classification. AAAI 2018. paper\nMuhan Zhang, Zhicheng Cui, Marion Neumann, Yixin Chen.\n  Hierarchical Graph Representation Learning with Differentiable Pooling. NeurIPS 2018. paper\nZhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, Jure Leskovec.\n  Self-Attention Graph Pooling. ICML 2019. paper\nJunhyun Lee, Inyeop Lee, Jaewoo Kang.\n  Graph U-Nets. ICML 2019. paper\nHongyang Gao, Shuiwang Ji.\n  Graph Convolutional Networks with EigenPooling. KDD 2019. paper\nYao Ma, Suhang Wang, Charu C. Aggarwal, Jiliang Tang.\n  Relational Pooling for Graph Representations. ICML 2019. paper\nRyan L. Murphy, Balasubramaniam Srinivasan, Vinayak Rao, Bruno Ribeiro.\n  Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional Networks. NeurIPS 2019. paper\nSitao Luan, Mingde Zhao, Xiao-Wen Chang, Doina Precup.\n  Diffusion Improves Graph Learning. NeurIPS 2019. paper\nJohannes Klicpera, Stefan Weißenberger, Stephan Günnemann.\n  Hierarchical Graph Pooling with Structure Learning. AAAI 2020. paper\nZhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Zhi Yu, Can Wang.\n  StructPool: Structured Graph Pooling via Conditional Random Fields. ICLR 2020. paper\nHao Yuan, Shuiwang Ji.\n  Analysis   A Comparison between Recursive Neural Networks and Graph Neural Networks. IJCNN 2006. paper\nVincenzo Di Massa, Gabriele Monfardini, Lorenzo Sarti, Franco Scarselli, Marco Maggini, Marco Gori.\n  Neural networks for relational learning: an experimental comparison. Machine Learning 2011. paper\nWerner Uwents, Gabriele Monfardini, Hendrik Blockeel, Marco Gori, Franco Scarselli.\n  Mean-field theory of graph neural networks in graph partitioning. NeurIPS 2018. paper\nTatsuro Kawamoto, Masashi Tsubaki, Tomoyuki Obuchi.\n  Representation Learning on Graphs with Jumping Knowledge Networks. ICML 2018. paper\nKeyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka.\n  Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. AAAI 2018. paper\nQimai Li, Zhichao Han, Xiao-Ming Wu.\n  How Powerful are Graph Neural Networks? ICLR 2019. paper\nKeyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka.\n  Stability and Generalization of Graph Convolutional Neural Networks. KDD 2019. paper\nSaurabh Verma, Zhi-Li Zhang.\n  Simplifying Graph Convolutional Networks. ICML 2019. paper\nFelix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr., Christopher Fifty, Tao Yu, Kilian Q. Weinberger.\n  Explainability Methods for Graph Convolutional Neural Networks. CVPR 2019. paper\nPhillip E. Pope, Soheil Kolouri, Mohammad Rostami, Charles E. Martin, Heiko Hoffmann.\n  Can GCNs Go as Deep as CNNs? ICCV 2019. paper\nGuohao Li, Matthias Müller, Ali Thabet, Bernard Ghanem.\n  Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks. AAAI 2019. paper\nChristopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton, Jan Eric Lenssen, Gaurav Rattan, Martin Grohe.\n  Understanding Attention and Generalization in Graph Neural Networks. NeurIPS 2019. paper\nBoris Knyazev, Graham W. Taylor, Mohamed R. Amer.\n  GNNExplainer: Generating Explanations for Graph Neural Networks. NeurIPS 2019. paper\nZhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec.\n  Universal Invariant and Equivariant Graph Neural Networks. NeurIPS 2019. paper\nNicolas Keriven, Gabriel Peyré.\n  Understanding Attention and Generalization in Graph Neural Networks. NeurIPS 2019. paper\nBoris Knyazev, Graham W Taylor, Mohamed Amer.\n  On the equivalence between graph isomorphism testing and function approximation with GNNs. NeurIPS 2019. paper\nZhengdao Chen, Soledad Villar, Lei Chen, Joan Bruna.\n  Understanding the Representation Power of Graph Neural Networks in Learning Graph Topology. NeurIPS 2019. paper\nNima Dehmamy, Albert-Laszlo Barabasi, Rose Yu.\n  Graph Neural Networks Exponentially Lose Expressive Power for Node Classification. ICLR 2020. paper\nKenta Oono, Taiji Suzuki.\n  What graph neural networks cannot learn: depth vs width. ICLR 2020. paper\nAndreas Loukas.\n  The Logical Expressiveness of Graph Neural Networks. ICLR 2020. paper\nPablo Barceló, Egor V. Kostylev, Mikael Monet, Jorge Pérez, Juan Reutter, Juan Pablo Silva.\n  On the Equivalence between Positional Node Embeddings and Structural Graph Representations. ICLR 2020. paper\nBalasubramaniam Srinivasan, Bruno Ribeiro.\n  Efficiency   Stochastic Training of Graph Convolutional Networks with Variance Reduction. ICML 2018. paper\nJianfei Chen, Jun Zhu, Le Song.\n  FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. ICLR 2018. paper\nJie Chen, Tengfei Ma, Cao Xiao.\n  Adaptive Sampling Towards Fast Graph Representation Learning. NeurIPS 2018. paper\nWenbing Huang, Tong Zhang, Yu Rong, Junzhou Huang.\n  Large-Scale Learnable Graph Convolutional Networks. KDD 2018. paper\nHongyang Gao, Zhengyang Wang, Shuiwang Ji.\n  Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. KDD 2019. paper\nWei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh.\n  A Degeneracy Framework for Scalable Graph Autoencoders. IJCAI 2019. paper\nGuillaume Salha, Romain Hennequin, Viet Anh Tran, Michalis Vazirgiannis.\n  Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks. NeurIPS 2019. paper\nDifan Zou, Ziniu Hu, Yewen Wang, Song Jiang, Yizhou Sun, Quanquan Gu.\n  Applications Physics   Discovering objects and their relations from entangled scene representations. ICLR Workshop 2017. paper\nDavid Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap, Peter Battaglia.\n  A simple neural network module for relational reasoning. NIPS 2017. paper\nAdam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap.\n  Interaction Networks for Learning about Objects, Relations and Physics. NIPS 2016. paper\nPeter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, Koray Kavukcuoglu.\n  Visual Interaction Networks: Learning a Physics Simulator from Video. NIPS 2017. paper\nNicholas Watters, Andrea Tacchetti, Théophane Weber, Razvan Pascanu, Peter Battaglia, Daniel Zoran.\n  Graph networks as learnable physics engines for inference and control. ICML 2018. paper\nAlvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia.\n  Learning Multiagent Communication with Backpropagation. NIPS 2016. paper\nSainbayar Sukhbaatar, Arthur Szlam, Rob Fergus.\n  VAIN: Attentional Multi-agent Predictive Modeling. NIPS 2017 paper\nYedid Hoshen.\n  Neural Relational Inference for Interacting Systems. ICML 2018. paper\nThomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemel.\n  Graph Element Networks: adaptive, structured computation and memory. ICML 2019. paper\nFerran Alet, Adarsh K. Jeewajee, Maria Bauza, Alberto Rodriguez, Tomas Lozano-Perez, Leslie Pack Kaelbling.\n  Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics. ICLR 2020. paper\nSungyong Seo, Chuizheng Meng, Yan Liu.\n  Chemistry and Biology   Convolutional networks on graphs for learning molecular fingerprints. NIPS 2015. paper\nDavid Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli, Timothy Hirzel, Alán Aspuru-Guzik, Ryan P. Adams.\n  Molecular Graph Convolutions: Moving Beyond Fingerprints. Journal of computer-aided molecular design 2016. paper\nSteven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, Patrick Riley.\n  Protein Interface Prediction using Graph Convolutional Networks. NIPS 2017. paper\nAlex Fout, Jonathon Byrd, Basir Shariat, Asa Ben-Hur.\n  Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification. IJCAI 2018. paper\nSungmin Rhee, Seokjun Seo, Sun Kim.\n  Modeling polypharmacy side effects with graph convolutional networks. ISMB 2018. paper\nMarinka Zitnik, Monica Agrawal, Jure Leskovec.\n  Spectral Multigraph Networks for Discovering and Fusing Relationships in Molecules. NeurIPS Workshop 2018. paper\nBoris Knyazev, Xiao Lin, Mohamed R. Amer, Graham W. Taylor.\n  MR-GNN: Multi-Resolution and Dual Graph Neural Network for Predicting Structured Entity Interactions. IJCAI 2019. paper\nNuo Xu, Pinghui Wang, Long Chen, Jing Tao, Junzhou Zhao.\n  Pre-training of Graph Augmented Transformers for Medication Recommendation. IJCAI 2019. paper\nJunyuan Shang, Tengfei Ma, Cao Xiao, Jimeng Sun.\n  GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination. AAAI 2019. paper\nJunyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li, Jimeng Sun.\n  AffinityNet: semi-supervised few-shot learning for disease type prediction. AAAI 2019. paper\nTianle Ma, Aidong Zhang.\n  Graph Transformation Policy Network for Chemical Reaction Prediction. KDD 2019. paper\nKien Do, Truyen Tran, Svetha Venkatesh.\n  Functional Transparency for Structured Data: a Game-Theoretic Approach. ICML 2019. paper\nGuang-He Lee, Wengong Jin, David Alvarez-Melis, Tommi S. Jaakkola.\n  Learning Multimodal Graph-to-Graph Translation for Molecular Optimization. ICLR 2019. paper\nWengong Jin, Kevin Yang, Regina Barzilay, Tommi Jaakkola.\n  A Generative Model For Electron Paths. ICLR 2019. paper\nJohn Bradshaw, Matt J. Kusner, Brooks Paige, Marwin H. S. Segler, José Miguel Hernández-Lobato.\n  Retrosynthesis Prediction with Conditional Graph Logic Network. NeurIPS 2019. paper\nHanjun Dai, Chengtao Li, Connor Coley, Bo Dai, Le Song.\n  Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer. AAAI 2020. paper\nEdward Choi, Zhen Xu, Yujia Li, Michael W. Dusenberry, Gerardo Flores, Yuan Xue, Andrew M. Dai.\n  Knowledge Graph   Modeling Relational Data with Graph Convolutional Networks. ESWC 2018. paper\nMichael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, Max Welling.\n  Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks. EMNLP 2018. paper\nZhichun Wang, Qingsong Lv, Xiaohan Lan, Yu Zhang.\n  Representation learning for visual-relational knowledge graphs. arxiv 2017. paper\nDaniel Oñoro-Rubio, Mathias Niepert, Alberto García-Durán, Roberto González, Roberto J. López-Sastre.\n  End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion. AAAI 2019. paper\nChao Shang, Yun Tang, Jing Huang, Jinbo Bi, Xiaodong He, Bowen Zhou.\n  Knowledge Transfer for Out-of-Knowledge-Base Entities : A Graph Neural Network Approach. IJCAI 2017. paper\nTakuo Hamaguchi, Hidekazu Oiwa, Masashi Shimbo, Yuji Matsumoto.\n  Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding. AAAI 2019. paper\nPeifeng Wang, Jialong Han, Chenliang Li, Rong Pan.\n  Dynamic Graph Generation Network: Generating Relational Knowledge from Diagrams. CVPR 2018. paper\nHaoyu Wang, Defu Lian, Yong Ge.\n  Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks. KDD 2019. paper\nNamyong Park, Andrey Kan, Xin Luna Dong, Tong Zhao, Christos Faloutsos.\n  OAG: Toward Linking Large-scale Heterogeneous Entity Graphs. KDD 2019. paper\nFanjin Zhang, Xiao Liu, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, Xiaotao Gu, Yan Wang, Bin Shao, Rui Li, Kuansan Wang.\n  Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs. ACL 2019. paper\nDeepak Nathani, Jatin Chauhan, Charu Sharma, Manohar Kaul.\n  Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network. ACL 2019. paper\nKun Xu, Mo Yu, Yansong Feng, Yan Song, Zhiguo Wang, Dong Yu.\n  Multi-relational Poincaré Graph Embeddings. NeurIPS 2019. paper\nIvana Balazevic, Carl Allen, Timothy Hospedales.\n  Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning. ICLR 2020. paper\nXiaoran Xu, Wei Feng, Yunsheng Jiang, Xiaohui Xie, Zhiqing Sun, Zhi-Hong Deng.\n  Efficient Probabilistic Logic Reasoning with Graph Neural Networks. ICLR 2020. paper\nYuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi, Le Song.\n  Recommender Systems   Graph Convolutional Neural Networks for Web-Scale Recommender Systems. KDD 2018. paper\nRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, Jure Leskovec.\n  Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks. NIPS 2017. paper\nFederico Monti, Michael M. Bronstein, Xavier Bresson.\n  Graph Convolutional Matrix Completion. 2017. paper\nRianne van den Berg, Thomas N. Kipf, Max Welling.\n  STAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender Systems. IJCAI 2019. paper\nJiani Zhang, Xingjian Shi, Shenglin Zhao, Irwin King.\n  Binarized Collaborative Filtering with Distilling Graph Convolutional Networks. IJCAI 2019. paper\nHaoyu Wang, Defu Lian, Yong Ge.\n  Graph Contextualized Self-Attention Network for Session-based Recommendation. IJCAI 2019. paper\nChengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, Xiaofang Zhou.\n  Session-based Recommendation with Graph Neural Networks. AAAI 2019. paper\nShu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan.\n  Geometric Hawkes Processes with Graph Convolutional Recurrent Neural Networks. AAAI 2019. paper\nJin Shang, Mingxuan Sun.\n  Knowledge-aware Graph Neural Networks with Label Smoothness Regularization for Recommender Systems. KDD 2019. paper\nHongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao, Wenjie Li, Zhongyuan Wang.\n  Exact-K Recommendation via Maximal Clique Optimization. KDD 2019. paper\nYu Gong, Yu Zhu, Lu Duan, Qingwen Liu, Ziyu Guan, Fei Sun, Wenwu Ou, Kenny Q. Zhu.\n  KGAT: Knowledge Graph Attention Network for Recommendation. KDD 2019. paper\nXiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua.\n  Knowledge Graph Convolutional Networks for Recommender Systems. WWW 2019. paper\nHongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, Minyi Guo.\n  Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems. WWW 2019. paper\nQitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao, Guihai Chen.\n  Graph Neural Networks for Social Recommendation. WWW 2019. paper\nWenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, Dawei Yin.\n  Memory Augmented Graph Neural Networks for Sequential Recommendation. AAAI 2020. paper\nChen Ma, Liheng Ma, Yingxue Zhang, Jianing Sun, Xue Liu, Mark Coates.\n  Revisiting Graph based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach. AAAI 2020. paper\nLei Chen, Le Wu, Richang Hong, Kun Zhang, Meng Wang.\n  Inductive Matrix Completion Based on Graph Neural Networks. ICLR 2020. paper\nMuhan Zhang, Yixin Chen.\n  Computer Vision   Graph Neural Networks for Object Localization. ECAI 2006. paper\nGabriele Monfardini, Vincenzo Di Massa, Franco Scarselli, Marco Gori.\n  Learning Human-Object Interactions by Graph Parsing Neural Networks. ECCV 2018. paper\nSiyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, Song-Chun Zhu.\n  Learning Conditioned Graph Structures for Interpretable Visual Question Answering. NeurIPS 2018. paper\nWill Norcliffe-Brown, Efstathios Vafeias, Sarah Parisot.\n  Symbolic Graph Reasoning Meets Convolutions. NeurIPS 2018. paper\nXiaodan Liang, Zhiting Hu, Hao Zhang, Liang Lin, Eric P. Xing.\n  Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering. NeurIPS 2018. paper\nMedhini Narasimhan, Svetlana Lazebnik, Alexander Schwing.\n  Structural-RNN: Deep Learning on Spatio-Temporal Graphs. CVPR 2016. paper\nAshesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena.\n  Relation Networks for Object Detection. CVPR 2018. paper\nHan Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, Yichen Wei.\n  Learning Region features for Object Detection. ECCV 2018. paper\nJiayuan Gu, Han Hu, Liwei Wang, Yichen Wei, Jifeng Dai.\n  The More You Know: Using Knowledge Graphs for Image Classification. CVPR 2017. paper\nKenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta.\n  Understanding Kin Relationships in a Photo. TMM 2012. paper\nSiyu Xia, Ming Shao, Jiebo Luo, Yun Fu.\n  Graph-Structured Representations for Visual Question Answering. CVPR 2017. paper\nDamien Teney, Lingqiao Liu, Anton van den Hengel.\n  Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition. AAAI 2018. paper\nSijie Yan, Yuanjun Xiong, Dahua Lin.\n  Dynamic Graph CNN for Learning on Point Clouds. CVPR 2018. paper\nYue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, Justin M. Solomon.\n  PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. CVPR 2018. paper\nCharles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas.\n  3D Graph Neural Networks for RGBD Semantic Segmentation. CVPR 2017. paper\nXiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, Raquel Urtasun.\n  Iterative Visual Reasoning Beyond Convolutions. CVPR 2018. paper\nXinlei Chen, Li-Jia Li, Li Fei-Fei, Abhinav Gupta.\n  Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs. CVPR 2017. paper\nMartin Simonovsky, Nikos Komodakis.\n  Situation Recognition with Graph Neural Networks. ICCV 2017. paper\nRuiyu Li, Makarand Tapaswi, Renjie Liao, Jiaya Jia, Raquel Urtasun, Sanja Fidler.\n  Deep Reasoning with Knowledge Graph for Social Relationship Understanding. IJCAI 2018. paper\nZhouxia Wang, Tianshui Chen, Jimmy Ren, Weihao Yu, Hui Cheng, Liang Lin.\n  I Know the Relationships: Zero-Shot Action Recognition via Two-Stream Graph Convolutional Networks and Knowledge Graphs. AAAI 2019. paper\nJunyu Gao, Tianzhu Zhang, Changsheng Xu.\n  more  Graph CNNs with Motif and Variable Temporal Block for Skeleton-based Action Recognition. AAAI 2019. paper\nYu-Hui Wen, Lin Gao, Hongbo Fu, Fang-Lue Zhang, Shihong Xia.\n  Multi-Label Image Recognition with Graph Convolutional Networks. CVPR 2019. paper\nZhao-Min Chen, Xiu-Shen Wei, Peng Wang, Yanwen Guo.\n  Spatial-Aware Graph Relation Network for Large-Scale Object Detection. CVPR 2019. paper\nHang Xu, Chenhan Jiang, Xiaodan Liang, Zhenguo Li.\n  GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation. CVPR 2019. paper\nXinhong Ma, Tianzhu Zhang, Changsheng Xu.\n  Mind Your Neighbours: Image Annotation With Metadata Neighbourhood Graph Co-Attention Networks. CVPR 2019. paper\nJunjie Zhang, Qi Wu, Jian Zhang, Chunhua Shen, Jianfeng Lu.\n  Attentive Relational Networks for Mapping Images to Scene Graphs. CVPR 2019. paper\nMengshi Qi, Weijian Li, Zhengyuan Yang, Yunhong Wang, Jiebo Luo.\n  Knowledge-Embedded Routing Network for Scene Graph Generation. CVPR 2019. paper\nTianshui Chen, Weihao Yu, Riquan Chen, Liang Lin.\n  Auto-Encoding Scene Graphs for Image Captioning. CVPR 2019. paper\nXu Yang, Kaihua Tang, Hanwang Zhang, Jianfei Cai.\n  Learning to Cluster Faces on an Affinity Graph. CVPR 2019. paper\nLei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy, Dahua Lin.\n  Learning a Deep ConvNet for Multi-label Classification with Partial Labels. CVPR 2019. paper\nThibaut Durand, Nazanin Mehrasa, Greg Mori.\n  Graph Convolutional Label Noise Cleaner: Train a Plug-and-play Action Classifier for Anomaly Detection. CVPR 2019. paper\nJia-Xing Zhong, Nannan Li, Weijie Kong, Shan Liu, Thomas H. Li, Ge Li.\n  Learning Actor Relation Graphs for Group Activity Recognition. CVPR 2019. paper\nJianchao Wu, Limin Wang, Li Wang, Jie Guo, Gangshan Wu.\n  ABC: A Big CAD Model Dataset For Geometric Deep Learning. CVPR 2019. paper\nSebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, Daniele Panozzo.\n  Neighbourhood Watch: Referring Expression Comprehension via Language-guided Graph Attention Networks. CVPR 2019. paper\nPeng Wang, Qi Wu, Jiewei Cao, Chunhua Shen, Lianli Gao, Anton van den Hengel.\n  Graph-Based Global Reasoning Networks. CVPR 2019. paper\nYunpeng Chen, Marcus Rohrbach, Zhicheng Yan, Shuicheng Yan, Jiashi Feng, Yannis Kalantidis.\n  Linkage Based Face Clustering via Graph Convolution Network. CVPR 2019. paper\nZhongdao Wang, Liang Zheng, Yali Li, Shengjin Wang.\n  Fast Interactive Object Annotation with Curve-GCN. CVPR 2019. paper\nHuan Ling, Jun Gao, Amlan Kar, Wenzheng Chen, Sanja Fidler.\n  Semantic Graph Convolutional Networks for 3D Human Pose Regression. CVPR 2019. paper\nLong Zhao, Xi Peng, Yu Tian, Mubbasir Kapadia, Dimitris N. Metaxas.\n  Neural Task Graphs: Generalizing to Unseen Tasks from a Single Video Demonstration. CVPR 2019. paper\nDe-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, Animesh Garg, Li Fei-Fei, Silvio Savarese, Juan Carlos Niebles.\n  Graphonomy: Universal Human Parsing via Graph Transfer Learning. CVPR 2019. paper\nKe Gong, Yiming Gao, Xiaodan Liang, Xiaohui Shen, Meng Wang, Liang Lin.\n  Learning Context Graph for Person Search. CVPR 2019. paper\nYichao Yan, Qiang Zhang, Bingbing Ni, Wendong Zhang, Minghao Xu, Xiaokang Yang.\n  Occlusion-Net: 2D/3D Occluded Keypoint Localization Using Graph Networks. CVPR 2019. paper\nN. Dinesh Reddy, Minh Vo, Srinivasa G. Narasimhan.\n  MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment. CVPR 2019. paper\nDa Zhang, Xiyang Dai, Xin Wang, Yuan-Fang Wang, Larry S. Davis.\n  Context-Aware Visual Compatibility Prediction. CVPR 2019. paper\nGuillem Cucurull, Perouz Taslakian, David Vazquez.\n  Graph Attention Convolution for Point Cloud Semantic Segmentation. CVPR 2019. paper\nLei Wang, Yuchun Huang, Yaolin Hou, Shenman Zhang, Jie Shan.\n  An Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition. CVPR 2019. paper\nChenyang Si, Wentao Chen, Wei Wang, Liang Wang, Tieniu Tan.\n  Actional-Structural Graph Convolutional Networks for Skeleton-based Action Recognition. CVPR 2019. paper\nMaosen Li, Siheng Chen, Xu Chen, Ya Zhang, Yanfeng Wang, Qi Tian.\n  Graph Convolutional Tracking. CVPR 2019. paper\nJunyu Gao, Tianzhu Zhang, Changsheng Xu.\n  Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition. CVPR 2019. paper\nLei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu.\n  Skeleton-Based Action Recognition With Directed Graph Neural Networks. CVPR 2019. paper\nLei Shi, Yifan Zhang, Jian Cheng, Hanqing Lu.\n  Neural Module Networks. CVPR 2016. paper\nJacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein.\n  LatentGNN: Learning Efficient Non-local Relations for Visual Recognition. ICML 2019. paper\nSongyang Zhang, Shipeng Yan, Xuming He.\n  Graph Convolutional Gaussian Processes. ICML 2019. paper\nIan Walker, Ben Glocker.\n  GEOMetrics: Exploiting Geometric Structure for Graph-Encoded Objects. ICML 2019. paper\nEdward J. Smith, Scott Fujimoto, Adriana Romero, David Meger.\n  Learning Cross­‐modal Context Graph Networks for Visual Grounding. AAAI 2020. paper\nYongfei Liu, Bo Wan, Xiaodan Zhu, Xuming He.\n  Zero­‐Shot Sketch-based Image Retrieval via Graph Convolution Network. AAAI 2020. paper\nZhaolong Zhang, Yuejie Zhang, Rui Feng, Tao Zhang, Weiguo Fan.\n  Hybrid Graph Neural Networks for Crowd Counting. AAAI 2020. paper\nAo Luo, Fan Yang, Xin Li, Dong Nie, Zhicheng Jiao, Shangchen Zhou, Hong Cheng.\n  Learning Graph Convolutional Network for Skeleton-­‐based Human Action Recognition by Neural Searching. AAAI 2020. paper\nWei Peng, Xiaopeng Hong, Haoyu Chen, Guoying Zhao.\n  STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits. AAAI 2020. paper\nUttaran Bhattacharya, Trisha Mittal, Rohan Chandra, Tanmay Randhavane, Aniket Bera, Dinesh Manocha.\n  Relation‐Aware Pedestrian Attribute Recognition with Graph Convolutional Networks. AAAI 2020. paper\nZichang Tan, Yang Yang, Jun Wan, Stan Li.\n  Deep Generative Probabilistic Graph Neural Networks for Scene Graph Generation. AAAI 2020. paper\nMahmoud Khademi, Oliver Schulte.\n  Zero-­‐shot Ingredient Recognition by Multi-­‐Relational Graph Convolutional Network. AAAI 2020. paper\nJingjing Chen, Liang-Ming Pan, Zhi-Peng Wei, Xiang Wang, Chong-Wah Ngo,Tat-Seng Chua.\n  Location-aware Graph Convolutional Networks for Video Question Answering. AAAI 2020. paper\nDeng Huang, Peihao Chen, Runhao Zeng, Qing Du, Mingkui Tan, Chuang Gan.\n  Facial Action Unit Intensity Estimation via Semantic Correspondence Learning with Dynamic Graph Convolution. AAAI 2020. paper\nFan Yingruo, Jacqueline C.K. Lam, Victor Li.\n  Reasoning with Heterogeneous Graph Alignment for Video Question Answering. AAAI 2020. paper\nPin Jiang, Yahong Han.\n  Multi-Label Classification with Label Graph Superimposing. AAAI 2020. paper\nYa Wang, Dongliang He, Fu Li, Xiang Long, Zhichao Zhou, Jinwen Ma, Shilei Wen.\n  Part-Level Graph Convolutional Network for Skeleton-Based Action Recognition. AAAI 2020. paper\nLinjiang Huang, Yan Huang, Wanli Ouyang, Liang Wang.\n  SOGNet: Scene Overlap Graph Network for Panoptic Segmentation. AAAI 2020. paper\nYibo Yang, Hongyang Li, Xia Li, Qijie Zhao, Jianlong Wu, Zhouchen Lin.\n  Universal-RCNN: Universal Object Detector via Transferable Graph R-CNN. AAAI 2020. paper\nHang Xu, Linpu Fang, Xiaodan Liang, Wenxiong Kang, Zhenguo Li.\n  Abstract Diagrammatic Reasoning with Multiplex Graph Networks. ICLR 2020. paper\nDuo Wang, Mateja Jamnik, Pietro Lio.\n   Natural Language Processing   Conversation Modeling on Reddit using a Graph-Structured LSTM. TACL 2018. paper\nVicky Zayats, Mari Ostendorf.\n  Learning Graphical State Transitions. ICLR 2017. paper\nDaniel D. Johnson.\n  Multiple Events Extraction via Attention-based Graph Information Aggregation. EMNLP 2018. paper\nXiao Liu, Zhunchen Luo, Heyan Huang.\n  Recurrent Relational Networks. NeurIPS 2018. paper\nRasmus Palm, Ulrich Paquet, Ole Winther.\n  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks. ACL 2015. paper\nKai Sheng Tai, Richard Socher, Christopher D. Manning.\n  Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling. EMNLP 2017. paper\nDiego Marcheggiani, Ivan Titov.\n  Graph Convolutional Networks with Argument-Aware Pooling for Event Detection. AAAI 2018. paper\nThien Huu Nguyen, Ralph Grishman.\n  Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks. NAACL 2018. paper\nDiego Marcheggiani, Joost Bastings, Ivan Titov.\n  Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks. 2018. paper\nLinfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian, Daniel Gildea.\n  Graph Convolution over Pruned Dependency Trees Improves Relation Extraction. EMNLP 2018. paper\nYuhao Zhang, Peng Qi, Christopher D. Manning.\n  N-ary relation extraction using graph state LSTM. EMNLP 18. paper\nLinfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.\n  A Graph-to-Sequence Model for AMR-to-Text Generation. ACL 2018. paper\nLinfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.\n  Graph-to-Sequence Learning using Gated Graph Neural Networks. ACL 2018. paper\nDaniel Beck, Gholamreza Haffari, Trevor Cohn.\n  Cross-Sentence N-ary Relation Extraction with Graph LSTMs. TACL. paper\nNanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau Yih.\n  Sentence-State LSTM for Text Representation. ACL 2018. paper\nYue Zhang, Qi Liu, Linfeng Song.\n  End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures. ACL 2016. paper\nMakoto Miwa, Mohit Bansal.\n  Graph Convolutional Encoders for Syntax-aware Neural Machine Translation. EMNLP 2017. paper\nJoost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, Khalil Sima\u0026rsquo;an.\n  Semi-supervised User Geolocation via Graph Convolutional Networks. ACL 2018. paper\nAfshin Rahimi, Trevor Cohn, Timothy Baldwin.\n  Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering. COLING 2018. paper\nDaniil Sorokin, Iryna Gurevych.\n  Graph Convolutional Networks for Text Classification. AAAI 2019. paper\nLiang Yao, Chengsheng Mao, Yuan Luo.\n  more  Constructing Narrative Event Evolutionary Graph for Script Event Prediction. IJCAI 2018. paper\nZhongyang Li, Xiao Ding, Ting Liu.\n  Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks. ACL 2019. paper\nShikhar Vashishth, Manik Bhandari, Prateek Yadav, Piyush Rai, Chiranjib Bhattacharyya, Partha Talukdar\n  PaperRobot: Incremental Draft Generation of Scientific Ideas. ACL 2019. paper\nQingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal, Yi Luan.\n  Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network. ACL 2019. paper\nSunil Kumar Sahu, Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou.\n  Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension. ACL 2019. paper\nDaesik Kim, Seonhoon Kim, Nojun Kwak.\n  Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs. ACL 2019. paper\nMing Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou.\n  Dynamically Fused Graph Network for Multi-hop Reasoning. ACL 2019. paper\nYunxuan Xiao, Yanru Qu, Lin Qiu, Hao Zhou, Lei Li, Weinan Zhang, Yong Yu.\n  Cognitive Graph for Multi-Hop Reading Comprehension at Scale. ACL 2019. paper\nMing Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang.\n  Joint Type Inference on Entities and Relations via Graph Convolutional Networks. ACL 2019. paper\nChangzhi Sun, Yeyun Gong, Yuanbin Wu, Ming Gong, Daxing Jiang, Man Lan, Shiliang Sun1, Nan Duan.\n  Attention Guided Graph Convolutional Networks for Relation Extraction. ACL 2019. paper\nZhijiang Guo, Yan Zhang, Wei Lu.\n  GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction. ACL 2019. paper\nTsu-Jui Fu, Peng-Hsuan Li, Wei-Yun Ma.\n  Graph Neural Networks with Generated Parameters for Relation Extraction. ACL 2019. paper\nHao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Tat-seng Chua, Maosong Sun.\n  Generating Logical Forms from Graph Representations of Text and Entities. ACL 2019. paper\nPeter Shaw, Philip Massey, Angelica Chen, Francesco Piccinno, Yasemin Altun.\n  Matching Article Pairs with Graphical Decomposition and Convolutions. ACL 2019. paper\nBang Liu, Di Niu, Haojie Wei, Jinghong Lin, Yancheng He, Kunfeng Lai, Yu Xu.\n  Representing Schema Structure with Graph Neural Networks for Text-to-SQL Parsing. ACL 2019. paper\nBen Bogin, Matt Gardner, Jonathan Berant.\n  Coherent Comment Generation for Chinese Articles with a Graph-to-Sequence Model. ACL 2019. paper\nWei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu sun.\n  GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification. ACL 2019. paper\nJie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun.\n  Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution. ACL 2019. paper\nYinchuan Xu, Junlin Yang.\n  Structured Neural Summarization. ICLR 2019. paper\nPatrick Fernandes, Miltiadis Allamanis, Marc Brockschmidt.\n  Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks. NAACL 2019. paper\nNingyu Zhang, Shumin Deng, Zhanlin Sun, Guanying Wang, Xi Chen, Wei Zhang, Huajun Chen.\n  Text Generation from Knowledge Graphs with Graph Transformers. NAACL 2019. paper\nRik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, Hannaneh Hajishirzi.\n  Question Answering by Reasoning Across Documents with Graph Convolutional Networks. NAACL 2019. paper\nNicola De Cao, Wilker Aziz, Ivan Titov.\n  BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering. NAACL 2019. paper\nYu Cao, Meng Fang, Dacheng Tao.\n  GraphIE: A Graph-Based Framework for Information Extraction. NAACL 2019. paper\nYujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, Regina Barzilay.\n  Graph Convolution for Multimodal Information Extraction from Visually Rich Documents. NAACL 2019. paper\nXiaojing Liu, Feiyu Gao, Qiong Zhang, Huasha Zhao.\n  Structural Neural Encoders for AMR-to-text Generation. NAACL 2019. paper\nMarco Damonte, Shay B. Cohen.\n  Abusive Language Detection with Graph Convolutional Networks. NAACL 2019. paper\nPushkar Mishra, Marco Del Tredici, Helen Yannakoudakis, Ekaterina Shutova.\n  Learning Graph Pooling and Hybrid Convolutional Operations for Text Representations. WWW 2019. paper\nHongyang Gao, Yongjun Chen, Shuiwang Ji.\n  Graph­‐based Transformer with Cross-candidate Verification for Semantic Parsing. AAAI 2020. paper\nBo Shao, Yeyun Gong, Weizhen Qi, Guihong Cao, Jianshu Ji, Xiaola Lin.\n  Efficient Multi-Person Pose Estimation with Provable Guarantees. AAAI 2020. paper\nShaofei Wang, Konrad Paul Kording, Julian Yarkony.\n  Graph Transformer for Graph-to-Sequence Learning. AAAI 2020. paper\nDeng Cai, Wai Lam.\n  Multi-­‐label Patent Categorization with Non-­‐local Attention-­‐based Graph Convolutional Network. AAAI 2020. paper\nPingjie Tang, Meng Jiang, Bryan (Ning) Xia, Jed Pitera, Jeff Welser, Nitesh Chawla.\n  Multi-task Learning for Metaphor Detection with Graph Convolutional Neural Networks and Word Sense Disambiguation. AAAI 2020. paper\nDuong Minh Le, My Thai and Thien Huu Nguyen.\n  Schema-Guided Multi-Domain Dialogue State Tracking with Graph Attention Neural Networks. AAAI 2020. paper\nLu Chen, Boer Lv, Chi Wang, Su Zhu, Bowen Tan, Kai Yu.\n  GraphER: Token-Centric Entity Resolution with Graph Convolutional Neural Networks. AAAI 2020. paper\nBing Li, Wei Wang, Yifang Sun, Linhan Zhang, Muhammad Asif Ali, Yi Wang.\n  CFGNN:Cross Flow Graph Neural Networks for Question Answering on Complex Tables. AAAI 2020. paper\nXuanyu Zhang.\n   Generation   Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation. NeurIPS 2018. paper\nJiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, Jure Leskovec.\n  Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders. NeurIPS 2018. paper\nTengfei Ma, Jie Chen, Cao Xiao.\n  Learning deep generative models of graphs. ICLR Workshop 2018. paper\nYujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, Peter Battaglia.\n  MolGAN: An implicit generative model for small molecular graphs. 2018. paper\nNicola De Cao, Thomas Kipf.\n  GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models. ICML 2018. paper\nJiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, Jure Leskovec.\n  NetGAN: Generating Graphs via Random Walks. ICML 2018. paper\nAleksandar Bojchevski, Oleksandr Shchur, Daniel Zügner, Stephan Günnemann.\n  Graphite: Iterative Generative Modeling of Graphs. ICML 2019. paper\nAditya Grover, Aaron Zweig, Stefano Ermon.\n  Generative Code Modeling with Graphs. ICLR 2019. paper\nMarc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt, Oleksandr Polozov.\n  Efficient Graph Generation with Graph Recurrent Attention Networks. NeurIPS 2019. paper\nRenjie Liao, Yujia Li, Yang Song, Shenlong Wang, Will Hamilton, David Duvenaud, Raquel Urtasun, Richard Zemel.\n  Graph Normalizing Flows. NeurIPS 2019. paper\nJenny Liu, Aviral Kumar, Jimmy Ba, Jamie Kiros, Kevin Swersky.\n  Conditional Structure Generation through Graph Variational Generative Adversarial Nets. NeurIPS 2019. paper\nCarl Yang, Peiye Zhuang, Wenhan Shi, Alan Luu, Pan Li.\n  GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation. ICLR 2020. paper\nChence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, Jian Tang.\n  Combinatorial Optimization   Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search. NeurIPS 2018. paper\nZhuwen Li, Qifeng Chen, Vladlen Koltun.\n  Learning a SAT Solver from Single-Bit Supervision. ICLR 2019. paper\nDaniel Selsam, Matthew Lamm, Benedikt Bünz, Percy Liang, Leonardo de Moura, David L. Dill.\n  A Note on Learning Algorithms for Quadratic Assignment with Graph Neural Networks. PADL 2017. paper\nAlex Nowak, Soledad Villar, Afonso S. Bandeira, Joan Bruna.\n  Attention Solves Your TSP, Approximately. 2018. paper\nWouter Kool, Herke van Hoof, Max Welling.\n  Learning to Solve NP-Complete Problems - A Graph Neural Network for Decision TSP. AAAI 2019. paper\nMarcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Luis Lamb, Moshe Vardi.\n  DAG-GNN: DAG Structure Learning with Graph Neural Networks. ICML 2019. paper\nYue Yu, Jie Chen, Tian Gao, Mo Yu.\n  Exact Combinatorial Optimization with Graph Convolutional Neural Networks. NeurIPS 2019. paper\nMaxime Gasse, Didier Chetelat, Nicola Ferroni, Laurent Charlin, Andrea Lodi.\n  Approximation Ratios of Graph Neural Networks for Combinatorial Problems. NeurIPS 2019. paper\nRyoma Sato, Makoto Yamada, Hisashi Kashima.\n  Adversarial Attack   Adversarial Attacks on Neural Networks for Graph Data. KDD 2018. paper\nDaniel Zügner, Amir Akbarnejad, Stephan Günnemann.\n  Adversarial Attack on Graph Structured Data. ICML 2018. paper\nHanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, Le Song.\n  Adversarial Examples on Graph Data: Deep Insights into Attack and Defense. IJCAI 2019. paper\nHuijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu, Liming Zhu.\n  Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective. IJCAI 2019. paper\nKaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, Xue Lin.\n  Robust Graph Convolutional Networks Against Adversarial Attacks. KDD 2019. paper\nDingyuan Zhu, Ziwei Zhang, Peng Cui, Wenwu Zhu.\n  Certifiable Robustness and Robust Training for Graph Convolutional Networks. KDD 2019. paper\nDaniel Zügner, Stephan Günnemann.\n  Adversarial Attacks on Node Embeddings via Graph Poisoning. ICML 2019. paper\nAleksandar Bojchevski, Stephan Günnemann.\n  Adversarial Attacks on Graph Neural Networks via Meta Learning. ICLR 2019. paper\nDaniel Zügner, Stephan Günnemann.\n  PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks. ICLR 2019. paper\nJan Svoboda, Jonathan Masci, Federico Monti, Michael Bronstein, Leonidas Guibas.\n  Certifiable Robustness to Graph Perturbations. NeurIPS 2019. paper\nAleksandar Bojchevski, Stephan Günnemann.\n  A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning. NeurIPS 2019. paper\nXuanqing Liu, Si Si, Jerry Zhu, Yang Li, Cho-Jui Hsieh.\n  Graph Clustering   Attributed Graph Clustering: A Deep Attentional Embedding Approach. IJCAI 2019. paper\nChun Wang, Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Chengqi Zhang.\n  Attributed Graph Clustering via Adaptive Graph Convolution. IJCAI 2019. paper\nXiaotong Zhang, Han Liu, Qimai Li, Xiao-Ming Wu.\n  Graph Classification   Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing. ICML 2018. paper\nDavide Bacciu, Federico Errica, Alessio Micheli.\n  Semi-Supervised Graph Classification: A Hierarchical Graph Perspective. WWW 2019. paper\nJia Li, Yu Rong, Hong Cheng, Helen Meng, Wenbing Huang, Junzhou Huang.\n  DDGK: Learning Graph Representations for Deep Divergence Graph Kernels. WWW 2019. paper\nRami Al-Rfou, Dustin Zelle, Bryan Perozzi.\n  Unsupervised Inductive Graph-Level Representation Learning via Graph-Graph Proximity. IJCAI 2019. paper\nYunsheng Bai, Hao Ding, Yang Qiao, Agustin Marinovic, Ken Gu, Ting Chen, Yizhou Sun, Wei Wang.\n  Motif-matching based Subgraph-level Attentional Convolution Network for Graph Classification. AAAI 2020. paper\nHao Peng, Jianxin Li, Qiran Gong, Yuanxing Ning, Senzhang Wang, Lifang He.\n  InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. ICLR 2020. paper\nFan-Yun Sun, Jordan Hoffman, Vikas Verma, Jian Tang.\n  A Fair Comparison of Graph Neural Networks for Graph Classification. ICLR 2020. paper\nFederico Errica, Marco Podda, Davide Bacciu, Alessio Micheli.\n  Reinforcement Learning   NerveNet: Learning Structured Policy with Graph Neural Networks. ICLR 2018. paper\nTingwu Wang, Renjie Liao, Jimmy Ba, Sanja Fidler.\n  Structured Dialogue Policy with Graph Neural Networks. ICCL 2018. paper\nLu Chen, Bowen Tan, Sishan Long, Kai Yu.\n  Action Schema Networks: Generalised Policies with Deep Learning. AAAI 2018. paper\nSam Toyer, Felipe Trevizan, Sylvie Thiébaux, Lexing Xie.\n  Relational inductive bias for physical construction in humans and machines. CogSci 2018. paper\nJessica B. Hamrick, Kelsey R. Allen, Victor Bapst, Tina Zhu, Kevin R. McKee, Joshua B. Tenenbaum, Peter W. Battaglia.\n  Relational Deep Reinforcement Learning. arxiv 2018. paper\nVinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia.\n  Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning. NAACL 2019. paper\nPrithviraj Ammanabrolu, Mark O. Riedl.\n  Learning Transferable Graph Exploration. NeurIPS 2019. paper\nHanjun Dai, Yujia Li, Chenglong Wang, Rishabh Singh, Po-Sen Huang, Pushmeet Kohli.\n  Multi-Agent Game Abstraction via Graph Attention Neural Network. AAAI 2020. paper\nYong Liu, Weixun Wang, Yujing Hu, Jianye Hao, Xingguo Chen, Yang Gao.\n  Graph Convolutional Reinforcement Learning. ICLR 2020. paper\nJiechuan Jiang, Chen Dun, Tiejun Huang, Zongqing Lu.\n  Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation. ICLR 2020. paper\nYu Chen, Lingfei Wu, Mohammed J. Zaki.\n  Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs. ICLR 2020. paper\nAditya Paliwal, Felix Gimeno, Vinod Nair, Yujia Li, Miles Lubin, Pushmeet Kohli, Oriol Vinyals.\n  Traffic Network   Spatiotemporal Multi‐Graph Convolution Network for Ride-hailing Demand Forecasting. AAAI 2019. paper\nXu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, Yan Liu.\n  Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. AAAI 2019. paper\nShengnan Guo, Youfang Lin, Ning Feng, Chao Song, Huaiyu Wan.\n  Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. arxiv 2018. paper\nZhiyong Cui, Kristian Henrickson, Ruimin Ke, Yinhai Wang.\n  Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. IJCAI 2018. paper\nBing Yu, Haoteng Yin, Zhanxing Zhu.\n  Origin-Destination Matrix Prediction via Graph Convolution: a New Perspective of Passenger Demand Modeling. KDD 2019. paper\nYuandong Wang, Hongzhi Yin, Hongxu Chen, Tianyu Wo, Jie Xu, Kai Zheng.\n  Predicting Path Failure In Time-Evolving Graphs. KDD 2019. paper\nJia Li, Zhichao Han, Hong Cheng, Jiao Su, Pengyun Wang, Jianfeng Zhang, Lujia Pan.\n  Stochastic Weight Completion for Road Networks using Graph Convolutional Networks. ICDE 2019. paper\nJilin Hu, Chenjuan Guo, Bin Yang, Christian S. Jensen.\n  STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting. IJCAI 2019. paper\nLei Bai, Lina Yao, Salil.S Kanhere, Xianzhi Wang, Quan.Z Sheng.\n  Graph WaveNet for Deep Spatial-Temporal Graph Modeling. IJCAI 2019. paper\nZonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Chengqi Zhang.\n  Social-BiGAT: Multimodal Trajectory Forecasting using Bicycle-GAN and Graph Attention Networks. NeurIPS 2019. paper\nVineet Kosaraju, Amir Sadeghian, Roberto Martín-Martín, Ian Reid, Hamid Rezatofighi, Silvio Savarese.\n  GMAN: A Graph Multi-­‐Attention Network for Traffic Prediction. AAAI 2020. paper\nChuanpan Zheng, Xiaoliang Fan, Cheng Wang, Jianzhong Qi.\n  Few-shot and Zero-shot Learning   Few-Shot Learning with Graph Neural Networks. ICLR 2018. paper\nVictor Garcia, Joan Bruna.\n  Prototype Propagation Networks (PPN) for Weakly-supervised Few-shot Learning on Category Graph. IJCAI 2019. paper\nLu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Lina Yao, Chengqi Zhang.\n  Edge-labeling Graph Neural Network for Few-shot Learning. CVPR 2019. paper\nJongmin Kim, Taesup Kim, Sungwoong Kim, Chang D. Yoo.\n  Generating Classification Weights with GNN Denoising Autoencoders for Few-Shot Learning. CVPR 2019. paper\nSpyros Gidaris, Nikos Komodakis.\n  Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs. CVPR 2018. paper\nXiaolong Wang, Yufei Ye, Abhinav Gupta.\n  Rethinking Knowledge Graph Propagation for Zero-Shot Learning. CVPR 2019. paper\nMichael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P. Xing.\n  Multi-Label Zero-Shot Learning with Structured Knowledge Graphs. CVPR 2018. paper\nChung-Wei Lee, Wei Fang, Chih-Kuan Yeh, Yu-Chiang Frank Wang.\n  Learning to Propagate for Graph Meta-Learning. NeurIPS 2019. paper\nLU LIU, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang.\n  Attribute Propagation Network for Graph Zero-­shot Learning. AAAI 2020. paper\nLU LIU, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang.\n  Graph Few-­‐shot Learning via Knowledge Transfer. AAAI 2020. paper\nHuaxiu Yao, Chuxu Zhang, Ying WEI, Meng Jiang, Suhang Wang, Junzhou Huang, Nitesh Chawla, Zhenhui Li.\n  FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES. ICLR 2020. paper\nJatin Chauhan, Deepak Nathani, Manohar Kaul.\n  Program Representation   Learning to Represent Programs with Graphs. ICLR 2018. paper\nMiltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi.\n  Open Vocabulary Learning on Source Code with a Graph-Structured Cache. ICML 2019. paper\nMilan Cvitkovic, Badal Singh, Anima Anandkumar.\n  Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks. NeurIPS 2019. paper\nYaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, Yang Liu.\n  LambdaNet: Probabilistic Type Inference using Graph Neural Networks. ICLR 2020. paper\nJiayi Wei, Maruth Goyal, Greg Durrett, Isil Dillig.\n  HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS. ICLR 2020. paper\nElizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, Ke Wang.\n  Social Network   Link Prediction Based on Graph Neural Networks. NeurIPS 2018. paper\nMuhan Zhang, Yixin Chen.\n  DeepInf: Social Influence Prediction with Deep Learning. KDD 2018. paper\nJiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, Jie Tang.\n  Characterizing and Forecasting User Engagement with In-app Action Graph: A Case Study of Snapchat. KDD 2019. paper\nYozen Liu, Xiaolin Shi, Lucas Pierce, Xiang Ren.\n  MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. KDD 2019. paper\nHao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, Wen Su.\n  Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding. KDD 2019. paper\nNinghao Liu, Qiaoyu Tan, Yuening Li, Hongxia Yang, Jingren Zhou, Xia Hu.\n  Encoding Social Information with Graph Convolutional Networks for Political Perspective Detection in News Media. ACL 2019. paper\nChang Li, Dan Goldwasser.\n  Fine-grained Event Categorization with Heterogeneous Graph Convolutional Networks. IJCAI 2019. paper\nHao Peng, Jianxin Li, Qiran Gong, Yangqiu Song, Yuanxing Ning, Kunfeng Lai, Philip S. Yu.\n  Graph Convolutional Networks with Markov Random Field Reasoning for Social Spammer Detection. AAAI 2020. paper\nYongji Wu, Defu Lian, Yiheng Xu, Le Wu, Enhong Chen.\n  Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks. AAAI 2020. paper\nTian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong, Junzhou Huang.\n  Graph Matching   Deep Graph Matching Consensus. ICLR 2020. paper\nMatthias Fey, Jan E. Lenssen, Christopher Morris, Jonathan Masci, Nils M. Kriege.\n  ","excerpt":"License To the extent possible under law, GNNPapers has waived all copyright and related or …","ref":"/docs/machinelearning/models/graph-nn/papers/collections/","title":"Collections"},{"body":"\n1. What is attention?  Attention is a vector, often the outputs of dense layer using softmax function.  2. What is an attention model?   The attention model plugs a context vector into the gap between encoder and decoder.\n  According to the schematic below, blue represents encoder and red represents decoder\n  The context vector takes all cells’ outputs as input to compute the probability distribution of source language words for each single word decoder wants to generate.\n  Image Source\n3. Why do we use attention model?   Attention model allows machine translator to look over all the information the original sentence holds, then generate the proper word according to current word it works on and the context.\n  It can even allow translator to zoom in or out (focus on local or global features).\n  By utilizing attention model, it is possible for decoder to capture somewhat global information rather than solely to infer based on one hidden state.   4. How to solve a Human-Machine Translation problem using a attention-based bidirectional LSTM?   Try the Human-Machine Translation exercise on Coursera\n(Translating human readable dates into machine readable dates)\nCoursera notebook\n  Take a look at my notebook\n   Read more?   A Brief Overview of Attention Mechanism, Medium\n  How Does Attention Work in Encoder-Decoder Recurrent Neural Networks\n  ","excerpt":"1. What is attention?  Attention is a vector, often the outputs of dense layer using softmax …","ref":"/docs/machinelearning/models/deep-learning/sequence-models/attention-model/","title":"Attention Model"},{"body":"\n conda Sreamlit cheat sheet Data science cheatsheet A lof of cheatsheets  ","excerpt":"\n conda Sreamlit cheat sheet Data science cheatsheet A lof of cheatsheets  ","ref":"/docs/swiss-knives/cheatsheets/","title":"Cheatsheets"},{"body":"\n A Simple Introduction to Naive Bayes  ","excerpt":"\n A Simple Introduction to Naive Bayes  ","ref":"/docs/machinelearning/models/-naive-bayes/","title":"Naive Bayes"},{"body":" Probability – making the best estimate of the chance in an uncertain world\n Table of Contents  Basic Probability Compound Probability Probability Distributions Frequentist Inference Bayesian Inference Regression Analysis References  Basic Probability  Probability theory is the mathematical framework that allows us to analyze chance events in a logically sound manner.\n  Chance Events Expectation: provides a measure of centrality    The expectation of a random variable is a number that attempts to capture the center of that random variable\u0026rsquo;s distribution. It can be interpreted as the long-run average of many independent samples from the given distribution. More precisely, it is defined as the probability-weighted sum of all possible values in the random variable\u0026rsquo;s support,    Variance: quantifies the spread of that random variable\u0026rsquo;s distribution  Compound Probability  Set: a collection of compound events  Set Identities   Permutations: different ordered sequences Combinations: different unordered sets Conditional Probability: a conditional probability is the probability of an event, given some other event has already occurred.  It allows us to account for information we have about our system of interest Mathematically, computing a conditional probability amounts to shrinking our sample space to a particular event. A visual explaination     For example, we might expect the probability that it will rain tomorrow (in general) to be smaller than the probability it will rain tomorrow given that it is cloudy today. This latter probability is a conditional probability, since it accounts for relevant information that we possess.\n Probability Distributions  A probability distribution specifies the relative likelihoods of all possible outcomes.\n   Random Variables: Formally, a random variable is a function that assigns a real number to each outcome in the probability space.\n  Discrete Probability Distributions\n  Univariate Discrete Distributions\n  The Central Limit Theorem (CLT) states that the sample mean of a sufficiently large number of i.i.d. random variables is approximately normally distributed. The larger the sample, the better the approximation.\n  Frequentist Inference  Bootstrap provides a convenient way to estimate properties of an estimator via resampling.  Bayesian Inference  Bayesian inference techniques specify how one should update one’s beliefs upon observing data.\n Regression Analysis  Analysis of Variance (ANOVA) is a statistical method for testing whether groups of data have the same mean. ANOVA generalizes the t-test to two or more groups by comparing the sum of square error within and between groups.   References  Probability by Khan Academy Harvard Statistics 110: Probability A visual introduction to probability and statistics  pdf version   Python for probability statistics and machine-learning Probabilistic reasoning and statistical analysis in TensorFlow The story of every distribution - Discrete Distributions  ","excerpt":"Probability – making the best estimate of the chance in an uncertain world\n Table of Contents  Basic …","ref":"/docs/math/intro/probability/","title":"Probablity"},{"body":"","excerpt":"","ref":"/docs/computer_science/","title":"Computer Science"},{"body":"\nHow to build a beautiful website using Pelican?\n What is Pelican? Pelican is a Python library that lets you generate static websites from templates.\n1. Installation # Install pelican pip install pelican markdown # Choose a name for your project (e.g. pelican-website) and directory for your site (fishingbird) mkdir -p pelican-website/fishingbird cd pelican-website/fishingbird 2. Generate the initial boilerplate pelican-quickstart \u0026gt; Where do you want to create your new web site? [.] \u0026gt; What will be the title of this web site? Fishing Birds \u0026gt; Who will be the author of this web site? j \u0026gt; What will be the default language of this web site? [en] \u0026gt; Do you want to specify a URL prefix? e.g., https://example.com (Y/n) n \u0026gt; Do you want to enable article pagination? (Y/n) Y \u0026gt; How many articles per page do you want? [10] \u0026gt; What is your time zone? [Europe/Paris] \u0026gt; Do you want to generate a tasks.py/Makefile to automate generation and publishing? (Y/n) Y \u0026gt; Do you want to upload your website using FTP? (y/N) n \u0026gt; Do you want to upload your website using SSH? (y/N) n \u0026gt; Do you want to upload your website using Dropbox? (y/N) n \u0026gt; Do you want to upload your website using S3? (y/N) n \u0026gt; Do you want to upload your website using Rackspace Cloud Files? (y/N) n \u0026gt; Do you want to upload your website using GitHub Pages? (y/N) y 3. Add content in a markdown file vim content/fish.md 4. Generate your site pelican content 5. Preview your site pelican --listen # Navigate to http://localhost:8000/ in your browser. 6. Optional: 6.1 How to add a theme? # Choose a path for to clone pelican-themes directory (e.g. pelican-website/) git clone --recursive https://github.com/getpelican/pelican-themes ../pelican-themes # Add a theme in the pelicanconf.py of your site (e.g. fishingbird/pelicanconf.py) THEME = '../pelican-themes/bootstrap2' 6.2 How to add theme as git module # Add a .gitmodules and a directory `themes/` in the project perclican-website git submodule add git@github.com:getpelican/pelican-themes.git themes # Commit git commit -am \u0026#39;Add theme as a submodule\u0026#39; # Check whether the themes is listed as a submodule git submodule status \u0026#39;565dc8959ad2573c4a9245eaaec73916c782f6d9 theme (heads/master)\u0026#39; # Check available themes cd themes git submodule status # Initialize the bootstrap2 theme git submodule init bootstrap2 # Update the submodule git submodule update cd .. # Add the theme path in the pelicanconf.py of your site (e.g. fishingbird/pelicanconf.py) THEME = '../themes/bootstrap2' 7. Publish to Github project page vim ./fishingbird/pelicanconf.py # Add your SITE_URL in pelicanconf.py SITEURL = \u0026#39;https://dj-application.github.io/pelican-website/\u0026#39;cd fishingbird pelican content -o output -s pelicanconf.py ghp-import output -n git push origin gh-pages 8. What are the files?   ├── License.md ├── README.md ├── fishingbird │ ├── Makefile │ ├── content │ ├── output │ ├── pelicanconf.py │ ├── publishconf.py │ └── tasks.py ├── requirements.txt └── themes   Makefile - This file defines make commands that perform the most important tasks like generating your site and starting a local http server. pelicanconf.py - This file contains settings to customize your site. publishconf.py - This file contains settings that are only used when you’re ready to publish to the web. content/ - This folder is where you’ll put the templates and files that will be translated into the content of your site. output/ - This folder might not exist until you convert your content into html. By default, the translated website lands here.  9. Reference  Tutorials Documentation python-livereload Using LiveReload with Pelican Getting Started with Pelican on Github Pages migrated to Pelican and GitHub pages  ","excerpt":"How to build a beautiful website using Pelican?\n What is Pelican? Pelican is a Python library that …","ref":"/docs/web/pelican-website/","title":"Pelican Website"},{"body":"\nActor-Critic Methods  Actor-critic agent is an agent that uses function approximation to learn a policy and value function Employ two NN  One for Actor One for Policy   Advantages:  more stable than value-based agents Need fewer samples than policy-based agents    Generalized Advantage Estimation (GAE) DDPG  Deep Deterministic Policy Gradient DDPG is a DQN method for continuous action spaces DDPG uses a replay buffer and soft updates to the target networks  Read  Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic High-Dimensional Continuous Control Using Generalized Advantage Estimation  ","excerpt":"\nActor-Critic Methods  Actor-critic agent is an agent that uses function approximation to learn a …","ref":"/docs/machinelearning/courses/reinforcement-learning/c3-policy/p04-actor-critic/","title":"Actor-Critic Methods"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/reinforcement-learning/c2-value/","title":"Value-based"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/reinforcement-learning/","title":"Reinforcement Learning"},{"body":"\nPrediction Problem  An approach that can be used to estimate the state-value function. Given a policy, how might the agent estimate the value function for that policy?   Gridworld Example  The agent has a policy in mind, it follows the policy to collect a lot of episodes. For each state, to figure out which action is best, the agent can look for which action tended to result in the most cumulative reward.  Monte Carlo Methods. Image from Udacity nd893\nMonte Carlo (MC) Methods  Even though the underlying problem involves a great degree of randomness, we can infer useful information that we can trust just by collecting a lot of samples. The equiprobable random policy is the stochastic policy where - from each state - the agent randomly selects from the set of available actions, and each action is selected with equal probability.  MC prediction (MDP)  Monte Carlo (MC) approaches to the prediction problem The agent can take a bad policy, like the equiprobable random policy, use it to collect some episodes, and then consolidate the results to arrive at a better policy. Algorithms that solve the prediction problem determine the value function $v_{\\pi}$ or $q_{\\pi}$ Each occurrence of the state-action pair $s$, $a$ ($s \\in S$, $a \\in A$) in an episode is called a visit to $s$, $a$.  Two types of MC prediction   Every-visit MC Prediction\n Average the returns following all visits to each state-action pair, in all episodes.    First-visit MC Prediction\n For each episode, we only consider the first visit to the state-action pair.    Q-table  When working with finite MDPs, we can estimate the action-value function $q_{\\pi}$ corresponding to a policy $\\pi$ in a table. This table has one row for each state and one column for each action. The entry in the $s$-th row and $a$-th column contains the agent\u0026rsquo;s estimate for expected return that is likely to follow, if the agent starts in state $s$, selects action $a$, and then henceforth follows the policy $\\pi$.  MC Prediction, image from Udacity nd893\nFirst-visit vs Every-visit  Both the first-visit and every-visit method are guaranteed to converge to the true action-value function, as the number of visits to each state-action pair approaches infinity. As long as the agent gets enough experience with each state-action pair, the value function estimate will be pretty close to the true value. In the case of first-visit MC, convergence follows from the Law of Large Numbers, and the details are covered in section 5.1 of the textbook. Differences  Every-visit MC is biased, whereas first-visit MC is unbiased (see Theorems 6 and 7). Initially, every-visit MC has lower mean squared error (MSE), but as more episodes are collected, first-visit MC attains better MSE (see Corollary 9a and 10a, and Figure 4). Ref - Reinforcement Learning with Replacing Eligibility Traces    Greedy Policy  A greedy policy means the agent constantly performs the action that is believed to yield the highest expected reward. With respect to an action-value function estimate $Q$ if for every state $s \\in S$, it is guaranteed to select an action $a \\in A(s)$ such that $a = argmax_{a \\in A_{s}}Q(s,a)$. The greedy action: the selected action $a$.  greedy-policy, image from Udacity nd893\nEpsilon-Greedy Policy  Greedy Policy:  always selects the greedy action   Epsilon-Greedy Policy:  most likely selects the greedy action, with probability $1 - \\epsilon$ picks up other non-greedy actions with small, but non-zero probability $\\epsilon$  the agent selects an action uniformly at random from the set of available (non-greedy AND greedy actions) allowing the agent to explore other probabilities   when $\\epsilon = 0$, the policy becomes a greedy policy when $\\epsilon = 1$, the policy becomes an epsilon-greedy policy that is equivalent to the equiprobable random policy  where, from each state, each action is equally likely to be selected      Control Problem  Estimates the optimal policy  MC Control Method  Algorithms designed to solve the control problem determine the optimal policy $\\pi_*$ from interaction with the environment. The MCC method uses alternating rounds of policy evaluation and improvement to recover the optimal policy.  Two Steps of MC Control  Policy Evaluation: determine the action-value function of the policy Policy Improvement: improve the policy by changing it to be $\\epsilon$-greedy with respect to the Q-table  MC Control, image from Udacity nd893\nExploration-Exploitation Dilemma  In early episodes,  the agent\u0026rsquo;s knowledge is quite limited (and potentially flawed). So, it is highly likely that actions estimated to be non-greedy by the agent are in fact better than the estimated greedy action. With this in mind, a successful RL agent cannot act greedily at every time step (that is, it cannot always exploit its knowledge) in order to discover the optimal policy, it has to continue to refine the estimated return for all state-action pairs (in other words, it has to continue to explore the range of possibilities by visiting every state-action pair). That said, the agent should always act somewhat greedily, towards its goal of maximizing return as quickly as possible. This motivated the idea of an $\\epsilon$-greedy policy. Therefore, the agent begins its interaction with the environment by favoring exploration over exploitation. After all, when the agent knows relatively little about the environment\u0026rsquo;s dynamics, it should distrust its limited knowledge and explore, or try out various strategies for maximizing return.   At later time steps, it makes sense to favor exploitation over exploration, where the policy gradually becomes more greedy with respect to the action-value function estimate.  After all, the more the agent interacts with the environment, the more it can trust its estimated action-value function.    Solution: Early Sampling and Late Specialization One potential solution to this dilemma is implemented by gradually modifying the value of $\\epsilonϵ$ when constructing $\\epsilon$-greedy policies.\n The best starting policy is the equiprobable random policy, as it is equally likely to explore all possible actions from each state.  $\\epsilon_i \u0026gt;0$ for all time steps $i$   The later policy becomes more greedy  $\\epsilon_i$ decays to $0$ in the limit as the time step $i$ approaches infinity ($lim_{i \\to \\infty}\\epsilon_i = 0$) To ensure convergence to the optimal policy, we could set $ \\epsilon_i = \\frac 1 i $    Greedy in the limit with Infinite Exploration (GLIE)  A condition to guarantee that MC control converges to the optimal policy $\\pi$  every state-action pair $s$, $a$ (for all $s \\in S$ and $a \\in A_{(s)}$) is visited infinitely many times the policy converges to a policy that is greedy with respect to the action-value function estimate $Q$   The condition ensures that  the agent continues to explore for all time steps the agent gradually exploits more (and explore less)    Setting $\\epsilon$ in Practice Even though convergence is not guaranteed by the mathematics, you can often get better results by either:\n using fixed $\\epsilon$ letting $\\epsilon_i$ decay to a small positive number, like $0.1$.  If you get late in training and $\\epsilon$ is really small, you pretty much want the agent to have already converged to the optimal policy, as it will take way too long otherwise for it to test out new actions! An example of how the value of $\\epsilon$ was set in the famous DQN algorithm by reading the Methods section of Human-level control through deep reinforcement learning     The behavior policy during training was epsilon-greedy with epsilon annealed linearly from 1.0 to 0.1 over the first million frames, and fixed at 0.1 thereafter.\n Incremental Mean  Update the Q-table after every episode. Use the updated Q-table to improve the policy. That new policy could then be used to generate the next episode, and so on. There are two relevant tables  $Q-Q$ table: with a row for each state and a column for each action . The entry corresponding to state and action is denoted $Q(s,a)$. $N$ table: keeps track of the number of first visits we have made to each state-action pair   The number of episodes the agent collects is equal to $num_episodes$ The algorithm proceeds by looping over the following steps to improve the policy after every episode  The policy $\\pi$ is improved to be $\\epsilon$-greedy with respect to $Q$, and the agent use $\\pi$ to collect an episode. $N$ is updated to count the total number of first visits to each state action pair The estimates in $Q$ are updated to take into account the most recent information    Incremental Mean, image from Udacity nd893\nIncremental Mean Function, image from Udacity nd893\nConstant-alpha MC control  uses a constant step-size parameter $\\alpha$  Update equation   After each episode finishes, the Q-table is modified using the update equation:\n $Q(S_t, A_t) \\leftarrow (1-a)Q(S_t, A_t) + \\alpha G_t$ $G_t := \\sum_{s=t+1}^{T}\\gamma^{s-t-1}R_s$ is the return at timestep $t$ $Q(S_t,A_t)$ is the entry in the Q-table corresponding to state $S_t$ and action $A_t$.    The main idea behind the update equation\n $Q(S_t,A_t)$ contains the agent\u0026rsquo;s estimate for the expected return if the environment is in state $S_t$ and the agent selects action $A_t$ If the return $G_t$ is not equal to $Q(S_t,A_t)$, then we push the value of $Q(S_t,A_t)$ to make it agree slightly more with the return The magnitude of the change that we make to $Q(S_t,A_t)$ is controlled by $\\alpha \u0026gt; 0$    Step-size Parameter $\\alpha$  The step-size parameter $\\alpha$ must satisfy 0 \u0026lt; $\\alpha$ ≤1.  Higher values of $\\alpha$ will result in faster learning, but values of $\\alpha$ that are too high can prevent MC control from converging to $\\pi_*$ Smaller values for $\\alpha$ encourage the agent to consider a longer history of returns when calculating the action-value function estimate.   Increasing the value of $\\alpha$ ensures that the agent focuses more on the most recently sampled returns.   However,be careful to not set the value of $\\alpha$ too close to 1. This is because very large values can keep the algorithm from converging to the optimal policy $\\pi_*$   Boundary values   If $\\alpha = 0$, then the action-value function estimate is never updated by the agent. Meaning, the agent never learns If $\\alpha = 1$, then the final value estimate for each state-action pair is always equal to the last return that was experienced by the agent (after visiting the pair).  Constant-alpha\nExcercise OpenAI Gym: BlackJackEnv  Read Example 5.1 in textbook Github monte-carlo excercise  Optimal Policy and State-Value Function in Blackjack (Sutton and Barto, 2017)\nOpenAI Gym: FrozenLake-v0  Walking on the ice  The agent is rewarded for finding a walkable path to a goal tile. The solutions are ranked according to the number of episodes needed to find the solution.    Image from gismeteo\nTest Greedy Policy Which of the values for epsilon yields an epsilon-greedy policy where the agent has the possibility of selecting a greedy action, but might select a non-greedy action instead? In other words, how might you guarantee that the agent selects each of the available (greedy and non-greedy) actions with nonzero probability?\n   $\\epsilon = 0$    $\\epsilon = 0.3$    $\\epsilon = 0.5$    $\\epsilon = 1$     As long as epsilon \u0026gt; 0, the agent has nonzero probability of selecting any of the available actions. So the answer is 2,3,4\n Update Q-table What is the new value for the entry in the Q-table corresponding to state 1 and action right? MC Control Method Quiz from Udacity nd893\n Answer: 6 + 0.1(8-2) = 6.2 Current estimate: 6 Current reward: 8 $\\alpha = 0.1$\n ","excerpt":"Prediction Problem  An approach that can be used to estimate the state-value function. Given a …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f04-monte-carlo/","title":"Monte Carlo"},{"body":"\nDensity-Based Clustering  Blog by Joshua Poduska  ","excerpt":"\nDensity-Based Clustering  Blog by Joshua Poduska  ","ref":"/docs/machinelearning/models/clustering/density/","title":"Density-Based"},{"body":"\nConverting pdf to image on Linux # Syntax # pdftoppm {input.pdf} {output.file} -png # Example pdftoppm Bulldog.pdf Bulldog.pdf -png # each page from the PDF file is converted to Bulldog.pdf-1.png, Bulldog.pdf-2.png  For a large number of pdf files  # Step 1 - PDF to IMAGE / PNG format # for p in *.pdf do pdftoppm \u0026#34;$p\u0026#34; \u0026#34;$p\u0026#34; -png done \nConverting image to pdf on Linu mkdir out # convert convert out-Bulldog.pdf-1.png Bulldog.pdf-2.png Bulldog.pdf-3.png out/final-Bulldog.pdf # open  xdg-open out/final-Bulldog.pdf  For a large number of images  # Step 2 - IMAGE / PNG to PDF format # mkdir output for i in *.pdf do b=\u0026#34;$i\u0026#34; convert $b-?.png \u0026#34;output/$b\u0026#34; done \nCompress files if needed zip -r -e /tmp/Bulldog.pdf /tmp/output  -r : Recurse into directories -e : Password protect our zip file /tmp/project-invoices.pdf: Zip file name /tmp/output: Path/folder name to zip and compress everything for ease of use  Ref  How to convert pdf to image on Linux command line  Image source\n","excerpt":"Converting pdf to image on Linux # Syntax # pdftoppm {input.pdf} {output.file} -png # Example …","ref":"/docs/swiss-knives/converter-pdf-image/","title":"Converter PDF - Image"},{"body":"\nConditioning – the soul of statistics\n Independence means multiplication Newton–Pepys problem: another gambling problem 🎲 Which of the following three propositions has the greatest chance of success?\n A. Six fair dice are tossed independently and at least one “6” appears. B. Twelve fair dice are tossed independently and at least two “6”s appear. C. Eighteen fair dice are tossed independently and at least three “6”s appear.  Conditional probability 🏄‍♂️  How do you update probabilities/beliefs/uncertainty based on new evidence? Do you update in a coherent, consistent, and logical manner? $P_{(A | B)} = \\frac{P_{(A \\bigcap B)}}{P_{(B)}}$ if $P_{(B)} \u0026gt; 0$ $P_{(A \\bigcap B)} = P_{(B)} P_{(A|B)} = P_{(A)} P_{(B|A)}$ $P_{(A | B)} = \\frac{P_{(B | A)}P_{(A)}}{P_{(B)}}$ ❤️   Ref  Newton–Pepys problem  ","excerpt":"Conditioning – the soul of statistics\n Independence means multiplication Newton–Pepys problem: …","ref":"/docs/math/intro/probability/s110_l04_conditional_probability/","title":"Conditional Probability"},{"body":"","excerpt":"","ref":"/docs/data/","title":"Data"},{"body":"\ntabula-py  tabula-py is a simple Python wrapper of tabula-java Installation  pip install tabula-py  Usage  import tabula # Read pdf into list of DataFrame df = tabula.read_pdf(\u0026#34;test.pdf\u0026#34;, pages=\u0026#39;all\u0026#39;) # Read remote pdf into list of DataFrame df2 = tabula.read_pdf(\u0026#34;https://github.com/tabulapdf/tabula-java/raw/master/src/test/resources/technology/tabula/arabic.pdf\u0026#34;) # convert PDF into CSV file tabula.convert_into(\u0026#34;test.pdf\u0026#34;, \u0026#34;output.csv\u0026#34;, output_format=\u0026#34;csv\u0026#34;, pages=\u0026#39;all\u0026#39;) # convert all PDFs in a directory tabula.convert_into_by_batch(\u0026#34;input_directory\u0026#34;, output_format=\u0026#39;csv\u0026#39;, pages=\u0026#39;all) \nR Tabulizer  GitHub Installation  install.packages(\u0026#34;tabulizer\u0026#34;)  Usage  library(\u0026#34;tabulizer\u0026#34;) f \u0026lt;- system.file(\u0026#34;examples\u0026#34;, \u0026#34;data.pdf\u0026#34;, package = \u0026#34;tabulizer\u0026#34;) out1 \u0026lt;- extract_tables(f) str(out1) ","excerpt":"tabula-py  tabula-py is a simple Python wrapper of tabula-java Installation  pip install tabula-py …","ref":"/docs/swiss-knives/converter-pdf-table/","title":"Converter PDF - Table"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/course/debugging/","title":"Debugging"},{"body":"\n Course Link\n 1. Iterate with JavaScript While Loops  The first type of loop we will learn is called a while loop because it runs \u0026ldquo;while\u0026rdquo; a specified condition is true and stops once that condition is no longer true.\n // Setup var myArray = []; var i = 5; while (i \u0026gt;=0){ myArray.push(i); i--; } 2. Iterate with JavaScript For Loops // Setup var myArray = []; for (var i = 1; i \u0026lt; 6; i++){ myArray.push(i); } 3. Iterate Through an Array with a For Loop // Setup var myArr = [ 2, 3, 4, 5, 6]; // Only change code below this line var total = 0; for (var i= 0; i\u0026lt; myArr.length; i++){ total += myArr[i]; } 4. Nesting For Loops for (var i = 0; i \u0026lt; arr.length; i++) { for (var j = 0; j \u0026lt; arr[i].length; j++) { product *= arr[i][j]; } } 5. Iterate with JavaScript Do\u0026hellip;While Loops  Essentially, a do\u0026hellip;while loop ensures that the code inside the loop will run at least once  // Change the while loop in the code to a do...while loop so the loop will push only the number 10 to myArray, and i will be equal to 11 when your code has finished running. var myArray = []; var i = 10; do { myArray.push(i); i++; } while (i\u0026lt;5); 6. Replace Loops using Recursion  The recursive version of multiply breaks down like this. In the base case, where n \u0026lt;= 0, it returns 1. For larger values of n, it calls itself, but with n - 1. That function call is evaluated in the same way, calling multiply again until n \u0026lt;= 0. At this point, all the functions can return and the original multiply returns the answer.\nNote: Recursive functions must have a base case when they return without calling the function again (in this example, when n \u0026lt;= 0), otherwise they can never finish executing.\n function multiply(arr, n) { if (n \u0026lt;= 0) { return 1; } else { return multiply(arr, n - 1) * arr[n - 1]; } } // Setup var contacts = [ { \u0026#34;firstName\u0026#34;: \u0026#34;Akira\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Laine\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;0543236543\u0026#34;, \u0026#34;likes\u0026#34;: [\u0026#34;Pizza\u0026#34;, \u0026#34;Coding\u0026#34;, \u0026#34;Brownie Points\u0026#34;] }, { \u0026#34;firstName\u0026#34;: \u0026#34;Harry\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Potter\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;0994372684\u0026#34;, \u0026#34;likes\u0026#34;: [\u0026#34;Hogwarts\u0026#34;, \u0026#34;Magic\u0026#34;, \u0026#34;Hagrid\u0026#34;] }, { \u0026#34;firstName\u0026#34;: \u0026#34;Sherlock\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Holmes\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;0487345643\u0026#34;, \u0026#34;likes\u0026#34;: [\u0026#34;Intriguing Cases\u0026#34;, \u0026#34;Violin\u0026#34;] }, { \u0026#34;firstName\u0026#34;: \u0026#34;Kristian\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Vos\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;likes\u0026#34;: [\u0026#34;JavaScript\u0026#34;, \u0026#34;Gaming\u0026#34;, \u0026#34;Foxes\u0026#34;] } ]; function lookUpProfile(name, prop){ // Only change code below this line  for (var i =0; i \u0026lt;contacts.length; i++){ if (contacts[i].firstName == name){ for (var j = 0; j \u0026lt; contacts[i].length; j++){ if (j == prop){ return contacts[i][prop] } else { return \u0026#34;No such property\u0026#34; } } } else { return \u0026#34;No such contact\u0026#34; } // Only change code above this line }c } lookUpProfile(\u0026#34;Akira\u0026#34;, \u0026#34;likes\u0026#34;); ","excerpt":"Course Link\n 1. Iterate with JavaScript While Loops  The first type of loop we will learn is called …","ref":"/docs/coding/functional-coding/javascript/course/basics/loops/","title":"Loops"},{"body":"\nTools  scaden   Scaden is a deep-learning based algorithm for cell type deconvolution of bulk RNA-seq samples. It was developed at the DZNE Tübingen and the ZMNH in Hamburg. A pre-print describing the method is available at Biorxiv: Deep-learning based cell composition analysis from tissue expression profiles.\n ","excerpt":"\nTools  scaden   Scaden is a deep-learning based algorithm for cell type deconvolution of bulk …","ref":"/docs/healthcare/bioinfo/sc-rnaseq/","title":"Single-cell RNAseq"},{"body":"\nHaystack — Neural Question Answering At Scale  The performance of modern Question Answering Models (BERT, ALBERT \u0026hellip;) has seen drastic improvements within the last year enabling many new opportunities for accessing information more efficiently. However, those models are designed to find answers within rather small text passages. Haystack lets you scale QA models to large collections of documents! While QA is the focussed use case for haystack, we will soon support additional options to boost search (re-ranking, most-similar search \u0026hellip;).\nHaystack is designed in a modular way and lets you use any models trained with FARM or Transformers.\n Core Features  Powerful ML models: Utilize all latest transformer based models (BERT, ALBERT, RoBERTa \u0026hellip;) Modular \u0026amp; future-proof: Easily switch to newer models once they get published. Developer friendly: Easy to debug, extend and modify. Scalable: Production-ready deployments via Elasticsearch backend \u0026amp; REST API Customizable: Fine-tune models to your own domain \u0026amp; improve them continuously via user feedback  Cmponents  DocumentStore: Database storing the documents for our search. We recommend Elasticsearch, but have also more light-weight options for fast prototyping (SQL or In-Memory). Retriever: Fast, simple algorithm that identifies candidate passages from a large collection of documents. Algorithms include TF-IDF or BM25, custom Elasticsearch queries, and embedding-based approaches. The Retriever helps to narrow down the scope for Reader to smaller units of text where a given question could be answered. Reader: Powerful neural model that reads through texts in detail to find an answer. Use diverse models like BERT, RoBERTa or XLNet trained via FARM or Transformers on SQuAD like tasks. The Reader takes multiple passages of text as input and returns top-n answers with corresponding confidence scores. You can just load a pretrained model from Hugging Face\u0026rsquo;s model hub or fine-tune it to your own domain data. Finder: Glues together a Reader and a Retriever as a pipeline to provide an easy-to-use question answering interface. REST API: Exposes a simple API for running QA search, collecting feedback and monitoring requests Labeling Tool: Hosted version (Beta), Docker images (coming soon)  haystack\nQ\u0026amp;A\n","excerpt":"Haystack — Neural Question Answering At Scale  The performance of modern Question Answering Models …","ref":"/docs/machinelearning/nlp/nlp-tools/hay-stack/","title":"Haystack"},{"body":"\nLicense To the extent possible under law, awesome-community-detection has waived all copyright and related or neighboring rights to this work.\nTable of Contents  Matrix Factorization Deep Learning Label Propagation, Percolation and Random Walks Tensor Decomposition Spectral Methods Temporal Methods Cyclic Patterns Centrality and Cuts Physics Inspired Others Libraries  More Similar collections about graph classification, classification/regression tree, fraud detection, and gradient boosting papers with implementations.\n","excerpt":"License To the extent possible under law, awesome-community-detection has waived all copyright and …","ref":"/docs/machinelearning/models/graph-nn/papers/community-detection/","title":"Community Detection"},{"body":"","excerpt":"","ref":"/docs/data/visual-art/","title":"Visualization"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/models/graph-nn/","title":"Graph NN"},{"body":"","excerpt":"","ref":"/docs/machinelearning/models/optimization/","title":"Optimization"},{"body":"\nTypeError   TypeError: **init**\\ () takes 1 positional argument but 3 were given\n Example: bmi = calculate_bmi(heigh,weight) Reason: only position arguments were passed bmi = calculate_bmi(x,y) Solution: pass keyword arguments bmi = calculate_bmi(height=x, weight=y)    ","excerpt":"\nTypeError   TypeError: **init**\\ () takes 1 positional argument but 3 were given\n Example: bmi = …","ref":"/docs/coding/practices/error_collection/python/","title":"Python"},{"body":"\nLicense To the extent possible under law, Awesome NLP Paper Discussionshas waived all copyright and related or neighboring rights to this work.\nApril 7, 2020  Topic: Overview of recent work on: Indexing and Retrieval for Open Domain Question Answering Presenter: Yacine Jernite Discussion: Slides  March 24, 2020  Paper: Scaling Laws for Neural Language Models Authors: Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei Presenter: Teven Le Scao Discussion: Google doc paper tutorial  March 17, 2020  Paper: Representation Learning with Contrastive Predictive Coding Authors: Aaron van den Oord, Yazhe Li, Oriol Vinyals Presenter Patrick von Platen Discussion: Slides  March 10, 2020  Paper: Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference  Authors: R. Thomas McCoy, Ellie Pavlick, Tal Linzen Presenter: Victor Sanh Discussion: Slides  March 3, 2020  Paper: REALM: Retrieval-Augmented Language Model Pre-Training Authors: Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang Presenter: Joe Davison Discussion: Write-up  February 25, 2020  Paper: Adaptively Sparse Transformers Authors: Gonçalo M. Correia, Vlad Niculae, André F.T. Martins Presenter: Sasha Rush Discussion: Colab notebook  Planned Discussions March 31, 2020  Paper: Compositionality decomposed: how do neural networks generalise? Authors: Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni Presenter: Thomas Wolf  ","excerpt":"License To the extent possible under law, Awesome NLP Paper Discussionshas waived all copyright and …","ref":"/docs/machinelearning/nlp/nlp-papers/hugging-face/","title":"Hugging Face Paper Discussions"},{"body":" Flat is better than nested — The Zen of Python\n 1. How do you evaluate codes?  Time efficiency: Faster? Time complexity Space efficiency: Less memory intensive? More readable ?  2. What is big-O notation?  a fuzzy way for counting a big picture of the time efficiency of the code  3. How to measure the code performance using big-O?  Assignment statements and if statements that are only executed once regardless of the size of the problem are O(1). A simple “for” loop from 0 to n (with no internal loops), contributes O(n) (linear complexity); a nested loop of the same type (or bounded by the first loop parameter), gives O(n^2) (quadratic complexity); A loop in which the controlling parameter is divided by two at each step (and which terminates when it reaches 1), gives O(log n) (logarithmic complexity); A “while” loop may vary depends on the actual numbers of iterations it will run ( OK. It means as same as the for loop. That is to say, for all kinds of loops, we only care about the actual number of iterations that they’ve executed before they hit the upper bond). A loop with a not-O(1) execution inside, simply multiplies the complexity of the body of the loop, by the number of times the loop will execute. When dealing with multiple statements, add them up.  Rules:   Constants doesn\u0026rsquo;t matter\n  O(2N) = O(N)\n  O(5) = O(500) = O(1)\n  O (17NN) = O (NN)\n  Smaller terms doesn\u0026rsquo;t matter\n  O($N^2$ +50N +10) == O($N^2$)\n  O(1) \u0026lt; O(log n) \u0026lt; O( Sqrt(n) ) \u0026lt; O(n) \u0026lt; O(n log n) \u0026lt; O($n^2$) \u0026lt; O($n^3$) \u0026lt; O($2^n$)\n  4. What are the big-O notations from these ML techniques?  Linear: O(N) Sorting: O(nlogN)  5. BigO of various operations in current CPython Time Complexity\n6. References  Everything about big-o SVM Analysis RF Analysis Complete Beginner\u0026rsquo;s Guide to Big ONotation Big O Notation You (Probably) Don’t Need For-Loops Neural networks and Big(O) Back Prop Big-O cheatsheet  ","excerpt":"Flat is better than nested — The Zen of Python\n 1. How do you evaluate codes?  Time efficiency: …","ref":"/docs/computer_science/software-engineering/big-o/","title":"big-O"},{"body":"\nAbout Azure DevOps  Repo: a git repo (e.g. clone, fork etc) Pipeline Work Items (e.g. issue, epic ) Test Plan: more for large organization Artifacts: more for a small team  Create new feed and use in the pipelines    1. What is Azure Pipeline? Azure Pipelines is a cloud service that you can use to automatically build and test your code project and make it available to other users. It works with just about any language or project type.\nAzure Pipelines combines continuous integration (CI) and continuous delivery (CD) to constantly and consistently test and build your code and ship it to any target.\n    Continuous integration (CI) Continuous delivery (CD)     1 Automatically ensure you don\u0026rsquo;t ship broken code. Automatically deploy code to production.   2 Build faster by splitting test and build run Ensure deployment targets have latest code.   3 Run tests continually. Use tested code from CI process.   4 Increase code coverage.     2. Create an Azure Pipeline to build a GitHub repository  On GitHub  Register a GitHub account Create a new public repo (e.g. azure) and push an initial commit (e.g. README.md)   On Azure  Sign up an an Azure DevOps account Add an Azure DevOps organization Add a public Azure project In the project, navigate to the Pipiline page Select the GitHub repo azure Build a new pipeline following the tutorial    3. Customize your pipeline   Edit a yml file on Azure DevOps project/pipeline/Builds =\u0026gt; Commit and Run =\u0026gt; The yml file will be pushed to GitHub automatically\n  Push a new yml file to GitHub =\u0026gt; On Azure DevOps, select Existing Azure pipeline YAML file =\u0026gt; Select the yml on GitHub\n  4. Pipeline structures   Stage\n Major divisions in a pipeline By default, stages run sequentially e.g. build this app, run these tests, and deploy to pre-production    Job\n  Jobs can be run conditionally, and they may depend on earlier jobs.\n  A collection of steps to be run by an agent or on the server.\n    Step\n  A linear sequence of operations that make up a job\n  Each step runs in its own process on an agent and has access to the pipeline workspace on disk.\n  This means environment variables are not preserved between steps but filesystem changes are.\n    Variables\n  Hardcoded values can be added directly, or variable groups can be referenced.\n  Variables may be specified at the pipeline, stage, or job level.\n    Reference   Intro to Azure DevOps - Source Control, CI/CD, Automation\n  Azure Pipelines Doc\n Jobs Variables Pipelines-anaconda Run pipelines with Anaconda Continuous Builds for master branch and pull request Deploy a Python web app using CI/CD to Azure App Service    YAML schema reference\n Learn YAML in Y minutes    ","excerpt":"About Azure DevOps  Repo: a git repo (e.g. clone, fork etc) Pipeline Work Items (e.g. issue, epic ) …","ref":"/docs/cloud/azure/","title":"Azure"},{"body":"\n1. Set up Google Cloud Platform (GCP)  Go to Create service account key page Select project on top \u0026lsquo;pines1\u0026rsquo; Service account, my account JSON Provide authentication credentials to your application code Enable billing  export GOOGLE_APPLICATION_CREDENTIALS=\u0026#34;/home/pi/gcp/pines1-6e82e765805d.json\u0026#34; 2. Install GCP SDK Installing with apt-get for Debian and Ubuntu\nexport CLOUD_SDK_REPO=\u0026#34;cloud-sdk-$(lsb_release -c -s)\u0026#34; echo \u0026#34;deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPOmain\u0026#34; | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install google-cloud-sdk 3. Setup GCloud SDK gcloud init 4. Authorizing Cloud SDK tools Authorizing a service accounts\ngloud auth login gcloud auth application-default login gcloud auth list ","excerpt":"1. Set up Google Cloud Platform (GCP)  Go to Create service account key page Select project on top …","ref":"/docs/cloud/google/gcp_sdk/","title":"GCP SDK Setup"},{"body":"\n","excerpt":"","ref":"/docs/cloud/google/","title":"Google"},{"body":"\nHow to load csv files to colab?  From Github (Files \u0026lt; 25MB)  import pandas as pd url = \u0026#39;copied_raw_link\u0026#39; df1 = pd.read_csv(url)  From a local drive  from google.colab import files uploaded = files.upload() \nWhat is colab?  Colab (short for Colaboratory) is a free platform from Google that allows users to code in Python. Colab is essentially the Google Suite version of a Jupyter Notebook. Advantages of Colab over Jupyter include:  an easier installation of packages easy sharing of documents     How to save a colab notebook to GitHub? cmd/ctrl-shift-P In the dropdown menu, select 'Save a copy in GitHub' \nHow to use TensorFlow with GPU? demo code\nMore examples TensorFlow 2.0 + Keras\n References  3 Ways to Load CSV files into Colab Colab  ","excerpt":"How to load csv files to colab?  From Github (Files \u0026lt; 25MB)  import pandas as pd url = …","ref":"/docs/cloud/google/colab/","title":"Google Colab"},{"body":"\nCourse Link https://www.futurelearn.com/courses/managing-your-health-data Course Instructors :  David Pérez del Rey Sergio Paraiso Raúl Alonso-Calvo Edward Meinert  Course Notes  ","excerpt":"\nCourse Link https://www.futurelearn.com/courses/managing-your-health-data Course Instructors : …","ref":"/docs/healthcare/healthcare-data/","title":"Manage your own health data"},{"body":"\nHow to build a beautiful website using Hugo?\n What is Hugo? Hugo is one of the most popular open-source static site generators. With its amazing speed and flexibility, Hugo makes building websites fun again.\n1. Create two repos on your GitHub  Create a your-project (e.g. hugo-website) repository on GitHub.   This repository will contain Hugo’s content and other source files.\n  Create a yourusrname.github.io GitHub repository.   This is the repository that will contain the fully rendered version of your Hugo website.\n 2. Add website content in your-project (e.g. hugo-website) # Add a new repo `hugo-website`on your GitHub git clone git@github.com:yourusrname/hugo-website.git\u0026amp;\u0026amp; cd hugo-website git init # Add a theme (e.g. docsy) as a submodule git submodule add https://github.com/google/docsy.git themes/docsy echo \u0026#39;theme = \u0026#34;docsy\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml git submodule update --init --recursive # Commit in your repo git add . git commit -m \u0026#39;initial commit\u0026#39; \n3. Enable website search vim hugo-website/config.toml # Enable Lunr.js offline searchofflineSearch = trueRef\n4. Enable Emoji vim hugo-website/config.toml # Add enableEmoji = true\n5. Add resources using Hugo\u0026rsquo;s short codes  Short codes are simple snippets inside your content files calling built-in or custom templates.  6. Insert videos \u0026lt;div class=\u0026quot;parent\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;child\u0026quot; style=\u0026quot;position: relative; padding-bottom: 50%; height: 0; overflow: hidden;\u0026quot;\u0026gt; \u0026lt;iframe src=\u0026quot;https://gym.openai.com/videos/2019-10-21--mqt8Qj1mwo/BipedalWalker-v2/original.mp4\u0026quot; style=\u0026quot;position: absolute; top: 0; left: 0; width: 40%; height: 40%; border:0;\u0026quot; allowfullscreen title=\u0026quot;BipedalWalker-v2\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style=\u0026quot;position: relative; padding-bottom: 50%; height: 0; overflow: hidden;\u0026quot;\u0026gt; \u0026lt;iframe src=\u0026quot;https://gym.openai.com/videos/2019-10-21--mqt8Qj1mwo/MountainCarContinuous-v0/original.mp4\u0026quot; style=\u0026quot;position: absolute; top: 0; left: 0; width: 40%; height: 40%; border:0;\u0026quot; allowfullscreen title=\u0026quot;MountainCar\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 7. Deploy to yourusrname.github.io  Make sure your website works locally  hugo server open your browser to http://localhost:1313.   Prepare a deploy.sh file  vim ./deploy.sh # Write the below in ./deploy.shset -eprintf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34;# Build the project.#hugo #-t docsy # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;`hugo -t docsy# Go To Public foldercd public# Add changes to git.git add .# Commit changes.msg=\u0026#34;rebuilding site $(date)\u0026#34;if [ -n \u0026#34;$*\u0026#34; ]; then\tmsg=\u0026#34;$*\u0026#34;figit commit -m \u0026#34;$msg\u0026#34;# Push source and build repos.git push origin master Deploy your website to your yourusrname.githu.bio  git submodule add -b master git@github.com:yourusrname/yourusrname.github.io.git public ./deploy.sh \u0026#34;v0\u0026#34;  The public folder will be pushed to yourusrname.github.io Check your website yourusrname.github.io  Reference  Host on GitHub  Error  If you acidentally delete (e.g. rm -rf public) the folder which Hugo uses to place the rendered flies, you probably will encounter this error when you try to git push:  fatal: in unpopulated submodule 'public' Ref    # remove public dirctory rm -r public/ # remove files from the working tree and from the index git rm -r --cached public # re-add public as submodule  git submodule add -b master --force git@github.com:yourusrname/yourusrname.github.io.git public git submodule add -b master --force git@github.com:dujm/dujm.github.io.git public ","excerpt":"How to build a beautiful website using Hugo?\n What is Hugo? Hugo is one of the most popular …","ref":"/docs/web/hugo-website/","title":"Hugo Website"},{"body":" Statistics – the logic of uncertainty\n Read More  Statistics for Applications  StatQuest with Josh Starmer Statistics with R Specialization stat-cookbook  ","excerpt":" Statistics – the logic of uncertainty\n Read More  Statistics for Applications  StatQuest with Josh …","ref":"/docs/math/intro/statistics/","title":"Statistics"},{"body":"\nHow to convert a tab-deliminated file (.txt/.tsv) to a csv? 0. Open the terminal cd filedirectory 1. Convert file commas (,) to semi-colon (;) perl -pe \u0026#39;s/,/;/g\u0026#39; file1.txt \u0026gt; file2.txt 2. Conver tab (\\t) to comma(,) perl -pe \u0026#39;s/\\t/,/g\u0026#39; file2.txt \u0026gt; file3.csv \nHow to convert a csv to a tab-deliminated file (.txt/.tsv)? 1. Conver file tabs (\\t) to semi-colon(;) perl -pe \u0026#39;s/\\t/;/g\u0026#39; file3.csv \u0026gt;file2.csv 2. Conver comma (,) to tab (\\t) perl -pe \u0026#39;s/,/\\t/g\u0026#39; file2.csv \u0026gt; file1.txt ","excerpt":"How to convert a tab-deliminated file (.txt/.tsv) to a csv? 0. Open the terminal cd filedirectory 1. …","ref":"/docs/swiss-knives/converter-csv-txt/","title":"Converter CSV - TXT"},{"body":"\n1. How to write and display mathematical formulas code editors?   Jupyter notebook latex equations\n  List of mathematical formulas in markdown\n  Atom\n Open Atom =\u0026gt; Preference =\u0026gt; Install Install markdown-preview-plus Install mathjax-wrapper Atom Preview: Toggle LaTex Rendering     VScode: nothing\n  2. How to write and display a column vector on my github.io? 2.1) Add the following code to  If you use Jekyll =\u0026gt; Open _includes/mathjax.html  If you use Hugo =\u0026gt; Open themes/layouts/partials/mathjax.html   \u0026lt;script type=\u0026quot;text/x-mathjax-config\u0026quot;\u0026gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\u0026quot;\\\\(\u0026quot;,\u0026quot;\\\\)\u0026quot;] ], processEscapes: true } }); \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot; charset=\u0026quot;utf-8\u0026quot; src=\u0026quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026quot; \u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot; charset=\u0026quot;utf-8\u0026quot; src=\u0026quot;https://vincenttam.github.io/javascripts/MathJaxLocal.js\u0026quot; \u0026gt; \u0026lt;/script\u0026gt; \n2.2) Add the following line in the html layouts where I want to add formulas  If you use Jekyll =\u0026gt; Open _layouts/post.html or _layouts/page.html =\u0026gt; Add   {% include mathjax.html %}  If you use Hugo =\u0026gt; Open themes/layouts/partials/head.html  =\u0026gt; Add the below line before{{end}}   {{ partial \u0026quot;mathjax_support.html\u0026quot; . }} \n2.3) Test: Write a column vector in the new page(e.g. rendering.md)     github io Atom/VSCode I choose     $\\begin{bmatrix}1 \\\\2 \\end{bmatrix}$ good bad yes   $\\begin{bmatrix}1 \\2 \\end{bmatrix}$ bad good no   $\\begin{bmatrix}1 \\2 \\end{bmatrix}$ bad bad no    Reference\n3. How to write mathematic formulas in Markdown/Latex?    Category Symbol $input$     Greek Letters      $\\alpha, A$ \\alpha, A    $\\beta, B$ \\beta, B    $\\gamma$, $\\Gamma$ \\gamma, \\Gamma    $\\lambda$, $\\Lambda$ \\lambda,\\Lambda    $\\omega, \\Omega$ \\omega, \\Omega    $\\epsilon$, $\\varepsilon$ \\epsilon, varepsilon    $\\pi$, $\\Pi$ \\pi, \\Pi    $\\phi$, $\\Phi$, $\\varphi$ \\phi, \\Phi, \\varphi    $\\sigma$, $\\Sigma$ \\sigma, \\Sigma    $\\theta$, $\\vartheta$, $\\Theta$ \\theta, \\vartheta \\Theta    $\\mu$, $M$ \\mu, M    $\\nu$, $N$ \\nu N    $\\delta$, $\\Delta$ \\delta, \\Delta    $\\nabla$, $\\triangledown$, $\\triangle$, \\nabla, \\triangledown, \\triangle   Format     1) blackboard bold $\\Bbb {AI}$ \\Bbb {AI}   2) boldface $\\mathbf {AI}$ \\mathbf {AI}   3) calligraphic $\\mathcal {AI}$ \\mathcal {AI}   4) insert a thin space $x,y$, $xy$ x,y, xy   5) devider (e.g. set comprehension) $x\\mid x^2$ x\\mid x^2   6) symbol $\\star \\ast \\oplus \\circ \\bullet$ \\star \\ast \\oplus \\circ \\bullet        Operators      $\\cos$ \\cos    $\\sin$ \\sin    $\\lim_{x\\to c}$ \\lim_{x\\to c}    $\\exp$ \\exp    $\\to$ \\to    $\\infty$ \\infty    $\\ne$ \\ne    $\\ge \\circ \\le$ \\ge \\le    $\\sim$ \\sim    $\\approx$ \\approx    $\\equiv$ \\equiv    $\\bmod$ \\bmod    $\\times$ , $\\pm$ \\times, \\pm   Power and Indices      $k_{n+1}$ k_{n+1}    $n^2$ n^2    $n^{-2}$ n^{-2}    $k_n^2$ k_n^2   Fractions and Binomials      $\\frac{n!}{k!(n-k)!}$ \\frac{n!}{k!(n-k)!}    $\\binom{n}{k}$ \\binom{n}{k}    $\\frac{\\frac{x}{1}}{x - y}$ \\frac{\\frac{x}{1}}{x - y}    $^3/_7$ ^3/_7   Roots      $\\sqrt{k}$ \\sqrt{k}    $\\sqrt[n]{k}$ \\sqrt[n]{k}   Sums and Integrals      $\\sum_{i=1}^{10} t_i$ \\sum_{i=1}^{10} t_i    $\\int_0^\\infty \\mathrm{e}^{-x},\\mathrm{d}x$ \\int_0^\\infty \\mathrm{e}^{-x},\\mathrm{d}x    $\\sum$ \\sum    $\\prod$ \\prod    $\\coprod$ \\coprod    $\\in$ \\in    $\\notin$ \\notin    $\\varnothing$ \\varnothing    $\\bigoplus$ \\bigoplus    $\\bigotimes$ \\bigotimes    $\\bigodot$ \\bigodot    $\\bigcup$ \\bigcup    $\\bigcap$ \\bigcap    $\\biguplus$ \\biguplus    $\\bigsqcup$ \\bigsqcup    $\\bigvee$ \\bigvee    $\\bigwedge$ \\bigwedge    $\\int$ \\int    $\\oint$ \\oint    $\\iint$ \\iint    $\\iiint$ \\iiint    $\\idotsint$ \\idotsint    $\\sum_{\\substack{0\u0026lt;i\u0026lt;m, 0\u0026lt;j\u0026lt;n}} P(i, j)$ \\sum_{\\substack{0\u0026lt;i\u0026lt;m, 0\u0026lt;j\u0026lt;n}} P(i, j)    $\\int\\limits_a^b$ \\int\\limits_a^b    $a’$ $a^{\\prime}$ a’ a^{\\prime}    $a’’$ a’’    $\\hat{a}$ \\hat{a}    $\\bar{a}$ \\bar{a}    $\\grave{a}$ \\grave{a}    $\\acute{a}$ \\acute{a}    $\\dot{a}$ \\dot{a}    $\\ddot{a}$ \\ddot{a}    $\\not{a}$ \\not{a}    $\\mathring{a}$ \\mathring{a}    ${A}\\rightarrow{B} $ {A}\\rightarrow{B}    ${A}\\leftarrow{B}$ {A}\\leftarrow{B}    $\\overrightarrow{AB}$ \\overrightarrow{AB}    $\\overleftarrow{AB}$ \\overleftarrow{AB}    $a’’’$ a’’’    $\\overline{aaa}$ \\overline{aaa}    $\\check{a}$ \\check{a}    $\\vec{a}$ \\vec{a}    $\\underline{a}$ \\underline{a}    $\\color{red}x\\color{blue}y\\color{orange}z$ \\color{red}x\\color{blue}y\\color{orange}z    $\\pm$ \\pm    $\\mp$ \\mp    $\\int y \\mathrm{d}x$ \\int y \\mathrm{d}x    $,$ ,    $:$ :    $;$ ;    $!$ !    $\\int y, \\mathrm{d}x$ \\int y, \\mathrm{d}x    $\\dots$ \\dots    $\\ldots$ \\ldots    $\\cdot$ \\cdot    $\\cdots$ \\cdots    $\\vdots$ \\vdots    $\\ddots$ \\ddots   Brackets      $(\\overbrace{\u0026hellip;+r_{t-1}}^{\\require{cancel}\\bcancel{R^{\\rm past}_t}} + \\overbrace{r_{t}+\u0026hellip;}^{R^{\\rm future}_t})$ (\\overbrace{\u0026hellip;+r_{t-1}}^{\\require{cancel}\\bcancel{R^{\\rm past}_t}} + \\overbrace{r_{t}+\u0026hellip;}^{R^{\\rm future}_t})    $\\Biggl(\\biggl(\\Bigl(\\bigl((a)\\bigr)\\Bigr)\\biggr)\\Biggr)$ \\Biggl(\\biggl(\\Bigl(\\bigl((a)\\bigr)\\Bigr)\\biggr)\\Biggr)    $[a]$ [a]    ${a}$ {a}    $\\lvert f\\rvert$ \\lvert f\\rvert    $\\langle f \\rangle$ \\langle f \\rangle    $\\lfloor f \\rfloor$ \\lfloor f \\rfloor    $\\lceil f \\rceil$ \\lceil f \\rceil    $\\ulcorner f \\urcorner$ \\ulcorner f \\urcorner   Matrices      $\\begin{bmatrix}0\u0026amp;1 \\\\1\u0026amp;0 \\end{bmatrix}$    Arrays      $\\begin{array}{|cc|} a\u0026amp;b\\\\c\u0026amp;d\\end{array}$          $\\frac { \\begin{array}{|cc|} e\u0026amp;b\\\\f\u0026amp;d\\end{array} } { {\\begin{array}{|cc|} a\u0026amp;b\\\\c\u0026amp;d\\end{array} } }$     References  Collected by Archer Reilly Prevent MathJax from using the dollar sign as a delimiter, TEX Commands available in MathJax List of Greek letters and math symbols MathJax basic tutorial and quick reference Live equation editing MathJax doc Adding MathJax to a GitHub Pages Jekyll Blog readme2tex mimetex A big page alert: TEX Commands available in MathJax   ","excerpt":"1. How to write and display mathematical formulas code editors?   Jupyter notebook latex equations …","ref":"/docs/math/intro/render-math/","title":"Math Formulas"},{"body":"  Arduino\n  Raspberry Pi\n  Banana Pi\n  Orange pi\n  Coral\n  Jetson Nano\n  Sparkfun Edge\n  More IoT developer prototyping kits\n  ","excerpt":"  Arduino\n  Raspberry Pi\n  Banana Pi\n  Orange pi\n  Coral\n  Jetson Nano\n  Sparkfun Edge\n  More IoT …","ref":"/docs/computer_science/iot/development_board/","title":"Development Boards"},{"body":"\n  Coursera Link\n  Instructors\n Brian Innes (Developer Advocate, IBM Digital Business Group) Yianna Papadakis Kantos (Curriculum Specialist, IoT User Education, IBM Watson IoT)    My Notes\n  ","excerpt":"\n  Coursera Link\n  Instructors\n Brian Innes (Developer Advocate, IBM Digital Business Group) Yianna …","ref":"/docs/computer_science/iot/ibm-iot-course/","title":"IBM IoT Course"},{"body":"\nHow to assemble RPI Touch Screen LCD?  Raspberry Pi 7\u0026quot; Touch Screen LCD - Assembly\n    How to adjust the screen brightness? # Adjust brightness sudo sh -c 'echo 90 \u0026gt; /sys/class/backlight/rpi_backlight/brightness' \nHow to disable the screen saver? sudo apt-get install xscreensaver Go to GUI Preferences/Screensaver/DisplayMode/Dropdown/DisableScreenSaver \nHow to install virtual keyboard on RPI? sudo apt-get install matchbox-keyboard -y ","excerpt":"\nHow to assemble RPI Touch Screen LCD?  Raspberry Pi 7\u0026quot; Touch Screen LCD - Assembly\n    How to …","ref":"/docs/computer_science/iot/rpi-lcd-display/","title":"RPI Touch Screen LCD"},{"body":"\nHigh Peformance Computing  About distributing storage and processing over many processors. Not just hardware, but also software to manage the execution of the tasks on ha rdware  This is why we need the orchestration softwares. e.g. The AlphaGo distributed processing on many different GPUs.    Distributed Machine Learning  Different models can be trained in parallel using different subsets of the data, and then the results can be merged. The operation of a single but large model can be distributed over many processors.  e.g. A deep NN which have many layers, parts of it can be run on different processors working as a pipeline    Time and Space  Machine learning is not just a component in a product. Time and space sometimes are more important than accuracy  Time: a self-driving car in a real world only has limited amount of time to decide whether there is pedestrian on the road or not.  The accuracy of the recognizer becomes irrelevent when it can not decide fast enough.   Space: IoT devices have limited computing power.  Such systems may be making decisions on site or may just work as smart processors of the signal.      ","excerpt":"High Peformance Computing  About distributing storage and processing over many processors. Not just …","ref":"/docs/computer_science/hpc/","title":"HPC"},{"body":"\nMammoth Mammoth is designed to convert .docx documents, such as those created by Microsoft Word, Google Docs and LibreOffice, and convert them to HTML.\npip install mammoth # Generate Markdown mammoth document.docx --output-format=markdown ","excerpt":"\nMammoth Mammoth is designed to convert .docx documents, such as those created by Microsoft Word, …","ref":"/docs/swiss-knives/converter-docx-markdown/","title":"Converter .docx"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/reinforcement-learning/c3-policy/","title":"Policy-based"},{"body":"\nTemporal Difference (TD) Control  A class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic programming methods. Ref  TD vs MC Control  TD: update Q-table after every time step MC: update the Q-table after complete an entire episode of interaction  Sarsa(0) Algorithm  Naming: State–action–reward–state–action In the algorithm, the number of episodes the agent collects is equal to $num$ $episodes$. For every time step $t\\ge 0$, the agent:  takes the action $A_t$ (from the current state $S_t$ that is $\\epsilon$-greedy with respect to the Q-table receives the reward $R_{t+1}$ and next state $S_{t+1}$ chooses the next action $A_{t+1}$ (from the next state $S_{t+1}$) that is $\\epsilon$-greedy with respect to the Q-table   uses the information in the tuple ($S_t,A_t, R_{t+1}, S_{t+1}, A_{t+1}$) tp ipdate the entry $Q(S_t, A_t)$ in the Q-table corresponding to the current state $S_t$ and the action $A_t$.    Sarsa Algorithm, image from Udacity nd893\nSarsamax (Q-Learning) Sarsamax Algorithm, image from Udacity nd893\nOptimism 🔭  For any TD control method, you must begin by initializing the values in the Q-table. It has been shown that initializing the estimates to large values can improve performance. If all of the possible rewards that can be received by the agent are negative, then initializing every estimate in the Q-table to zeros is a good technique. In this case, we refer to the initialized Q-table as optimistic, since the action-value estimates are guaranteed to be larger than the true action values.  Excercise OpenAI Gym: CliffWalkingEnv  Read in Example 6.6 Openai cliffwalking.py  Test Sarsa Sarsa Algorithm, image from Udacity nd893\n Answer: 6.16\n ","excerpt":"Temporal Difference (TD) Control  A class of model-free reinforcement learning methods which learn …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f05-temporal-difference/","title":"Temporal Difference"},{"body":"","excerpt":"","ref":"/docs/coding/practices/env/","title":"Environment"},{"body":"\nSorts Image from xkcd\n","excerpt":"Sorts Image from xkcd","ref":"/docs/computer_science/software-engineering/sorts/","title":"Sorts"},{"body":"\nThinking conditionally – a condition for thinking\n How do you solve a problem?  Try simple and extreme conditions Try to decompose a complex problem into simpler pieces Try Richard Feynman\u0026rsquo;s approach  Write down the problem Think hard about it 🤔🤔🤔 Write down the solution    ","excerpt":"\nThinking conditionally – a condition for thinking\n How do you solve a problem?  Try simple and …","ref":"/docs/math/intro/probability/s110_l05_conditioning_2/","title":"Conditional Probability"},{"body":"\nLabel Smoothing Label Smoothing is a regularization technique that introduces noise for the labels.\n When Does Label Smoothing Help?   We show that label smoothing encourages the representations of training examples from the same class to group in tight clusters. This results in loss of information in the logits about resemblances between instances of different classes, which is necessary for distillation, but does not hurt generalization or calibration of the model’s predictions.\n  When Does Label Smoothing Help? Medium post What is Label Smoothing? Label smoothing with Keras, TensorFlow, and Deep Learning Kaggle notebook Label Smoothing: An ingredient of higher model accuracy  Smoothie ","excerpt":"Label Smoothing Label Smoothing is a regularization technique that introduces noise for the labels. …","ref":"/docs/machinelearning/models/classification/multi-class/","title":"Multi-class"},{"body":"\n","excerpt":"","ref":"/docs/coding/functional-coding/javascript/course/data-structure/","title":"Data Structure"},{"body":"\n Course Link\n 1. Generate Random Fractions with JavaScript JavaScript has a Math.random() function that generates a random decimal number between 0 (inclusive) and not quite up to 1 (exclusive). Thus Math.random() can return a 0 but never quite return a 1\nfunction randomFraction() { return Math.random(); } \n2. Generate Random Whole Numbers It\u0026rsquo;s great that we can generate random decimal numbers, but it\u0026rsquo;s even more useful if we use it to generate random whole numbers.\n  Use Math.random() to generate a random decimal. Multiply that random decimal by 20. Use another function, Math.floor() to round the number down to its nearest whole number. Remember that Math.random() can never quite return a 1 and, because we\u0026rsquo;re rounding down, it\u0026rsquo;s impossible to actually get 20. This technique will give us a whole number between 0 and 19.   Math.floor(Math.random() * 20); \n3. Generate Random Whole Numbers within a Range function randomRange(myMin, myMax) { // Only change code below this line  return Math.floor(Math.random() * (myMax - myMin + 1)) + myMin // Only change code above this line } \n4. Use the parseInt Function The parseInt() function parses a string and returns an integer\nfunction convertToInteger(str) { return parseInt(str) } # test convertToInteger(\u0026#34;56\u0026#34;); \n5. Use the parseInt Function with a Radix Use parseInt() in the convertToInteger function so it converts a binary number to an integer and returns it\n# parseInt(string, radix); function convertToInteger(str) { return parseInt(str,2) } convertToInteger(\u0026#34;10011\u0026#34;); \n6. Use the Conditional (Ternary) Operator 😃  The conditional operator, also called the ternary operator, can be used as a one line if-else expression. The syntax is: condition ? statement-if-true : statement-if-false; Example  function findGreater(a, b) { if(a \u0026gt; b) { return \u0026#34;a is greater\u0026#34;; } else { return \u0026#34;b is greater\u0026#34;; } } can be re-written using the conditional operator\nfunction findGreater(a,b){ return a \u0026gt;b ? \u0026#34;a is greater\u0026#34; : \u0026#34;b is greater\u0026#34;; }  7. Use Multiple Conditional (Ternary) Operators  Use multiple conditional operators in the checkSign function to check if a number is positive, negative or zero. The function should return \u0026ldquo;positive\u0026rdquo;, \u0026ldquo;negative\u0026rdquo; or \u0026ldquo;zero\u0026rdquo;.\n function checkSign(num) { return (num==0)? \u0026#34;zero\u0026#34; : (num\u0026gt;0) ? \u0026#34;positive\u0026#34; : \u0026#34;negative\u0026#34; } checkSign(10); \n8. Use Recursion to Create a Countdown  The function should use recursion to return an array containing the integers n through 1 based on the n parameter. If the function is called with a number less than 1, the function should return an empty array. For example, calling this function with n = 5 should return the array [5, 4, 3, 2, 1]\n function countdown(n) { if (n \u0026lt; 1) { return []; } else { const arr = countdown(n - 1); //index  arr.unshift(n); // unshift  return arr; } } \n9. Use Recursion to Create a Range of Numbers  We have defined a function named rangeOfNumbers with two parameters. The function should return an array of integers which begins with a number represented by the startNum parameter and ends with a number represented by the endNum parameter.\nThe starting number will always be less than or equal to the ending number. Your function must use recursion by calling itself and not use loops of any kind. It should also work for cases where both startNum and endNum are the same.\n function rangeOfNumbers(startNum, endNum) { if (startNum === endNum){ return [startNum]; } else { // how many  var arr = rangeOfNumbers(startNum, endNum - 1); arr.push(endNum); return arr } }; ","excerpt":"Course Link\n 1. Generate Random Fractions with JavaScript JavaScript has a Math.random() function …","ref":"/docs/coding/functional-coding/javascript/course/basics/numbers/","title":"Numbers"},{"body":"\nGitHub\n Google\u0026rsquo;s differential privacy library can be used to produce aggregate statistics over numeric data sets containing private or sensitive information. The functionality is currently available in C++ and Java.\n ","excerpt":"\nGitHub\n Google\u0026rsquo;s differential privacy library can be used to produce aggregate statistics …","ref":"/docs/machinelearning/privacy/differential-privacy/","title":"Differential Privacy"},{"body":"\nUnit Test  Unit testing framework  import unittest from sklearn.metrics import precision_score, recall_score from src.train import prepare_data_and_train_model class TestModelMetrics(unittest.TestCase): def test_model_precision_score_should_be_above_threshold(self): model, X_test, Y_test = prepare_data_and_train_model() Y_pred = model.predict(X_test) precision = precision_score(Y_test, Y_pred) self.assertGreaterEqual(precision, 0.7) def test_model_recall_score_should_be_above_threshold(self): model, X_test, Y_test = prepare_data_and_train_model() Y_pred = model.predict(X_test) recall = recall_score(Y_test, Y_pred) self.assertGreaterEqual(recall, 0.6)  Ref\n Read More  Better habits for managing complexity in data science codebases pytest Testing Your Code  ","excerpt":"\nUnit Test  Unit testing framework  import unittest from sklearn.metrics import precision_score, …","ref":"/docs/coding/functional-coding/python/testing/unittest/","title":"Unit Test"},{"body":"House-GAN Relational Generative Adversarial Networks for Graph-constrained House Layout Generation\n Paper\nNelson Nauata, Kai-Hung Chang, Chin-Yi Cheng, Greg Mori, Yasutaka Furukawa\nThis paper proposes a novel graph-constrained generative adversarial network, whose generator and discriminator are built upon relational architecture.\nThe main idea is to encode the constraint into the graph structure of its relational networks.\nWe have demonstrated the proposed architecture for a new house layout generation problem, whose task is to take an architectural constraint as a graph (i.e., the number and types of rooms with their spatial adjacency) and produce a set of axis-aligned bounding boxes of rooms.\nWe measure the quality of generated house layouts with the three metrics: the realism, the diversity, and the compatibility with the input graph constraint.\nOur qualitative and quantitative evaluations over 117,000 real floorplan images demonstrate that the proposed approach outperforms existing methods and baselines. We will publicly share all our code and data.\n ","excerpt":"House-GAN Relational Generative Adversarial Networks for Graph-constrained House Layout Generation …","ref":"/docs/machinelearning/models/graph-nn/applications/gans-house/","title":"House-GAN"},{"body":"","excerpt":"","ref":"/docs/coding/practices/error_collection/","title":"Error Collections"},{"body":"\nWindows Command   export is not recognized as an internal or external command\n Solution: In Windows use set instead of export    Windows Installation  How to install make for Windows?  Run as an Administrator Install chocolatey choco install make    Errors  UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 3896: character maps to \u0026lt;undefined\u0026gt;  Solution: rm ~/.python_history    ","excerpt":"\nWindows Command   export is not recognized as an internal or external command\n Solution: In Windows …","ref":"/docs/coding/practices/error_collection/windows/","title":"Windows"},{"body":"\n1. Jupytext  Install jupytext  # Use conda or pip conda install -c conda-forge jupytext  Edit Jupyter config  # Generate a Jupyter config jupyter notebook --generate-config # Edit .jupyter/jupyter_notebook_config.py vim /Users/j/.jupyter/jupyter_notebook_config.py # Append the following c.NotebookApp.contents_manager_class = \u0026#34;jupytext.TextFileContentsManager\u0026#34; # Restart Jupyter Notebook jupyter notebook  Convert format within Notebook  # Click Edit=\u0026gt;Edit Notebook Metadata and append the below line \u0026quot;jupytext\u0026quot;: {\u0026quot;formats\u0026quot;: \u0026quot;ipynb,py\u0026quot;},  Or convert format using command line  jupytext --to py:percent notebook.ipynb # create a notebook.py file in the double percent format jupytext --to markdown notebook.ipynb # create a notebook.md file jupytext --output script.py notebook.ipynb # create a script.py file jupytext --to notebook notebook.py # overwrite notebook.ipynb (remove outputs) jupytext --to notebook --update notebook.py # update notebook.ipynb (preserve outputs) jupytext --to ipynb notebook1.md notebook2.py # overwrite notebook1.ipynb and notebook2.ipynb jupytext --to md --test notebook.ipynb # Test round trip conversion jupytext --to md --output - notebook.ipynb # display the markdown version on screen jupytext --from ipynb --to py:percent # read ipynb from stdin and write double percent script on stdout  Reference Jupytext highlight  2. jupyter2slides python create_slides.py --file static/filename.ipynb python run.py --file static/filename.slides.html http://0.0.0.0:9099/  change footer in jupyter_template.tpl  3. nbconvert ","excerpt":"1. Jupytext  Install jupytext  # Use conda or pip conda install -c conda-forge jupytext  Edit …","ref":"/docs/swiss-knives/converter-jupyter/","title":"Converter Jupyter"},{"body":"\nGPU Dashborads  A JupyterLab extension for displaying dashboards of GPU usage. Install jupyterlab-nvdashboard   GPU Dashboards in Jupyter Lab\n Version control  jupyterlab-git nbdime  How to add conda environment to jupyter lab? # Activate my conda environment mt  conda activate mt (mt)$ conda install ipykernel (mt)$ ipython kernel install --user --name=mt (mt)$ conda deactivate # Check in Jupyter lab  jupyter lab \nHow to update Jupyter Lab? conda update jupyterlab ","excerpt":"GPU Dashborads  A JupyterLab extension for displaying dashboards of GPU usage. Install …","ref":"/docs/swiss-knives/jupyter-lab/","title":"Jupyter Lab"},{"body":"\nHow to install Jupyter using miniconda? conda install jupyter \nHow to view Jupyter notebook if Github page fails to render ipynb notebook?  Go to https://nbviewer.jupyter.org/ Paste the link to your notebook  How to parameterize, execute, and analyze Jupyter notebook?  papermill  How to format code in Jupyter notebook?  Jupyter Black  # install jupyter nbextension install https://github.com/drillan/jupyter-black/archive/master.zip --user # enable  jupyter nbextension enable jupyter-black-master/jupyter-black \nHow to download all files in a path on Jupyter notebook server   Open a Jupyter notebook X on the server\n!tar cvfz allfiles.tar.gz *\nReference\n  A file allfiles.tar.gz can be found in the directory where your X is localized. Click the file to download it.\n  Extract files from the .tar.gz in your local terminal tar -xvzf allfiles.tar.gz\n  How to know which Python and packages are used in jupyter notebook? import sys print(sys.executable) print(sys.version) print(sys.version_info) # Get locally imported modules from current notebook import pkg_resources import types def get_imports(): for name, val in globals().items(): if isinstance(val, types.ModuleType): # Split ensures you get root package, # not just imported function name = val.__name__.split(\u0026#34;.\u0026#34;)[0] elif isinstance(val, type): name = val.__module__.split(\u0026#34;.\u0026#34;)[0] # Some packages are weird and have different # imported names vs. system/pip names. Unfortunately, # there is no systematic way to get pip names from # a package\u0026#39;s imported name. You\u0026#39;ll have to had # exceptions to this list manually! poorly_named_packages = { \u0026#34;PIL\u0026#34;: \u0026#34;Pillow\u0026#34;, \u0026#34;sklearn\u0026#34;: \u0026#34;scikit-learn\u0026#34; } if name in poorly_named_packages.keys(): name = poorly_named_packages[name] yield name imports = list(set(get_imports())) # The only way I found to get the version of the root package # from only the name of the package is to cross-check the names # of installed packages vs. imported packages requirements = [] for m in pkg_resources.working_set: if m.project_name in imports and m.project_name!=\u0026#34;pip\u0026#34;: requirements.append((m.project_name, m.version)) for r in requirements: print(\u0026#34;{}=={}\u0026#34;.format(*r)) Reference\n","excerpt":"How to install Jupyter using miniconda? conda install jupyter \nHow to view Jupyter notebook if …","ref":"/docs/swiss-knives/jupyter-notebook/","title":"Jupyter Notebook"},{"body":"\nCourse: How to win a data science competition: learn from top Kagglers  Instructors   Dmitry Ulyanov, Alexander Guschin, Mikhail Trofimov, Dmitry Altukhov, Marios Michailidis* National Research University Higher School of Economics\nCourse Link\nMy Notes\nKaggle perfect scores  The public leaderboard is computed based on a fraction of the test set. The private leaderboard is computed on the whole test set. If you overfit the test set you can do very well in the public leaderboard and very bad in the private one.\n Kaggle past solutions Kaggle competition solutions Kaggle classification The perfect score script   How to download data using Kaggle API? # 1) Install kaggle package pip install --user kaggle # Note: pip install kaggle \u0026lt;== This command cause problems # 2) Download and save your kaggle API token 'Go to https://www.kaggle.com/username/account ==\u0026gt; Create API Token' ==\u0026gt; Download API token (This will trigger the download of kaggle.json, a file containing your API credentials.)' # Place this file in the location ~/.kaggle/kaggle.json # Go to the directory where the kaggle.json was saved sudo cp kaggle.json ~/.kaggle/kaggle.json sudo cp kaggle.json /Users/j/.local/lib/python3.7/site-packages/kaggle/kaggle.json # Ensure other users don't have access to the key sudo chmod 600 ~/.kaggle/kaggle.json # 3) Download competition data in your project # List files in a competition kaggle competitions download -c quora-insincere-questions-classification # Download all files in a competition kaggle competitions files quora-insincere-questions-classification # Download your notebook mynotebook.ipynb from the kaggle kernel kaggle kernels pull usrname/mynotebook # 4) Add kaggle toyour path # Open .zshrc vi ~/.zshrc # add alias kaggle=\u0026quot;/Users/j/.local/lib/python3.7/site-packages/kaggle\u0026quot; source ~/.zshrc # Save and run zsh \nHow to upload functions in Kaggle kernel? # 1. Upload your awesome_function.py file as a Dataset in your Notebook/Script kernel In your running Notebook/Script kernel, click 'Add Dataset' =\u0026gt; Select 'Dataset' =\u0026gt; Click 'Upload a Dataset' =\u0026gt; Upload your awesome_function.py file from local/GitHub =\u0026gt; Enter a title for your dataset e.g. 'kutil' (This will in fact create a subfolder 'kutil')=\u0026gt; Click 'Create' # 2. Your Notebook/Script kernel will refresh. The awesome_function.py is saved in '../input/kutils/' # 3. Copy the awesome_function.py to kaggle working directory '/kaggle/working' from shutil import copyfile copyfile(src = \u0026quot;../input/kutil/awesome_function.py\u0026quot;, dst = '/kaggle/working/awesome_function.py') # 4. Import functions from awesome_function.py to your Notebook/Script kernel from awsome_function import *  References  Kaggle API Import functions from Kaggle script Adding Data Sources  ","excerpt":"Course: How to win a data science competition: learn from top Kagglers  Instructors   Dmitry …","ref":"/docs/data/dataset/kaggle/","title":"Kaggle"},{"body":"\nLevenshtein Distance  The Levenshtein distance is one of the methods to calculate the similarity between two strings. When converting one string to the other, the Levenshtein distance is calculated by the operation how many times the character is  inserted deleted replaced    import Levenshtein str1 = \u0026#39;Rievenstein\u0026#39; str2 = \u0026#39;Levenshtein\u0026#39; print(Levenshtein.distance(str1, str2)) #3  # if you want to know the operations print(Levenshtein.editops(str1, str2)) # [(\u0026#39;delete\u0026#39;, 0, 0), (\u0026#39;replace\u0026#39;, 1, 0), (\u0026#39;insert\u0026#39;, 7, 6)] # If you want to get the similarity ratios print(Levenshtein.ratio(str1, str2)) # 0.8181818181818182 print(Levenshtein.ratio(str1, str1)) # 1.0 print(Levenshtein.ratio(str1, \u0026#39;\u0026#39;)) # 0.0 # If you want to select the average string in the list of several strings, you should use to median. print(Levenshtein.median([ \u0026#39;Rievenstein\u0026#39;, \u0026#39;Levenshtein\u0026#39;, \u0026#39;Revenshtein\u0026#39;, \u0026#39;Lievenstein\u0026#39;, \u0026#39;Levenshtain\u0026#39;, \u0026#39;Levennshtein\u0026#39; ])) # Levenshtein ","excerpt":"Levenshtein Distance  The Levenshtein distance is one of the methods to calculate the similarity …","ref":"/docs/machinelearning/metrics/","title":"Metrics"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/courses/reinforcement-learning/c4-multi-agent/","title":"Multi Agent"},{"body":"\nReinforcement Learning: Framework   Model-based\n requires a known transition and reward model essentially apply dynamic programming to iteratively compute the desired value functions and optimal policies using that model Examples  Policy iteration Value iteration      Model-free\n samples the environment by carrying out exploratory actions and use the experience gained to directly estimate value functions Examples  Monte Carlo Methods Temporal-Difference Learning      Dealing with Discrete and Continuous Spaces  Discretization: Converting a continuous space into a discrete space Function Approximation  [Non-uniform Discretization, image from Udacity 893]\nOpenAI Environments  Discrete(): refers to a discrete space Box(): indicates a continuous space  Tile Coding  Adaptive Tile Coding  does not rely on a human to specify a discretization ahead of time the resulting space is appropriately partitioned based on its complexity    Coarse Coding  Generalization  Narrow generalization Broad generalization Asymmetric generalization   Redial Basis Functions  [Coarse Coding, image from Udacity 893]\nFunction Approximation   State value approximation\n linear function approximation: $\\hat{v}(s,w) = x(s)^T \\cdot w$ Goal: Minimize Error Use Gradient Descent: $\\nabla_w \\hat{v}(s, w) = x(s)$    Action value approximation\n  [Linear Function Approximation]\n","excerpt":"Reinforcement Learning: Framework   Model-based\n requires a known transition and reward model …","ref":"/docs/machinelearning/courses/reinforcement-learning/c1-foundation/f06-rl-continuous-spaces/","title":"Continuous Spaces"},{"body":"\n","excerpt":"","ref":"/docs/math/intro/probability/s110_l06_montyhall/","title":"Monty Hall, Simpson's Paradox"},{"body":"\nMulti-label  Multilabel-Classification using TensorFlow Deep dive into multi-label classification NeuralClassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit scikit-multilearn Deep learning architectures for multi-label classification of intelligent health risk prediction  ","excerpt":"\nMulti-label  Multilabel-Classification using TensorFlow Deep dive into multi-label classification …","ref":"/docs/machinelearning/models/classification/multi-label/","title":"Multi-label"},{"body":"Books  Think Bayes by Allen B. Downey, free book  What does Bayes Theorem do? It helps us to update a hypothesis based on new evidence.\nTerms  Base Rate Fallacy (Base Rate Neglect): If presented with related base rate information (i.e., general information on prevalence) and specific information (i.e., information pertaining only to a specific case), people tend to ignore the base rate in favor of the individuating information, rather than correctly integrating the two.  Image from thedecisionlab\n","excerpt":"Books  Think Bayes by Allen B. Downey, free book  What does Bayes Theorem do? It helps us to update …","ref":"/docs/math/intro/bayes-theorem/","title":"Bayes Theorem"},{"body":"","excerpt":"","ref":"/docs/coding/functional-coding/python/format/","title":"Format"},{"body":"CRank- Prioritizing network communities CRank is an automatic unsupervised method for prioritizing network communities and identifying the most promising ones for further experimentation.\n  GitHub\n  Paper - Prioritizing network communities\n   Uncovering modular structure in networks is fundamental for systems in biology, physics, and engineering.\nCommunity detection identifies candidate modules as hypotheses, which then need to be validated through experiments, such as mutagenesis in a biological laboratory.\nOnly a few communities can typically be validated, and it is thus important to prioritize which communities to select for downstream experimentation.\nHere we develop CRank, a mathematically principled approach for prioritizing network communities. CRank efficiently evaluates robustness and magnitude of structural features of each community and then combines these features into the community prioritization.\nCRank can be used with any community detection method. It needs only information provided by the network structure and does not require any additional metadata or labels.\nHowever, when available, CRank can incorporate domain-specific information to further boost performance. Experiments on many large networks show that CRank effectively prioritizes communities, yielding a nearly 50-fold improvement in community prioritization.\n ","excerpt":"CRank- Prioritizing network communities CRank is an automatic unsupervised method for prioritizing …","ref":"/docs/machinelearning/models/graph-nn/tools/rank/","title":"Rank Algorithms"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/models/","title":"Models"},{"body":"","excerpt":"","ref":"/docs/computer_science/iot/","title":"IoT"},{"body":"\nA Beginner\u0026rsquo;s Guide to the Mathematics of Neural Networks\n","excerpt":"A Beginner\u0026rsquo;s Guide to the Mathematics of Neural Networks","ref":"/docs/math/intro/neural-networks/","title":"Mathematics of Neural Networks"},{"body":"","excerpt":"","ref":"/docs/machinelearning/","title":"Machine Learning"},{"body":"\nImage source\n","excerpt":"Image source","ref":"/docs/machinelearning/models/deep-learning/transformers/","title":"Transformers"},{"body":"\nfactoextra : Extract and Visualize the Results of Multivariate Data Analyses   GitHub\n  Functions\n  Principal Component Analysis (PCA), which is used to summarize the information contained in a continuous (i.e, quantitative) multivariate data by reducing the dimensionality of the data without loosing important information.\n  Correspondence Analysis (CA), which is an extension of the principal component analysis suited to analyse a large contingency table formed by two qualitative variables (or categorical data).\n  Multiple Correspondence Analysis (MCA), which is an adaptation of CA to a data table containing more than two categorical variables.\n  Multiple Factor Analysis (MFA) dedicated to datasets where variables are organized into groups (qualitative and/or quantitative variables).\n  Hierarchical Multiple Factor Analysis (HMFA): An extension of MFA in a situation where the data are organized into a hierarchical structure.\n  Factor Analysis of Mixed Data (FAMD), a particular case of the MFA, dedicated to analyze a data set containing both quantitative and qualitative variables.\n    factoextra\nDimension reduction\nMCA\nLicense To the extent possible under law, factoextra has waived all copyright and related or neighboring rights to this work.\n","excerpt":"factoextra : Extract and Visualize the Results of Multivariate Data Analyses   GitHub\n  Functions …","ref":"/docs/data/visual-art/multivariate/","title":"Multivariate"},{"body":"\nPackages  click sys.argv   Different command line package\n Tutorials  The Easy Guide to Python Command Line Arguments  ","excerpt":"\nPackages  click sys.argv   Different command line package\n Tutorials  The Easy Guide to Python …","ref":"/docs/coding/functional-coding/python/command-line/","title":"Command Line"},{"body":"BANANAS Bayesian Optimization with Neural Architectures for Neural Architecture Search\n Authors Colin White, Willie Neiswanger, and Yash Savani\nGitHub\nPaper   BANANAS is a neural architecture search (NAS) algorithm which uses Bayesian optimization with a meta neural network to predict the validation accuracy of neural architectures. We use a path-based encoding scheme to featurize the neural architectures that are used to train the neural network model. After training on just 200 architectures, we are able to predict the validation accuracy of new architectures to within one percent on average. The full NAS algorithm beats the state of the art on the NASBench and the DARTS search spaces. On the NASBench search space, BANANAS is over 100x more efficient than random search, and 3.8x more efficent than the next-best algorithm we tried. On the DARTS search space, BANANAS finds an architecture with a test error of 2.57%.\n ","excerpt":"BANANAS Bayesian Optimization with Neural Architectures for Neural Architecture Search\n Authors …","ref":"/docs/machinelearning/models/optimization/bayesian-optimization/","title":"NN Optimization"},{"body":"License To the extent possible under law, Spark NLP has waived all copyright and related or neighboring rights to this work.\nWhat is Spark NLP? John Snow Labs Spark NLP is a natural language processing library built on top of Apache Spark ML. It provides simple, performant \u0026amp; accurate NLP annotations for machine learning pipelines that scale easily in a distributed environment.\nFeatures  Tokenization Stop Words Removal Normalizer Stemmer Lemmatizer NGrams Regex Matching Text Matching Chunking Date Matcher Sentence Detector Part-of-speech tagging Sentiment Detection (ML models) Spell Checker (ML and DL models) Word Embeddings (GloVe and Word2Vec) BERT Embeddings (TF Hub models) ELMO Embeddings (TF Hub models) Universal Sentence Encoder (TF Hub models) Sentence Embeddings Chunk Embeddings Multi-class Text Classification (Deep learning) Named entity recognition (Deep learning) Dependency parsing (Labeled/unlabled) Easy TensorFlow integration Full integration with Spark ML functions +30 pre-trained models in 6 languages (English, French, German, Italian, Spanish, and Russian) +30 pre-trained pipelines!  Requirements In order to use Spark NLP you need the following requirements:\n Java 8 Apache Spark 2.4.x  Installation $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.6 -y $ conda activate sparknlp $ pip install spark-nlp==2.4.5 pyspark==2.4.4 \nQuickstart # Import Spark NLP from sparknlp.base import * from sparknlp.annotator import * from sparknlp.pretrained import PretrainedPipeline import sparknlp # Start Spark Session with Spark NLP spark = sparknlp.start() # Download a pre-trained pipeline pipeline = PretrainedPipeline('explain_document_dl', lang='en') # Your testing dataset text = \u0026quot;\u0026quot;\u0026quot; The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris. \u0026quot;\u0026quot;\u0026quot; # Annotate your testing dataset result = pipeline.annotate(text) # What's in the pipeline list(result.keys()) Output: ['entities', 'stem', 'checked', 'lemma', 'document', 'pos', 'token', 'ner', 'embeddings', 'sentence'] # Check the results result['entities'] Output: ['Mona Lisa', 'Leonardo', 'Louvre', 'Paris'] \nSpark NLP Workshop ","excerpt":"License To the extent possible under law, Spark NLP has waived all copyright and related or …","ref":"/docs/machinelearning/nlp/nlp-tools/spark-nlp/","title":"Spark NLP"},{"body":"\npython packages   Palladium\n It is a pluggable framework for developing real-world machine learning solutions. It provides generic implementations for things commonly needed in machine learning, such as dataset loading, model training with parameter search, a web service, and persistence capabilities, allowing you to concentrate on the core task of developing an accurate machine learning model. Built on sklearn    Nashpy\n Game Theory concepts with application in Python using Nashpy    gc\nThis module provides an interface to the optional garbage collector. It provides the ability to disable the collector, tune the collection frequency, and set debugging options.\n  pathlib2\n  dabl (Data Analysis Baseline Library)\n  missingno\n  AutoViz\n  Bamboolib\n  FlashText\n  PyFlux\n  Numerizer\n  Emot\n   Useful python libraries for data science\n Machine learning  lightgbm GPipe nolearn Snorkel: Data gerneration and augmentation human learn  Data versioning  DVC Quilt: a versioned data portal for AWS  Data visualization   Pylab is a module that belongs to the Python mathematics library Matplotlib. PyLab combines the numerical module numpy with the graphical plotting module pyplot. PyLab was designed with the interactive Python interpreter in mind, and therefore many of its functions are short and require minimal typing.\n  Pydicom is a pure Python package for working with DICOM files such as medical images, reports, and radiotherapy objects.\n  imgaug\n  pillow\n  Data science pipeline  pypeln: creating concurrent data pipelines PyFunctional: creating data pipelines easy by using chained functional operators. Joblib: running Python functions as pipeline jobs  How to manage application dependencies?  Poetry: Dependency Management for Python  # install curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python # configure your current shell  source $HOME/.poetry/env  Pigar: Generate requirements.txt from a project or a file  # To install it with pip $ [sudo] pip install pigar # To install it with conda $ conda install -c conda-forge pigar # Generate requirements.txt for current directory. $ pigar # Generating requirements.txt for given directory in given file. $ pigar -p ../dev-requirements.txt -P ../  Manage dependencies for Python projects using Pipenv   Pipenv is a dependency manager for Python projects. If you’re familiar with Node.js’ npm or Ruby’s bundler, it is similar in spirit to those tools. While pip alone is often sufficient for personal use, Pipenv is recommended for collaborative projects as it’s a higher-level tool that simplifies dependency management for common use cases.\n $ pip install --user pipenv $ cd myproject $ pipenv install requests \nHow to integrate R and Python in a single workflow?  Use R snippet and python snippet developer tools in Knime Use RPy Package for R/Python Interface  How to operate and manipulate physical quantities in Python?  Pint   Pint is a Python package to define, operate and manipulate physical quantities: the product of a numerical value and a unit of measurement. It allows arithmetic operations between them and conversions from and to different units.\n # Install $ pip install pint \u0026gt;\u0026gt;\u0026gt; import pint \u0026gt;\u0026gt;\u0026gt; ureg = pint.UnitRegistry() # 1) Convert between meters and centimeters  \u0026gt;\u0026gt;\u0026gt; 3 * ureg.meter + 4 * ureg.cm \u0026lt;Quantity(3.04, \u0026#39;meter\u0026#39;)\u0026gt; # 2) Or use numpy  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; [3, 4] * ureg.meter + [4, 3] * ureg.cm \u0026lt;Quantity([ 3.04 4.03], \u0026#39;meter\u0026#39;)\u0026gt; \u0026gt;\u0026gt;\u0026gt; np.sum(_) \u0026lt;Quantity(7.07, \u0026#39;meter\u0026#39;)\u0026gt; \nHow to do geospatial operations?  Geolib   Library to provide basic geospatial operations like distance calculation, conversion of decimal coordinates to sexagesimal and vice versa, etc. This library is currently 2D, meaning that altitude/elevation is not yet supported by any of its functions!\n  Data science glossary  By Google Analytics Vidhya  ","excerpt":"python packages   Palladium\n It is a pluggable framework for developing real-world machine learning …","ref":"/docs/coding/functional-coding/python/packages/","title":"Packages"},{"body":"Gambler\u0026rsquo;s Rules           0 i N      Difference equation\n $q=1-p$ $p_i = pp_{i+1} + qp_{i-1}$    Differential equation An equation that relates one or more functions and their derivatives\n  Random variables A function from the sample space S to the rea lline\nBernoulli distribution  The Bernoulli distribution, named after Swiss mathematician Jacob Bernoulli, is the discrete probability distribution of a random variable which takes the value 1 with probability $p$ and the value 0 with probability $q = 1 − p$.  $P_{x=1} = p$ $P_{x=0} = 1-p$    Binomial distribution  In n independent Bernoulli trails, e.g. flipping a coin $n$ times, the distribution of success is called Binomial distribution Indicator variables Independent and identically distributed (iid) Probability Math Function (PMF)  $P_{(x=k)} = p^k(1-p)^{n-k}$   Binomial Distribution vs Normal Distribution:  Normal distribution describes continuous data which have a symmetric distribution, with a characteristic \u0026lsquo;bell\u0026rsquo; shape. Binomial distribution describes the distribution of binary data from a finite sample. Thus it gives the probability of getting r events out of n trials.    ","excerpt":"Gambler\u0026rsquo;s Rules           0 i N      Difference equation\n $q=1-p$ $p_i = pp_{i+1} + qp_{i-1}$ …","ref":"/docs/math/intro/probability/s110_l07_l08_random_variables_distributions/","title":"Random Variables and Distributions"},{"body":"","excerpt":"","ref":"/docs/math/","title":"Math"},{"body":"\nSummary of Clean code — Robert C. Martin  Summarized by wojteklu\n ","excerpt":"\nSummary of Clean code — Robert C. Martin  Summarized by wojteklu\n ","ref":"/docs/coding/practices/clean-code/","title":"Clean Code"},{"body":"\nTransformersis an opinionated library built for NLP researchers seeking to use/study/extend large-scale transformers models.\nThe library was designed with two strong goals in mind:\n  Be as easy and fast to use as possible:\n  we strongly limited the number of user-facing abstractions to learn, in fact, there are almost no abstractions, just three standard classes required to use each model: configuration, models and tokenizer,\n  all of these classes can be initialized in a simple and unified way from pretrained instances by using a common from_pretrained() instantiation method which will take care of downloading (if needed), caching and loading the related class from a pretrained instance supplied in the library or your own saved instance.\n  as a consequence, this library is NOT a modular toolbox of building blocks for neural nets. If you want to extend/build-upon the library, just use regular Python/PyTorch modules and inherit from the base classes of the library to reuse functionalities like model loading/saving.\n    Provide state-of-the-art models with performances as close as possible to the original models:\n we provide at least one example for each architecture which reproduces a result provided by the official authors of said architecture, the code is usually as close to the original code base as possible which means some PyTorch code may be not as pytorchic as it could be as a result of being converted TensorFlow code.    Three types of classes for each model   Model classes e.g., BertModel which are 20+ PyTorch models (torch.nn.Modules) that work with the pretrained weights provided in the library. In TF2, these are tf.keras.Model.\n  Configuration classes which store all the parameters required to build a model, e.g., BertConfig. You don’t always need to instantiate these your-self. In particular, if you are using a pretrained model without any modification, creating the model will automatically take care of instantiating the configuration (which is part of the model)\n  Tokenizer classes which store the vocabulary for each model and provide methods for encoding/decoding strings in a list of token embeddings indices to be fed to a model, e.g., BertTokenizer\n  All these classes can be instantiated from pretrained instances and saved locally using two methods:\n  from_pretrained() let you instantiate a model/configuration/tokenizer from a pretrained version either provided by the library itself (currently 27 models are provided as listed here) or stored locally (or on a server) by the user,\n  save_pretrained() let you save a model/configuration/tokenizer locally so that it can be reloaded using from_pretrained().\n  ","excerpt":"Transformersis an opinionated library built for NLP researchers seeking to use/study/extend …","ref":"/docs/machinelearning/models/deep-learning/transformers/hugging-face/","title":"Hugging Face"},{"body":"\nMesh R-CNN  Authors Georgia Gkioxari, Jitendra Malik, Justin Johnson (Facebook AI Research)\nGitHub Paper   Rapid advances in 2D perception have led to systems that accurately detect objects in real-world images. However, these systems make predictions in 2D, ignoring the 3D structure of the world. Concurrently, advances in 3D shape prediction have mostly focused on synthetic benchmarks and isolated objects.\nWe unify advances in these two areas. We propose a system that detects objects in real-world images and produces a triangle mesh giving the full 3D shape of each detected object. Our system, called Mesh R-CNN, augments Mask R-CNN with a mesh prediction branch that outputs meshes with varying topological structure by first predicting coarse voxel representations which are converted to meshes and refined with a graph convolution network operating over the mesh\u0026rsquo;s vertices and edges.\nWe validate our mesh prediction branch on ShapeNet, where we outperform prior work on single-image shape prediction. We then deploy our full Mesh R-CNN system on Pix3D, where we jointly detect objects and predict their 3D shapes.\n ","excerpt":"Mesh R-CNN  Authors Georgia Gkioxari, Jitendra Malik, Justin Johnson (Facebook AI Research)\nGitHub …","ref":"/docs/machinelearning/cv/papers/mesh-r-cnn/","title":"R-CNN"},{"body":"","excerpt":"","ref":"/docs/swiss-knives/","title":"Swiss Army Knives"},{"body":"\npip  Problem Unable to install a package using pip First upgrade pip  pip install --upgrade pip ","excerpt":"\npip  Problem Unable to install a package using pip First upgrade pip  pip install --upgrade pip ","ref":"/docs/coding/practices/error_collection/install/","title":"Installation"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/explainability/","title":"Explainability"},{"body":"\ncausalml Uplift Tree Visualization using causalml\nMeta Learner Feature Importances using causalml\nExplained.ai  Clarifying exceptions and visualizing tensor operations in deep learning code Image from Explained.ai  Tensor Sensor It works with Tensorflow, PyTorch, JAX, and Numpy, as well as higher-level libraries like Keras and fastai.\n Example notebook Image from Tensor Sensor  DALEX  Gentle introduction to DALEX with examples Installation pip install dalex -U  DALEXtra  scikit-learn keras H2O tidymodels xgboost mlr or mlr3  DALEX functions, image from DALEX \nWhy   From DALEX It\u0026rsquo;s clear that we need to control algorithms that may affect us. Such control is in our civic rights. Here we propose three requirements that any predictive model should fulfill.\n  Prediction\u0026rsquo;s justifications\n For every prediction of a model one should be able to understand which variables affect the prediction and how strongly. Variable attribution to final prediction.    Prediction\u0026rsquo;s speculations\n For every prediction of a model one should be able to understand how the model prediction would change if input variables were changed. Hypothesizing about what-if scenarios.    Prediction\u0026rsquo;s validations\n For every prediction of a model one should be able to verify how strong are evidences that confirm this particular prediction.    There are two ways to comply with these requirements.\n One is to use only models that fulfill these conditions by design.  White-box models like linear regression or decision trees. In many cases the price for transparency is lower performance.   The other way is to use approximated explainers – techniques that find only approximated answers, but work for any black box model.  Here we present such techniques.    ","excerpt":"causalml Uplift Tree Visualization using causalml\nMeta Learner Feature Importances using causalml …","ref":"/docs/machinelearning/explainability/explainability/","title":"Packages"},{"body":"\nRef Boost Your Efficiency with Customized Code Snippets on VSCode\n","excerpt":"Ref Boost Your Efficiency with Customized Code Snippets on VSCode","ref":"/docs/coding/practices/create-snippet/","title":"Create Snippets"},{"body":"\n1. Install z shell and oh-my-zshell sudo apt-get update sudo apt upgrade sudo apt install zsh sudo apt-get install powerline fonts-powerline git clone https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc vim .zshrc ZSH_THEME=\u0026#34;agnoster\u0026#34; chsh -s /bin/zsh cd /.oh-my-zsh # syntax highlighting git clone https://github.com/zsh-users/zsh-syntax-highlighting.git \u0026#34;$HOME/.zsh-syntax-highlighting\u0026#34; --depth 1 echo \u0026#34;source $HOME/.zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\u0026#34; \u0026gt;\u0026gt; \u0026#34;$HOME/.zshrc\u0026#34; # change back to bash # chsh -s /bin/bash  Ref\n 2. Enable conda command # open bashrc vim ~/.bashshrc vim ~/.zshrc # copy below from bashrc to zshrc # added by miniconda3 5.3.0 installer # \u0026gt;\u0026gt;\u0026gt; conda init \u0026gt;\u0026gt;\u0026gt; # !! Contents within this block are managed by \u0026#39;conda init\u0026#39; !! __conda_setup=\u0026#34;$(CONDA_REPORT_ERRORS=false \u0026#39;/miniconda3/bin/conda\u0026#39; shell.bash hook 2\u0026gt; /dev/null)\u0026#34; if [ $? -eq 0 ]; then \\eval \u0026#34;$__conda_setup\u0026#34; else if [ -f \u0026#34;/miniconda3/etc/profile.d/conda.sh\u0026#34; ]; then . \u0026#34;/miniconda3/etc/profile.d/conda.sh\u0026#34; CONDA_CHANGEPS1=false conda activate base else \\export PATH=\u0026#34;/miniconda3/bin:$PATH\u0026#34; fi fi unset __conda_setup # \u0026lt;\u0026lt;\u0026lt; conda init \u0026lt;\u0026lt;\u0026lt; # Restart zshell source ~/.zshrc \n3. Level Up: install power10k theme git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ~/powerlevel10k echo \u0026#39;source ~/powerlevel10k/powerlevel10k.zsh-theme\u0026#39; \u0026gt;\u0026gt;! ~/.zshrc # config p10k configure # Fix zsh compinit: insecure directories and files compaudit | xargs chmod g-w compaudit | xargs chown root  Ref\n 4. Install Meslo Nerd Font Download these four ttf files:\n MesloLGS NF Regular.ttf MesloLGS NF Bold.ttf MesloLGS NF Italic.ttf MesloLGS NF Bold Italic.ttf  Double-click on each file and click \u0026ldquo;Install\u0026rdquo;. This will make MesloLGS NF font available to all applications on your system. Configure your terminal to use this font:\n GNOME Terminal (the default Ubuntu terminal): Open Terminal → Preferences and click on the selected profile under Profiles. Check Custom font under Text Appearance and select MesloLGS NF Regular.   Ref\n 5. Change terminal settings for vscode # install vscode in Ubuntu  sudo snap install --classic code View =\u0026gt; Command Pallete =\u0026gt; Type settings and Select Preferences: Open Settings (JSON) =\u0026gt; Add the below lines\n{ \u0026quot;terminal.integrated.fontFamily\u0026quot;: \u0026quot;MesloLGS NF\u0026quot;, \u0026quot;terminal.integrated.shell.osx\u0026quot;: \u0026quot;/bin/zsh\u0026quot; }  Ref\n ","excerpt":"1. Install z shell and oh-my-zshell sudo apt-get update sudo apt upgrade sudo apt install zsh sudo …","ref":"/docs/swiss-knives/terminal-ubuntu/","title":"Terminal for Ubuntu"},{"body":"","excerpt":"","ref":"/docs/web/","title":"Web"},{"body":"\n1. Install Iterm2 # Install iterm2 cd myfolder brew cask install iterm2 \n2. Install Z-shell # Install ZSH brew install zsh # Install Oh My Zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026#34; # Source .bash_profile source ~/.bash_profile # If you use conda environment conda init zsh \n3. Install Color Scheme git clone git@github.com:mbadolato/iTerm2-Color-Schemes.git \u0026#39;Go to iTerm2 \u0026gt; Preferences \u0026gt; Profile \u0026gt; Colors \u0026gt; Color Presets \u0026gt; Import \u0026gt; Select Folder iTerm2-Color-Schemes/Schemes/yourfavouritecolor\u0026#39; \n4. Install powerline font git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k vim ~/.zshrc ZSH_THEME=\u0026#34;agnoster\u0026#34; # Clone git clone https://github.com/powerline/fonts.git --depth=1 # Install fonts cd fonts ./install.sh # Clean-up cd .. rm -rf fonts \u0026#39;Go to iTerm2 \u0026gt; Preferences \u0026gt; Profile \u0026gt; Text \u0026gt; ChangeFont\u0026#39; \n5. Get miniconda working in Oh My ZSH open ~/.bash_profile open ~/.zshrc \u0026#39;\u0026#39;\u0026#39; # Copy below from ~/.bash_profile to ~/.zshrc # added by miniconda3 5.3.0 installer # \u0026gt;\u0026gt;\u0026gt; conda init \u0026gt;\u0026gt;\u0026gt; # !! Contents within this block are managed by \u0026#39;conda init\u0026#39; !! __conda_setup=\u0026#34;$(CONDA_REPORT_ERRORS=false \u0026#39;/miniconda3/bin/conda\u0026#39; shell.bash hook 2\u0026gt; /dev/null)\u0026#34; if [ $? -eq 0 ]; then \\eval \u0026#34;$__conda_setup\u0026#34; else if [ -f \u0026#34;/miniconda3/etc/profile.d/conda.sh\u0026#34; ]; then . \u0026#34;/miniconda3/etc/profile.d/conda.sh\u0026#34; CONDA_CHANGEPS1=false conda activate base else \\export PATH=\u0026#34;/miniconda3/bin:$PATH\u0026#34; fi fi unset __conda_setup # \u0026lt;\u0026lt;\u0026lt; conda init \u0026lt;\u0026lt;\u0026lt; \u0026#39;\u0026#39;\u0026#39; # Add the below line in ~/.zshrc file export PATH=\u0026#34;~/Users/j/miniconda3/bin:$PATH\u0026#34; # Restart zshell source ~/.zshrc \n6. Add zsh syntax highlighting git clone https://github.com/zsh-users/zsh-syntax-highlighting.git echo \u0026#34;source ${(q-)PWD}/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\u0026#34; \u0026gt;\u0026gt; ${ZDOTDIR:-$HOME}/.zshrc \n References  How to Configure your macOs Terminal with Zsh like a Pro oh-my-zsh iTerm2-Color-Schemes powerline How to revert your terminal to its default settings zsh-syntax-highlighting  ","excerpt":"1. Install Iterm2 # Install iterm2 cd myfolder brew cask install iterm2 \n2. Install Z-shell # …","ref":"/docs/swiss-knives/terminal-mac/","title":"Terminal for Mac"},{"body":"\n","excerpt":"","ref":"/docs/machinelearning/privacy/","title":"Privacy"},{"body":"\nGR framework  gr   GR3 is a software library for simple visualization of 3D scenes. It was developed by Florian Rhiem as part of his bachelor’s thesis. GR3 is written in C and can also be used from Python or Julia through a wrapper module.\n  nilearn   Nilearn is a Python module for fast and easy statistical learning on NeuroImaging data.\nIt leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.\n 3-D Scientific Visualization in the Jupyter Notebook  ipygany  Interactive graph visualization with cytoscape.js in JupyterLab and the Jupyter notebook  ipycytoscape  pip install ipycytoscape # enable jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-cytoscape ","excerpt":"GR framework  gr   GR3 is a software library for simple visualization of 3D scenes. It was developed …","ref":"/docs/data/visual-art/3d/","title":"Visualization 3D"},{"body":"\nSuper-duper fast pytorch tpu kernel  Abhishek Thakur\nKaggle Link\n ","excerpt":"\nSuper-duper fast pytorch tpu kernel  Abhishek Thakur\nKaggle Link\n ","ref":"/docs/swiss-knives/tpu/","title":"TPU"},{"body":"","excerpt":"","ref":"/docs/coding/functional-coding/javascript/","title":"JavaScript"},{"body":"","excerpt":"","ref":"/docs/healthcare/papers/","title":"Papers"},{"body":"\nHow can I find the memory usage on my GPU?  For Nvidia GPUs:  nvidia-smi  For Intel GPUs:  intel_gpu_tools  For AMD GPUs:  aticonfig --odgc --odgt  For real time watching \u0026ndash; example  sudo watch nvidia-smi Reference\nRelease GPU  Terminal  sudo fuser -v /dev/nvidia* pkill -u PIDs  Use memory growing:  config = tf.ConfigProto() config.gpu_options.allow_growth = True session = tf.Session(config=config, ...)  Don\u0026rsquo;t allocate whole of your GPU memory(e.g. only 90%):  config = tf.ConfigProto() config.gpu_options.per_process_gpu_memory_fraction = 0.9 session = tf.Session(config=config, ...)  Clear background  keras.backend.clear_session()  Add this in the notebook  from keras import backend as K cfg = K.tf.ConfigProto() cfg.gpu_options.allow_growth = True K.set_session(K.tf.Session(config=cfg))   Added gc.collect() to the end of my custom generator and it helped to get rid of memory errors.\n  Reduce your batch size\n  ","excerpt":"How can I find the memory usage on my GPU?  For Nvidia GPUs:  nvidia-smi  For Intel GPUs: …","ref":"/docs/swiss-knives/gpu/","title":"GPU"},{"body":"\nActivation Functions in Deep Learning: From Softmax to Sparsemax — Math Proof\n","excerpt":"Activation Functions in Deep Learning: From Softmax to Sparsemax — Math Proof","ref":"/docs/math/machinelearning/activation/math-proof/","title":"Activation"},{"body":"\nLong-Range Arena (LRA)   Long-range arena is an effort toward systematic evaluation of efficient transformer models. The project aims at establishing benchmark tasks/dtasets using which we can evaluate transformer-based models in a systematic way, by assessing their generalization power, computational efficiency, memory foot-print, etc.\n  Long-range arena also implements different variants of Transformer models in JAX, using Flax.\n  This first initial release includes the benchmarks for the paper Long Range Arena: A benchmark for Efficient Transformers.\n  GitHub\n  ","excerpt":"Long-Range Arena (LRA)   Long-range arena is an effort toward systematic evaluation of efficient …","ref":"/docs/machinelearning/models/deep-learning/transformers/benchmark/","title":"Benchmark"},{"body":"\n","excerpt":"","ref":"/docs/cloud/devops/","title":"DevOps"},{"body":"\nR timevis: create interactive timeline visualization in R  GitHub timevis lets you create rich and fully interactive timeline visualizations in R. Timelines can be included in Shiny apps and R markdown documents, or viewed from the R console and RStudio Viewer. timevisincludes an extensive API to manipulate a timeline after creation, and supports getting data out of the visualization into R. This package is based on the visjs Timeline JavaScript library.  worldcup\n","excerpt":"R timevis: create interactive timeline visualization in R  GitHub timevis lets you create rich and …","ref":"/docs/data/visual-art/time-series/","title":"Visualization Timeline"},{"body":"\nCommit   How to revert last commit in the remote?\ngit reset HEAD^ --hard\ngit push -f\n  How to remove a file added in the most recent unpushed commit?\n Stage our giant file for removal, but leave it on disk  git rm --cached giant_file\n Commit this change  git commit --amend -CHEAD\n Push our rewritten, smaller commit  git push\n   How to remove a file from a Git repository without deleting it from the local filesystem git rm --cached file git rm -r --cached folderName  Submodule   How to remove a Git submodule?\n Delete the relevant section from the .gitmodules file Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config Run git rm --cached path_to_submodule -r (no trailing slash) Run rm -rf .git/modules/path_to_submodule (no trailing slash) Commit git commit -m 'Removed submodule' Delete the now untracked submodule files rm -rf path_to_submodule    Branch # 1) Add a new branch from your origin/master branch git branch new-branch origin/master git checkout new-branch # 2) Make a commit of your work (e.g. you added your name in the README.md) git add README.md git commit -m \u0026#39;add README\u0026#39; # 3) If you had multiple commits, but you want to select a specific commit(e.g. commit id: bbb909f) for a pull request  git cherry-pick bbb909f # 4) Push to your new-branch git push origin new-branch \nFind bugs git-bisect\n Use binary search to find the commit that introduced a bug\n Git patch Reference\n git add -p   git add partial (or patch)\n  git add -i   Git will ask you which files you would like to partially stage Then, for each section of the selected files, it will display hunks of the file diff and ask if you would like to stage them one by one. Choose type 5 or p (for patch)\n  git reset -p   Reset in patch\n  git commit -p   Combines git add -p and git commit in one command.\n Patch mode allows you to stage parts of a changed file, instead of the entire file. This allows you to make concise, well-crafted commits that make for an easier to read history. This feature can improve the quality of the commits. It also makes it easy to remove parts of the changes in a file that were only there for debugging purposes - prior to the commit without having to go back to the editor.\nIt allows you to see the changes (delta) to the code that you are trying to add, and lets you add them (or not) separately from each other using an interactive prompt. Here\u0026rsquo;s how to use it:\nAt each point, you will be asked whether you want to \u0026ldquo;stage this hunk\u0026rdquo;. Here are the commands you can use:\nCommonly used commands  y - stage this hunk n - do not stage this hunk a - stage this and all the remaining hunks in the file d - do not stage this hunk nor any of the remaining hunks in the file  More advanced commands  g - select a hunk to go to / - search for a hunk matching the given regex j - leave this hunk undecided, see next undecided hunk J - leave this hunk undecided, see next hunk k - leave this hunk undecided, see previous undecided hunk K - leave this hunk undecided, see previous hunk s - split the current hunk into smaller hunks e - manually edit the current hunk ? - print help  Some cool tips from the internet:  If git presents you with a chunk larger than what you would like to add, you can use the \u0026ldquo;e\u0026rdquo; interactive command to specify the exact lines that you want added or removed. This is probably the most powerful option. As promised, it will open the hunk in a text editor and you can edit it to your hearts content Split the hunk into smaller hunks. This only works if there’s unchanged lines between the changes in the displayed hunk, so this wouldn’t have any effect in the example above  ","excerpt":"Commit   How to revert last commit in the remote?\ngit reset HEAD^ --hard\ngit push -f\n  How to remove …","ref":"/docs/coding/practices/version-control/git/","title":"Git"},{"body":"\nCrash Course  Visual Studio Code Crash Course From freeCodeCamp  Theme  Oceanic Next dimmed bg Panda  Extensions Draw Note  Insert svg into Markdown files  Draw.io Integration ","excerpt":"\nCrash Course  Visual Studio Code Crash Course From freeCodeCamp  Theme  Oceanic Next dimmed bg …","ref":"/docs/swiss-knives/vscode/","title":"VS Code"},{"body":"\nLibraries for Geospatial Data Visualization in Python PyViz/HoloViz(Geoviews, Datashader, HvPlot)  Holoviz maintained libraries have all data visualisations you might need, including dashboards and interactive visualisation. Geoviews, in particular, with its dedicated Geospatial data visualisation library, provides an easy to use and convenient geospatial data.\n  Geoviews  Explore and visualize geographical, meteorological, and oceanographic datasets, such as those used in weather, climate, and remote sensing research.\n  HvPlot  Allows users to work with different data types and can extend the usage of other Python libraries including Pandas, Geopadnas, Dask and Rapids.\n  Datashader  It breaks the process into multiple steps and runs parallel to create a visualisation for large datasets quickly.\n  Panel  A high-level app and dashboarding solution for Python provide an easy to use interface on creating interactive web apps and dashboards using Jupyter notebooks.\n   import geoviews as gv imporg geopandas as gpd gv.Polygons(gpd.read_file(gpd.datasets.get_path(\u0026#39;naturalearth_lowres\u0026#39;)), vdims=[\u0026#39;pop_est\u0026#39;, (\u0026#39;name\u0026#39;, \u0026#39;Country\u0026#39;)]).opts( tools=[\u0026#39;hover\u0026#39;], width=600, projection=crs.Robinson() ) \nFolium  It is built on top of Leaflet.js and can cover most of your mapping needs in Python with its great plugins  import foliumm m= folium.Map(location=[45.5236, -122.6750]) \nKeplerGL  kepler.gl is a web-based visualisation tool for large Geospatial datasets built on top of deck.gl. Uber made it an open-source in 2018, and its functionality is impressive. You can easily drag and drop your dataset and tweak it immediately on the web to visualise large scale geospatial datasets with ease. It combines a world-class visualisation tool, an easy to use User interface (UI), and flexibility of python and Jupyter notebooks.  IpyLeaflet  It is built on top of Jupyter Widgets and Leaflet visualisation library. The interactive functionality in IpyLeaflet is unparalleled as Widgets enable bidirectional interactions. Therefore, your maps are not only interactive but also can capture user inputs to trigger new computations.  Geopandas  Only for static maps However, recent advances and additions of Contextily for base maps and IPYMPL for interactive matplotlib plots makes it straightforward to create interactive maps with Geopandas.  ","excerpt":"Libraries for Geospatial Data Visualization in Python PyViz/HoloViz(Geoviews, Datashader, HvPlot) …","ref":"/docs/data/visual-art/geo-spatial/","title":"Visualization Geospatial"},{"body":"\nWhite Board Platform  miro  ","excerpt":"\nWhite Board Platform  miro  ","ref":"/docs/swiss-knives/white-board/","title":"White Board"},{"body":"\n An Imaging Diagnostics Use Case in Healthcare, powered by Ocean Protocol NLP Application in Personalized Medicine NLP Text Classification of Quora Questsions  ","excerpt":"\n An Imaging Diagnostics Use Case in Healthcare, powered by Ocean Protocol NLP Application in …","ref":"/docs/machinelearning/projects/","title":"Projects"},{"body":"\nHow to deploy machine learning projects to Kubernetes? bodywork  GitHub Link Documentation Installation: pip install bodywork  Functions and examples  serve models as microservices execute batch jobs run reproducible pipelines  Benefits  Bodywork brings DevOps to your machine learning projects and will form the basis of your Machine Learning Operations (MLOps) platform. It will ensure that your projects are always trained with the latest data, the most recent models are always deployed and your machine learning systems remain highly-available.  Target users  Bodywork is aimed at teams who want to deploy machine learning projects in containers. It will deliver your project\u0026rsquo;s Python modules directly from your Git repository into Docker containers and manage their deployment to a Kubernetes cluster.  bodywork\nHow to use bodywork?  A GiHub account  support for GitLab, BitBucket and Azure DevOps will come later in 2021   Access to Kubernetes cluster Divide your project into discrete stages and create an executable Python module for each one. Bundle these files together with a bodywork.yaml configuration file, into a Git repository and you\u0026rsquo;re ready to go.\n   How to troubleshoot a serverless application? Grafana  Amazon Managed Service for Grafana (AMG), is a fully managed service that makes visualizing and analyzing operational data at scale easier. Many customers choose AMG because of an existing investment in Grafana, its deep integration with vendors they might already be using, consolidation of metrics across environments, and powerful visualizations for both in-cloud and on-premises workloads. Amazon Managed Service for Grafana is a powerful tool for analyzing your serverless application’s metrics and logs. Grafana  Ref  Amazon Managed Service for Grafana – Getting Started Using Amazon Managed Service for Grafana to troubleshoot a serverless application  ","excerpt":"How to deploy machine learning projects to Kubernetes? bodywork  GitHub Link Documentation …","ref":"/docs/cloud/devops/mlops/","title":"MLOps"},{"body":"\n1. How to align columns in markdown?    Left alignment Right alignment Center alignment     \u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;-: :\u0026mdash;\u0026mdash;:    2. How to copy table in excel and paste as a markdown table? thisdavej.com\n3. How to create books in markdown?  mdBook   mdBook is a command line tool and Rust crate to create books using Markdown files.\n # Install Rust curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh # Add Cargo's bin directory ($HOME/.cargo/bin) in your PATH source $HOME/.cargo/env # Install mdBook cargo install mdbook # Initialize mdbook init # Render your book mdbook build # Preview a book by serving it over HTTP at localhost:3000 by default mdbook serve  GitBook  4. What is a good Markdown editor?  tui.editor  5. How to highlight code in Markdown? var a = 9 Check Languages known to GitHub\n","excerpt":"1. How to align columns in markdown?    Left alignment Right alignment Center alignment …","ref":"/docs/coding/functional-coding/markdown/","title":"Markdown"},{"body":"","excerpt":"","ref":"/docs/coding/functional-coding/python/","title":"Python"},{"body":"\n1. Install AWS Command Line Interface (CLI) Doc\n# Optional: activate conda environment source activate pinenuts # Install AWS CLI pip install awscli # Install command completion feature on Raspberry Pi’s CLI interface complete -C aws_completer aws \n2. Setup Security Credentials Security_credentials\n# 1) Create Access Key ID and secret access keys \u0026#39;\u0026#39;\u0026#39; User on right top menu =\u0026gt; \u0026#39;My seceurity Credentials =\u0026gt; Access keys =\u0026gt; Create New Access Key =\u0026gt; Download the csv to your local drive \u0026#39;\u0026#39;\u0026#39; # 2) In your local terminal aws configure \u0026#39;\u0026#39;\u0026#39; AWS Access Key ID [None]: aaaaaaaaaaaaaa AWS Secret Access Key [None]: aaaaaaaaaa Default region name [None]: eu-west-1 Default output format [None]: json \u0026#39;\u0026#39;\u0026#39; 3. Use AWS SDK in your local terminal # Create a new Thing aws iot create-thing --thing-name \u0026#34;YourThingName\u0026#34; # List all your IoT Things aws iot list-things # List all your buckts aws s3 ls # List the content in one bucket aws s3 ls s3://greengrass-bucket-pinenuts # Copy files to your bucket aws s3 cp myfolder s3://greengrass-bucket-pinenuts --recursive \n4. Use AWS SDK in Python (Boto3 package) Boto 3\n# Install boto3 $ pip install boto3 Use boto3 python package import boto3 # Let\u0026#39;s use Amazon S3 s3 = boto3.resource(\u0026#39;s3\u0026#39;) # Print out bucket names for bucket in s3.buckets.all(): print(bucket.name) # Upload a new file data = open(\u0026#39;test.jpg\u0026#39;, \u0026#39;rb\u0026#39;) s3.Bucket(\u0026#39;my-bucket\u0026#39;).put_object(Key=\u0026#39;test.jpg\u0026#39;, Body=data) ","excerpt":"1. Install AWS Command Line Interface (CLI) Doc\n# Optional: activate conda environment source …","ref":"/docs/cloud/aws/aws_sdk_cli/","title":"SDK"},{"body":"Download workspace files into a tar file  Snippet from udacimak  \u0026#34;\u0026#34;\u0026#34; Source: - https://stackoverflow.com/questions/48122744/how-to-download-all-files-and-folder-hierarchy-from-jupyter-notebook \u0026#34;\u0026#34;\u0026#34; import os import tarfile def recursive_files(dir_name=\u0026#39;.\u0026#39;, ignore=None): for dir_name,subdirs,files in os.walk(dir_name): if ignore and os.path.basename(dir_name) in ignore: continue for file_name in files: if ignore and file_name in ignore: continue yield os.path.join(dir_name, file_name) def make_tar_file(dir_name=\u0026#39;.\u0026#39;, target_file_name=\u0026#39;workspace_archive.tar\u0026#39;, ignore=None): tar = tarfile.open(target_file_name, \u0026#39;w\u0026#39;) for file_name in recursive_files(dir_name, ignore): tar.add(file_name) tar.close() dir_name = \u0026#39;.\u0026#39; target_file_name = \u0026#39;workspace_archive.tar\u0026#39; # List of files/directories to ignore ignore = {\u0026#39;.ipynb_checkpoints\u0026#39;, \u0026#39;__pycache__\u0026#39;, target_file_name} make_tar_file(dir_name, target_file_name, ignore) ","excerpt":"Download workspace files into a tar file  Snippet from udacimak  \u0026#34;\u0026#34;\u0026#34; Source: - …","ref":"/docs/swiss-knives/download/","title":"Download files"},{"body":"","excerpt":"","ref":"/docs/","title":"Data Science"},{"body":"","excerpt":"","ref":"/community/","title":"Contact"},{"body":"\nExecute Python code from VSCode Install the Code Runner Extension.\n","excerpt":"Execute Python code from VSCode Install the Code Runner Extension.","ref":"/docs/coding/practices/error_collection/vscode/","title":"VScode"},{"body":"","excerpt":"","ref":"/docs/coding/practices/version-control/","title":"Version Control"},{"body":" 物来顺应，未来不迎，当时不杂 — 曾国藩\n ","excerpt":" 物来顺应，未来不迎，当时不杂 — 曾国藩\n ","ref":"/docs/swiss-knives/thoughts/","title":"Random Thoughts"},{"body":"","excerpt":"","ref":"/docs/healthcare/","title":"Healthcare"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_huced206859cad5be4c52922d82356914e_3407872_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_huced206859cad5be4c52922d82356914e_3407872_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to DJ\u0026#39;s Website Learn More   Check GitHub   \t        Goldydocs provides a single web UI providing visibility into porridge temperature, chair size, and bed softness metrics! You can even find out who\u0026rsquo;s been eating your porridge.\n(Sadly, Goldydocs isn\u0026rsquo;t a real project, but you can use this site as an example to create your own real websites with Docsy)\n      New chair metrics! The Goldydocs UI now shows chair size metrics by default.\nPlease follow this space for updates!\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter! For announcement of latest features etc.\nRead more …\n     This is the second Section        Download from AppStore Get the Goldydocs app!\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter! For announcement of latest features etc.\nRead more …\n     This is another Section     ---","excerpt":"#td-cover-block-0 { background-image: …","ref":"/","title":"DJ's Website"},{"body":"\nHow to read json files in a directory to a dataframe? import pandas as pd import json, os # List of json files files = list(os.listdir(json_dir))[0:400] df = pd.DataFrame() for file in files: json_path = os.path.join(json_dir, file) # Load json files with open(json_path) as json_file: json_data = json.load(json_file) # Convert to dataframe  json_data_df = pd.io.json.json_normalize(json_data) df = df.append(json_data_df) ","excerpt":"\nHow to read json files in a directory to a dataframe? import pandas as pd import json, os # List of …","ref":"/docs/coding/functional-coding/python/file-reading/","title":"Read Files"},{"body":"Distributions  discrete continuous distributions their standard properties common statistical measures simple statistical inference Methods useful for implementing Machine Learning ideas, for designing experiments, and for interpreting their results. No advanced topics such as Wiener processes or the Metropolis-Hastings algorithm. University of Cambridge first year statistics course ​[example sheets 1 and 2]​(https://www.dpmms.cam.ac.uk/study/IB/Statistics/)  Sheet 1 Sheet 2    ","excerpt":"Distributions  discrete continuous distributions their standard properties common statistical …","ref":"/docs/math/intro/statistics/summary/","title":""},{"body":"","excerpt":"","ref":"/docs/swiss-knives/download/download-workspace-file/","title":""},{"body":"","excerpt":"","ref":"/index.json","title":""},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]